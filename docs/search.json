[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Data Analysis for Chinese Lending Data Using R & LLMs",
    "section": "",
    "text": "Preface\nThis textbook accompanies the intensive month-long course Applied Data Analysis For Chinese Overseas Lending Data Using R & LLMs developed for AidData research analysts. The course combines four weekly 90-minute online sessions with a full day of in-person instruction, designed to equip analysts with powerful new tools for data analysis, visualization, and automation.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#our-promise-to-you",
    "href": "index.html#our-promise-to-you",
    "title": "Applied Data Analysis for Chinese Lending Data Using R & LLMs",
    "section": "Our Promise to You",
    "text": "Our Promise to You\nBy the end of this course, you will be able to:\n\nTransform complex datasets into compelling visual stories\nAutomate those repetitive tasks that consume hours of your week\nCreate analyses that update automatically when new data arrives\nGenerate professional reports that combine narrative, code, and visuals\nLeverage AI tools to enhance your analytical capabilities\nSolve common data challenges more efficiently",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#our-teaching-philosophy",
    "href": "index.html#our-teaching-philosophy",
    "title": "Applied Data Analysis for Chinese Lending Data Using R & LLMs",
    "section": "Our Teaching Philosophy",
    "text": "Our Teaching Philosophy\nThink of R not as a programming language to master, but as a powerful toolkit that helps you tell stories with data. Just as you don’t need to be a mechanic to drive a car effectively, you don’t need to be a programmer to use R powerfully. This course focuses on giving you practical tools that will immediately enhance your analytical capabilities.\nWe embrace two key advantages that make this possible:\n\nModern Tools: The tidyverse ecosystem transforms R from a statistical programming language into an intuitive data analysis toolkit\nAI Assistance: Large Language Models (LLMs) act as your personal guide, helping you find and implement the right tools for each task",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#what-makes-this-course-different",
    "href": "index.html#what-makes-this-course-different",
    "title": "Applied Data Analysis for Chinese Lending Data Using R & LLMs",
    "section": "What Makes This Course Different",
    "text": "What Makes This Course Different\nTraditional R courses often get bogged down in programming concepts before getting to practical applications. We flip this approach:\n\nStart with practical tools you can use immediately\nFocus on real AidData challenges and solutions\nUse AI tools to overcome technical hurdles\nBuild from practical application to deeper understanding",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#week-by-week-journey",
    "href": "index.html#week-by-week-journey",
    "title": "Applied Data Analysis for Chinese Lending Data Using R & LLMs",
    "section": "Week-by-Week Journey",
    "text": "Week-by-Week Journey\n\nWeek 1: First Steps with R\n\nSet up R & R Studio on your computer\nCreate your first data visualization\nLearn to use AI tools for coding assistance\nBegin working with Quarto for reproducible reports\n\n\n\nWeek 2: Data Visualization Mastery\n\nCreate publication-ready plots with ggplot2\nMaster the grammar of graphics\nBuild interactive visualizations\nDesign effective data presentations\n\n\n\nWeek 3: Data Transformation\n\nClean and reshape real development finance data\nMaster key data manipulation verbs\nReplicate analyses from AidData reports\nAutomate repetitive data tasks\n\n\n\nWeek 4: Advanced Topics\n\nHandle complex data cleaning challenges\nCreate reproducible workflows\nGenerate automated reports\nBuild functions for common tasks\n\n\n\nIn-Person Session\n\nWork on your own projects with expert guidance\nTackle advanced visualization challenges\nLearn to extract structured data from text using AI\nBuild confidence through hands-on practice",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#being-realistic-about-learning",
    "href": "index.html#being-realistic-about-learning",
    "title": "Applied Data Analysis for Chinese Lending Data Using R & LLMs",
    "section": "Being Realistic About Learning",
    "text": "Being Realistic About Learning\nYou won’t become an R expert in four weeks—and that’s okay. What you will achieve:\n\nMaster enough R to make your daily work easier and more efficient\nGet past the steepest part of the learning curve\nBuild confidence in your ability to learn more\nDevelop a foundation for continued learning",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#your-ai-learning-assistant",
    "href": "index.html#your-ai-learning-assistant",
    "title": "Applied Data Analysis for Chinese Lending Data Using R & LLMs",
    "section": "Your AI Learning Assistant",
    "text": "Your AI Learning Assistant\nLearning R in 2025 is fundamentally different from even a few years ago. Modern AI tools serve as 24/7 tutors that can:\n\nExplain complex code in plain English\nHelp debug your problems\nSuggest improvements to your code\nAnswer your questions any time\n\nThink of these AI tools as having a knowledgeable colleague1 always ready to help—they won’t do the work for you, but they’ll help you learn faster and overcome obstacles more efficiently.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-book",
    "href": "index.html#how-to-use-this-book",
    "title": "Applied Data Analysis for Chinese Lending Data Using R & LLMs",
    "section": "How to Use This Book",
    "text": "How to Use This Book\nThis book serves multiple purposes:\n\nA reference during the course\nA guide for self-paced learning\nA resource for future consultation\n\nEach chapter includes:\n\nClear learning objectives\nPractical examples using real data\nExercises to reinforce learning\nTips for using AI tools effectively\nResources for deeper learning\n\nLet’s begin this journey together. By the end of the course, you’ll have new tools and skills to analyze Chinese development finance data more effectively and efficiently than ever before.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Applied Data Analysis for Chinese Lending Data Using R & LLMs",
    "section": "",
    "text": "Sometimes that knowledgeable colleague is overconfident and incorrect. Use your human judgment.↩︎",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "week_1_pre_class.html",
    "href": "week_1_pre_class.html",
    "title": "1  Pre-Course Preparation",
    "section": "",
    "text": "1.1 Overview\nBefore our first class meeting, you’ll need to install some software and familiarize yourself with a few basic concepts. This preparation will ensure you can participate fully in class activities. While the steps are straightforward, please allow 45-60 minutes to complete everything comfortably.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pre-Course Preparation</span>"
    ]
  },
  {
    "objectID": "week_1_pre_class.html#learning-objectives",
    "href": "week_1_pre_class.html#learning-objectives",
    "title": "1  Pre-Course Preparation",
    "section": "1.2 Learning Objectives",
    "text": "1.2 Learning Objectives\nBy completing this pre-class work, you will be able to:\n\nInstall R and RStudio on your computer\nExplain the difference between R and RStudio\nPerform basic calculations in R\nCreate simple variables\nUse basic R functions\nUse AI tools to help understand R code",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pre-Course Preparation</span>"
    ]
  },
  {
    "objectID": "week_1_pre_class.html#what-is-r",
    "href": "week_1_pre_class.html#what-is-r",
    "title": "1  Pre-Course Preparation",
    "section": "1.3 What is R?",
    "text": "1.3 What is R?\nThink of R as two things working together: a powerful calculator designed specifically for data analysis, and a collection of tools that make that calculator more useful. R was created by statisticians in the 1990s to make data analysis more accessible and reproducible. Today, it’s one of the most popular tools for data analysis worldwide. It is free and open source.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pre-Course Preparation</span>"
    ]
  },
  {
    "objectID": "week_1_pre_class.html#what-is-rstudio",
    "href": "week_1_pre_class.html#what-is-rstudio",
    "title": "1  Pre-Course Preparation",
    "section": "1.4 What is RStudio?",
    "text": "1.4 What is RStudio?\nRStudio is like a workshop for R – it’s where you’ll actually do your work. If R is a powerful calculator, RStudio is the desk, notepad, file organizer, and reference library that makes using that calculator much easier. It’s called an IDE (Integrated Development Environment), but you can think of it as your data analysis workspace.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pre-Course Preparation</span>"
    ]
  },
  {
    "objectID": "week_1_pre_class.html#what-are-r-packages",
    "href": "week_1_pre_class.html#what-are-r-packages",
    "title": "1  Pre-Course Preparation",
    "section": "1.5 What are R Packages?",
    "text": "1.5 What are R Packages?\nPackages in R are like apps on your phone:\n\nYour phone comes with some basic apps (like R’s built-in functions)\nYou can install new apps (packages) to do specific tasks\nOnce installed, you need to open (load) an app to use it",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pre-Course Preparation</span>"
    ]
  },
  {
    "objectID": "week_1_pre_class.html#what-is-the-tidyverse",
    "href": "week_1_pre_class.html#what-is-the-tidyverse",
    "title": "1  Pre-Course Preparation",
    "section": "1.6 What is the tidyverse?",
    "text": "1.6 What is the tidyverse?\nThe tidyverse is like a bundle of the most useful data analysis apps, all designed to work together seamlessly. It includes tools for:\n\nCreating beautiful visualizations\nCleaning and organizing data\nImporting data from various sources\n\nThese tools are designed to be more intuitive and user-friendly than base R.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pre-Course Preparation</span>"
    ]
  },
  {
    "objectID": "week_1_pre_class.html#installation-steps",
    "href": "week_1_pre_class.html#installation-steps",
    "title": "1  Pre-Course Preparation",
    "section": "1.7 Installation Steps",
    "text": "1.7 Installation Steps\n\n1.7.1 1. Install R First\n\nGo to CRAN\nClick on your operating system\nDownload and run the installer\n\n\n\n1.7.2 2. Install RStudio Second\n\nGo to RStudio Download\nDownload and run the installer\n\n\n\n1.7.3 Need More Help?\nIf you run into any issues, you have two great options:\n\nTry an interactive tutorial\n\nThis will walk you through each step with detailed instructions\nIncludes screenshots and troubleshooting tips\n\nAsk a friendly LLM\n\nUse ChatGPT or Claude\nTry questions like: “I’m having trouble installing R on [your OS]. Here’s what I’ve tried…”\nThe LLM can provide customized help for your specific situation\n\n\n\n\n1.7.4 Verify Your Installation\nAfter installing both R and RStudio:\n\nOpen RStudio (not R)\nType 2 + 2 in the Console (bottom left)\nPress Enter\n\nIf you see [1] 4, you’re ready to go!\nIf not, ask your favorite LLM. Describe what your issue. Upload a screenshot if you are unsure.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pre-Course Preparation</span>"
    ]
  },
  {
    "objectID": "week_1_pre_class.html#the-rstudio-interface",
    "href": "week_1_pre_class.html#the-rstudio-interface",
    "title": "1  Pre-Course Preparation",
    "section": "1.8 The RStudio Interface",
    "text": "1.8 The RStudio Interface\n\n\n\nR Studio\n\n\nWhen you first open RStudio, you’ll likely see three panels. To see all four panels, click the “New File” icon in the top left corner and select “R Script”. Here’s what each panel does:\n\nSource Editor (top left): This is where you write and edit your R code files\n\nLike a text editor for your R scripts\nWhere you’ll write code you want to save and reuse\n\nConsole (bottom left): This is where you run R commands\n\nThink of it as R’s command center\nWhere you can try out code immediately\n\nEnvironment/History (top right): Shows your active variables and command history\n\nEnvironment tab lists all variables you’ve created\nHistory tab shows commands you’ve run\n\nFiles/Plots/Packages/Help (bottom right): A multi-purpose viewing area\n\nBrowse your files\nView plots and visualizations\nManage R packages\nAccess help documentation\n\n\n\n\n\n\n\n\nTip\n\n\n\nWant to learn more about RStudio’s features? Check out the RStudio IDE Cheat Sheet.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pre-Course Preparation</span>"
    ]
  },
  {
    "objectID": "week_1_pre_class.html#basic-r-console-practice",
    "href": "week_1_pre_class.html#basic-r-console-practice",
    "title": "1  Pre-Course Preparation",
    "section": "1.9 Basic R Console Practice",
    "text": "1.9 Basic R Console Practice\nOnce you have R and RStudio installed, try these commands in your RStudio console:\n\n1.9.1 R as a calculator\n\n2 * 3 + 4\n\n[1] 10\n\n10 / 2\n\n[1] 5\n\n2^3   # This means 2 to the power of 3\n\n[1] 8\n\n### Creating variables (we call this \"assignment\")\nx &lt;- 10    # The arrow means \"assign 10 to x\"\ny &lt;- 5\nx + y\n\n[1] 15\n\n### Using functions\nsum(1, 2, 3, 4, 5)\n\n[1] 15\n\nmean(c(1, 2, 3, 4, 5))    # c() combines numbers into a list\n\n[1] 3",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pre-Course Preparation</span>"
    ]
  },
  {
    "objectID": "week_1_pre_class.html#installing-your-first-package-the-tidyverse",
    "href": "week_1_pre_class.html#installing-your-first-package-the-tidyverse",
    "title": "1  Pre-Course Preparation",
    "section": "1.10 Installing Your First Package: The Tidyverse",
    "text": "1.10 Installing Your First Package: The Tidyverse\nJust as installing Microsoft Office gives you a whole suite of programs (Word, Excel, PowerPoint) at once, installing the tidyverse gives you a collection of R packages designed to work together seamlessly for data analysis. Let’s install it:\n\nType this command in your console:\n\n\ninstall.packages(\"tidyverse\")\n\nYou’ll see quite a bit of text appear as R downloads and installs multiple packages. This is normal! The tidyverse includes packages for:\nMaking plots (ggplot2) Working with data (dplyr) Reading data files (readr) And several others we’ll use throughout the course\nAfter installation completes, load the tidyverse:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nYou’ll see some messages about which packages were loaded. Don’t worry about understanding all of them now - we’ll learn about each one as we need it.\n\n\n\n\n\n\nNote\n\n\n\nYou only need to install a package once on your computer (like installing Microsoft Office), but you need to load it with library() each time you start R (like opening Excel when you want to use it).",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pre-Course Preparation</span>"
    ]
  },
  {
    "objectID": "week_1_pre_class.html#try-using-ai-to-learn-r",
    "href": "week_1_pre_class.html#try-using-ai-to-learn-r",
    "title": "1  Pre-Course Preparation",
    "section": "1.11 Try Using AI to Learn R",
    "text": "1.11 Try Using AI to Learn R\nAI can be your extra-attentive tutor. Here’s a piece of code to ask an LLM about:\n\nflights |&gt;\n  group_by(carrier) |&gt;\n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE),\n    n = n()\n  ) |&gt;\n  arrange(desc(avg_delay))\n\nTry this prompt with ChatGPT or Claude:\n\n“I’m new to R. Can you explain what each line of this code does? Please explain it like you’re talking to someone who has never programmed before.”\n\nLLMs’ coding ability improves rapidly, so it’s worth using the frontier models. If you don’t already have access to the paid version of either Claude or ChatGPT, it is $20 a month well spent1.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pre-Course Preparation</span>"
    ]
  },
  {
    "objectID": "week_1_pre_class.html#learning-resources",
    "href": "week_1_pre_class.html#learning-resources",
    "title": "1  Pre-Course Preparation",
    "section": "1.12 Learning Resources",
    "text": "1.12 Learning Resources\nOne of R’s greatest strengths is its welcoming, active community that creates high-quality learning resources in many different formats. Everyone learns differently, so we’ve provided options to suit different learning styles. Remember: our course will get you started, but these resources can help you continue your journey.\n\n1.12.1 THE Textbook\nR for Data Science (2e) is the definitive guide to modern data analysis in R, and it’s completely free online. Much of this course’s approach is inspired by this book, but with a key difference: while R4DS teaches concepts using general datasets (like diamond prices and penguin measurements), we’ll apply these same concepts directly to Chinese development finance data.\nThink of R4DS as your comprehensive reference manual. When you want to: - Understand a concept more deeply - Learn additional approaches - Explore beyond what we cover in class - Review fundamentals\nThis should be your first stop. The authors (Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund) have a gift for clear explanation, and the book is constantly updated to reflect modern best practices.\n\n\n\n\n\n\nTip\n\n\n\nBookmark R for Data Science now - you’ll be referring to it often!\n\n\n\n\n1.12.2 Video Learning\nIf you prefer to learn by watching, check out “R Programming for ABSOLUTE Beginners” (14 minutes). This gentle introduction is perfect if you’re feeling uncertain about where to start.\n\n\n1.12.3 Interactive Learning\nDataCamp’s Introduction to R provides hands-on practice in an online environment with immediate feedback. While DataCamp is generally a paid platform, this introductory course is free. This format worked particularly well for me when I was learning R.\n\n\n1.12.4 Community Resources\nThe R community is known for being friendly and supportive. Here’s where to find help:\n\n#rstats on Bluesky: The active R community shares tips, resources, and help\nR-Ladies: A worldwide organization promoting gender diversity in the R community\nR-bloggers: An aggregator of R-related blogs and tutorials\n\n\n\n\n\n\n\nNote\n\n\n\nWe’ll provide a resource list at the end of each chapter, but these should get you started. The R community’s commitment to sharing knowledge means you’ll never lack for learning materials!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pre-Course Preparation</span>"
    ]
  },
  {
    "objectID": "week_1_pre_class.html#success-checklist",
    "href": "week_1_pre_class.html#success-checklist",
    "title": "1  Pre-Course Preparation",
    "section": "1.13 Success Checklist",
    "text": "1.13 Success Checklist\nBefore coming to class, you should be able to:\n\nOpen RStudio\nPerform a calculation in the console\nCreate a variable\nUse a basic function\nInstall and load packages\nAsk an AI to explain R code",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pre-Course Preparation</span>"
    ]
  },
  {
    "objectID": "week_1_pre_class.html#footnotes",
    "href": "week_1_pre_class.html#footnotes",
    "title": "1  Pre-Course Preparation",
    "section": "",
    "text": "As of the time of writing in January of 2025, Claude is the best for R, but ChatGPT 4o (and above) aren’t too far behind. This will change quickly as new models come out.↩︎",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pre-Course Preparation</span>"
    ]
  },
  {
    "objectID": "week_1_in_class.html",
    "href": "week_1_in_class.html",
    "title": "2  Week 1: Getting Started (In-Class)",
    "section": "",
    "text": "2.0.1 Video Lecture\nWatch this video lecture to review the concepts from class 1:",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: Getting Started (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_1_in_class.html#todays-agenda-90-minutes",
    "href": "week_1_in_class.html#todays-agenda-90-minutes",
    "title": "2  Week 1: Getting Started (In-Class)",
    "section": "2.1 Today’s Agenda (90 minutes)",
    "text": "2.1 Today’s Agenda (90 minutes)\n\nWelcome & Course Overview (15 min)\n\nCourse logistics\nLearning approach\nSetting expectations\n\nProject Setup (20 min)\n\nCreating organized folder structure\nInstalling key packages\nUnderstanding RStudio’s layout\n\nFirst Steps with R (25 min)\n\nWriting your first function\nBuilding analysis pipelines\nCreating visualizations\n\nAutomated Reporting (25 min)\n\nSetting up report templates\nGenerating multiple reports\nHands-on practice\n\nWrap-up & Preview (5 min)\n\nReview key takeaways\nPreview next week\nAdditional resources",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: Getting Started (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_1_in_class.html#welcome-course-overview",
    "href": "week_1_in_class.html#welcome-course-overview",
    "title": "2  Week 1: Getting Started (In-Class)",
    "section": "2.2 Welcome & Course Overview",
    "text": "2.2 Welcome & Course Overview\nWelcome to Applied Data Analysis for Chinese Lending Data! Before we dive into R, let’s cover some course logistics:\n\nCourse Structure: 4 weekly online sessions + 1 full day in-person\nOnline Sessions: 90 minutes each, combining instruction and hands-on practice.\nMaterials: All course materials available in Quarto format\nSupport: Using AI tools (Claude, ChatGPT) for learning assistance. Slack channel. 1x1 support for any cool projects you want to pursue.\nQuestions: Ask questions anytime - no question is too basic!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: Getting Started (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_1_in_class.html#todays-focus-practical-tools-for-real-work",
    "href": "week_1_in_class.html#todays-focus-practical-tools-for-real-work",
    "title": "2  Week 1: Getting Started (In-Class)",
    "section": "2.3 Today’s Focus: Practical Tools for Real Work",
    "text": "2.3 Today’s Focus: Practical Tools for Real Work\nAt AidData, you spend countless hours analyzing development finance data and creating reports. Today’s session focuses on three key areas that will help make this work more efficient:\n\nWorking in RStudio\n\nGet comfortable with the RStudio interface\nUnderstand how to organize your projects\nLearn where to find help when you need it\n\nUsing Quarto for Better Documentation\n\nKeep track of your analysis process (like a lab notebook)\nCreate professional-quality reports\nCombine code, text, and visualizations seamlessly\n\nProductivity-Enhancing Tools\n\nWrite functions to avoid repetitive work\nUse map functions to process multiple countries efficiently\nCreate parameterized reports that save time and reduce errors",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: Getting Started (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_1_in_class.html#learning-objectives-first-steps-toward-efficiency",
    "href": "week_1_in_class.html#learning-objectives-first-steps-toward-efficiency",
    "title": "2  Week 1: Getting Started (In-Class)",
    "section": "2.4 Learning Objectives: First Steps Toward Efficiency",
    "text": "2.4 Learning Objectives: First Steps Toward Efficiency\nBy the end of today’s session, you’ll begin to:\n\nGet Started with Automated Reports\n\nSee how to transform manual reporting tasks into automated processes\nCreate your first parameterized report template\nUnderstand how to generate reports for multiple countries\n\nLearn About Analysis Pipelines\n\nSee how to make your analysis steps clear and reproducible\nStart building reusable analysis workflows\nGet introduced to tools for consistent results\n\nTake First Steps with Visualization\n\nCreate your first plots in R\nSee how to standardize visualizations across reports\nUnderstand how automated plotting can save time\n\nStart Working Smarter\n\nBegin reducing repetitive copy-paste work\nSee how automation can prevent common errors\nTake first steps toward reproducible analysis\n\n\nMost importantly, you’ll get hands-on experience with tools that can eventually save you hours of work each week. While mastering these tools takes time and practice, today you’ll see enough practical applications to understand their value. You’ll leave with working examples that you can build upon and adapt for your own work.\nThink of today as learning to drive a car - you won’t be a race car driver after one lesson, but you’ll understand the basics and see why it’s worth learning more. As the course progresses, we’ll build on these foundations and develop your skills further.\nLet’s get started!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: Getting Started (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_1_in_class.html#why-cool-things-first",
    "href": "week_1_in_class.html#why-cool-things-first",
    "title": "2  Week 1: Getting Started (In-Class)",
    "section": "2.5 Why “Cool Things First”?",
    "text": "2.5 Why “Cool Things First”?\nTraditional programming courses often start with fundamentals: variables, loops, conditionals. That’s like learning about internal combustion before driving a car! Instead, we’ll:\n\nStart with exciting, practical applications\nBuild motivation to learn fundamental concepts as we need them\nUse AI tools to help us understand the details and learn faster\n\nOur goal is to show you what’s possible, then help you understand how it works.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: Getting Started (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_1_in_class.html#setting-up-your-work-environment",
    "href": "week_1_in_class.html#setting-up-your-work-environment",
    "title": "2  Week 1: Getting Started (In-Class)",
    "section": "2.6 Setting Up Your Work Environment",
    "text": "2.6 Setting Up Your Work Environment\nLet’s create an organized workspace for this course. We’ll do this together - follow along on your computer:\n\n2.6.1 Creating a Project Structure\n\nIn RStudio, click File → New File → New Project\nClick “New Directory”\nClick “New Project”\nName it “data_analysis_bootcamp”\nChoose where to save it (remember this location!)\nClick “Create Project”\n\nNow let’s create an organized folder structure. Copy and paste this code into your R console:\n\n# Create week folders and their subfolders\nfor (week in 1:4) {\n  week_folder &lt;- paste0(\"week_\", week)\n  dir.create(week_folder)\n  \n  # Create standard subfolders\n  dir.create(file.path(week_folder, \"R\"))        # Scripts and Quarto documents\n  dir.create(file.path(week_folder, \"data-raw\")) # Original data files\n  dir.create(file.path(week_folder, \"data\"))     # Processed data\n  dir.create(file.path(week_folder, \"outputs\"))  # Generated reports and figures\n}\n\nThis will create:\ndata_analysis_bootcamp/\n├── week_1/\n│   ├── R/         # R scripts and Quarto documents\n│   ├── data-raw/  # Original data files\n│   ├── data/      # Processed data\n│   └── outputs/   # Generated reports and figures\n├── week_2/\n│   ├── R/\n│   ├── data-raw/\n│   ├── data/\n│   └── outputs/\n├── week_3/\n│   ├── R/\n│   ├── data-raw/\n│   ├── data/\n│   └── outputs/\n└── week_4/\n    ├── R/\n    ├── data-raw/\n    ├── data/\n    └── outputs/\n\n\n\n\n\n\nTip\n\n\n\nUse the Files pane in RStudio (bottom right) to verify that all folders were created correctly.\n\n\nEach week’s folder has:\n\nR/: Scripts and Quarto documents\ndata-raw/: Original, unmodified data\ndata/: Processed, analysis-ready data\noutputs/: Generated reports, figures, and other results\n\nFor this week’s automated reporting project, we’ll use:\n\nweek_1/R/ for our report template and functions\nweek_1/data-raw/ for any raw data we need to process\nweek_1/data/ for cleaned, ready-to-analyze data\nweek_1/outputs/ for our generated reports\n\n\n\n\n\n\n\nNote\n\n\n\nYou can also create folders using the Files pane in RStudio (bottom right) by clicking “New Folder”.\n\n\n\n\n2.6.2 Install & Load Packages\nThink of R packages like apps for your phone:\n\nYou install an app once\nYou open the app each time you want to use it\n\nSimilarly with R:\n\nYou install a package once\nYou load it with library() each time you start R\n\nThere are two main “app stores” for R packages:\n\nCRAN: The official R app store. Like the Apple App Store or Google Play Store, packages here go through review and testing\nGitHub: More like downloading apps directly from developers’ websites. Newer features, but less formal review\n\nLet’s install what we need:\n\n# First, install pak - our package installer\ninstall.packages(\"pak\")\n\n# Now use pak to install everything else\npak::pkg_install(\n  c(\n    \"quarto\",            # For report generation\n    \"t-emery/chinadevfin3\",  # From GitHub, GCDF 3.0 data package that I made\n    \"glue\",              # For working with text\n    \"tinytex\",           # For rendering pdfs\n    \"here\",              # For relative file paths,\n    \"withr\",             # For file system operations\n    \"fs\"                # For file system operations\n  )\n)\n\n# Special setup needed for PDF creation\ntinytex::install_tinytex() \n\n# If you haven't installed tidyverse yet (from pre-class setup):\n# pak::pkg_install(\"tidyverse\") # Core data science tools from CRAN\n\n\n\n\n\n\n\nTip\n\n\n\nThe c() function combines things together. We’ll use it often!\n\n\nNow let’s load the packages we’ll use:\n\nlibrary(tidyverse)      # Load core tools\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(chinadevfin3)   # Load GCDF 3.0 tools\nlibrary(glue)           # Load text tools\nlibrary(here)           # Load relative file paths\n\nhere() starts at /Users/teal_emery/Dropbox/DataScience/data_analysis_for_chinese_debt_data\n\n\n\n\n\n\n\n\nNote\n\n\n\nDon’t worry about the startup messages - they’re just telling us what was loaded.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: Getting Started (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_1_in_class.html#your-first-analysis-a-preview",
    "href": "week_1_in_class.html#your-first-analysis-a-preview",
    "title": "2  Week 1: Getting Started (In-Class)",
    "section": "2.7 Your First Analysis: A Preview",
    "text": "2.7 Your First Analysis: A Preview\nBefore we dive into details, let’s see what we’re working toward. Copy and paste this code into RStudio:\n\n# Get data for Angola\nget_gcdf3_dataset() |&gt;\n  filter(\n    recommended_for_aggregates == \"Yes\",\n    country_name == \"Angola\"\n  ) |&gt;\n  group_by(commitment_year) |&gt;\n  summarize(\n    total_usd_bn = sum(amount_constant_usd_2021, na.rm = TRUE) / 10^9\n  ) |&gt;\n  ggplot(aes(x = commitment_year, y = total_usd_bn)) +\n  geom_col(fill = \"steelblue\") +\n  labs(\n    title = \"Chinese Development Finance to Angola\",\n    x = \"Year\",\n    y = \"Commitments (2021 USD, Billions)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nDon’t worry if this looks intimidating - by the end of today:\n\nYou’ll understand what each part does\nYou’ll be able to modify it for your needs\nYou’ll know how to get AI help when stuck\n\nNext, we’ll break this down into reusable pieces and learn how to automate it for any country!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: Getting Started (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_1_in_class.html#introduction-to-quarto",
    "href": "week_1_in_class.html#introduction-to-quarto",
    "title": "2  Week 1: Getting Started (In-Class)",
    "section": "2.8 Introduction to Quarto",
    "text": "2.8 Introduction to Quarto\nQuarto is a modern scientific and technical publishing system built for the way we work today. Think of it as a powerful document creator that lets you combine your narrative (text), code, and results all in one place. When you make changes to your analysis, everything updates automatically - no more copying and pasting results into Word! You can write once and publish to multiple formats like HTML, PDF, Word, and presentations. It’s like having a Swiss Army knife for creating data-driven documents.\n\n\n\n\n\n\nGetting Started Resources\n\n\n\n\nFollow along with the official Getting Started with Quarto in RStudio tutorial\nKeep the handy Quarto Cheatsheet nearby for quick reference\n\n\n\n\n2.8.1 Why Use Quarto?\nQuarto documents are:\n\nReproducible: Code and results stay in sync\nProfessional: Beautiful output in multiple formats\nFlexible: One source, many outputs\nVersion-controlled: Easy to track changes\nShareable: Others can see your code and results\n\n\n\n2.8.2 Real-World Use Cases\nQuarto shines in several different scenarios:\n\n2.8.2.1 1. Lab Notebook / Exploratory Analysis\n\nWrite text and execute code in the same document\nTrack your thought process and decisions\nDocument what worked (and what didn’t)\nKeep a record of your exploration\nThis follows the tradition of “literate programming” introduced by Donald Knuth\n\nHere’s an example of documenting your exploration:\n## Question: Do loan commitments vary by region?\n\n```{r}\n# First, let's look at Africa\nget_gcdf3_dataset() |&gt; \n  calculate_yearly_commitments(\"Angola\")\n```\nInteresting spike in 2016. Let's check another country...\n\n\n2.8.2.2 2. Professional Documents\n\nTurn your analysis directly into reports\nCreate presentations\nBuild websites and books\nGenerate multiple formats from one source\n\nIn fact, this textbook itself is written in Quarto! You can see exactly how this page was created by looking at the source code on GitHub: week_1_in_class.qmd\nThis means:\n\nYou can see how we practice what we preach\nYou can learn from the actual code we use\nYou have examples to reference for your own work\n\n\n\n\n\n\n\nTip\n\n\n\nAs you work through this course, try viewing the source code for different pages. It’s a great way to learn Quarto techniques!\n\n\n\n\n\n2.8.3 Your First Quarto Document\n\nClick File → New File → Quarto Document\nFill in:\n\nTitle: “Week 1: Getting Started”\nAuthor: Your name\nClick “Create”\n\n\nYou’ll see a template document with some example content. Let’s modify it:\n---\ntitle: \"Week 1: Getting Started\"\nauthor: \"Your Name\"\nformat: \n  html:\n    embed-resources: true # Makes HTML easily shareable\n  docx: default\n  pdf: default\n---\n\n\n\n\n\n\nSharing HTML Documents\n\n\n\nUsing embed-resources: true ensures your HTML document can be shared and opened by anyone. The file will be a bit larger, but this is only noticeable when working with very large datasets. For most purposes, the convenience of easy sharing is worth it!\n\n\n\n\n2.8.4 Basic Markdown\nMarkdown is a simple way to format text that’s easy to read and write. Think of it as a set of formatting shortcuts: instead of clicking buttons like in Word, you add special characters around your text. Here are the basics you’ll see in our example:\n\nUse # for headers (more # means smaller headers)\nWrap words in **bold** to make them bold\nWrap words in *italics* to make them italics\nStart lines with - or numbers for lists\n\nTry this example:\n## About This Course\n\nThis course will teach me to:\n- Create **beautiful** visualizations\n- Write *efficient* code\n- Generate professional reports\n\n1. First, we'll learn about projects\n2. Then we'll explore functions\n3. Finally, we'll create visualizations\nTry toggling between the Source and Visual editors at the top left of your RStudio window. The Visual editor shows formatting like Word, but we encourage using the Source editor to better understand how markdown works.\n\n\n\n\n\n\nTip\n\n\n\nThere’s much more you can do with markdown! Check out the Quarto Markdown Basics guide when you’re ready to explore.\n\n\n\n\n2.8.5 Adding Code\nA code chunk is like a special container in your document where you can write and run R code. Think of it as a mini R console embedded right in your document - anything between the ``` markers will be treated as R code, run by R, and the results will appear right below it. This lets you mix explanatory text with working code and see the results all in one place.\nClick the “Insert” button or press Ctrl+Alt+I (Cmd+Option+I on Mac) to insert a code chunk:\n```{r}\n# Let's do a simple calculation\n2 + 2\n```\nTo run this code, you have two easy options:\n\nClick the small green “play” button ▶️ in the top-right corner of the code chunk\nUse keyboard shortcuts:\n\nWindows/Linux: Ctrl+Shift+Enter to run the entire chunk\nMac: Cmd+Shift+Enter to run the entire chunk\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can also run a single line by placing your cursor on that line and pressing:\n\nWindows/Linux: Ctrl+Enter\nMac: Cmd+Enter\n\n\n\nSave your Quarto document as week_1_in_class in the week_1/R folder. It will save your Quarto document with a .qmd extension.\n\n\n2.8.6 Rendering Your Document\n\nClick the “Render” button\nQuarto will create three versions:\n\nHTML (great for web sharing)\nWord (for collaborating with non-R users)\nPDF (for formal documents)\n\n\n\n\n2.8.7 Practice Time\n\nAdd a section about what you hope to learn\nInsert a code chunk with a simple calculation\nTry different heading levels (## and ###)\nAdd some bold and italic text\nRender to all formats\n\n\n\n\n\n\n\nTip\n\n\n\nKeep this document! We’ll add to it throughout the class.\n\n\nNext, we’ll start adding some real analysis to our document!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: Getting Started (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_1_in_class.html#lets-start-building-functions-pipelines",
    "href": "week_1_in_class.html#lets-start-building-functions-pipelines",
    "title": "2  Week 1: Getting Started (In-Class)",
    "section": "2.9 Let’s Start Building: Functions & Pipelines",
    "text": "2.9 Let’s Start Building: Functions & Pipelines\nNow that you’ve seen where we’re headed, let’s build this step by step. First, we’ll learn about two key concepts that make automation possible:\n\nFunctions: Write code once, use it many times\nPipes: Chain operations together clearly\n\nReady? Let’s dive in!\n\n2.9.1 Introduction to Functions: Making Your Code DRY and Error-Free\nOne of the fundamental principles of data analysis is DRY: Don’t Repeat Yourself. When you find yourself copying and pasting the same code multiple times, it’s time for a function. Functions help us: - Write code once and reuse it many times - Reduce the chance of errors from copy-paste mistakes - Make our code more readable and maintainable\nLet’s see this in action with a common task: making large numbers more readable.\n\n# Without a function - repetitive and error-prone\n1734483333 / 1000000000  # Convert to billions\n\n[1] 1.734483\n\n2847594938 / 1000000000  # Have to repeat the calculation\n\n[1] 2.847595\n\n5938273847 / 100000000  # Each repetition risks typos\n\n[1] 59.38274\n\n\nSpot the error above. It’s easy to make, and won’t always be as obvious to spot. Order of magnitude errors are surprisingly common, and quite embarrassing if you catch them afterwards.\nLet’s work hard to be lazy (and accurate), and make a function to do this:\n\n# With a function - write once, use many times\nto_billions &lt;- function(amount) {\n  amount / 10^9 # 10^9 = 1 billion, harder to mess up.\n}\n\n# Now it's easy and safe to convert any number\nto_billions(1734483333)  # Returns 1.73\n\n[1] 1.734483\n\nto_billions(2847594938)  # Returns 2.85\n\n[1] 2.847595\n\nto_billions(5938273847)  # Returns 5.94\n\n[1] 5.938274\n\n\nThis simple function shows us two key ideas:\n\nFunctions take an input and return an output\nFunctions help us do repetitive tasks easily\n\n\n\n2.9.2 Setting Up Our Analysis Tools\nNow let’s set up some more powerful functions for analyzing development finance data. Copy and paste this code block into RStudio:\n\n# Function to calculate yearly commitments for a country\ncalculate_yearly_commitments &lt;- function(data, country) {\n  data |&gt; \n    filter(\n      recommended_for_aggregates == \"Yes\",\n      country_name == country\n    ) |&gt; \n    group_by(\n      commitment_year,\n      flow_class\n    ) |&gt; \n    summarize(\n      amount_constant_usd_2021_bn = sum(\n        amount_constant_usd_2021, \n        na.rm = TRUE\n      ) |&gt; \n        to_billions(),\n      .groups = \"drop\"\n    )\n}\n\n# Function to create a visualization\nplot_loan_commitments &lt;- function(data, country) {\n  data |&gt; \n    ggplot(\n      aes(\n        x = commitment_year, \n        y = amount_constant_usd_2021_bn,\n        fill = flow_class\n      )\n    ) +\n    geom_col() +\n    labs(\n      title = str_glue(\"Chinese Development Finance Commitments to {country}\"),\n      subtitle = \"By Flow Class, 2000-2021\",\n      x = \"Commitment Year\",\n      y = \"Commitments (Constant 2021 USD, Billions)\",\n      fill = \"Flow Class\"\n    ) +\n    theme_minimal() +\n    scale_fill_brewer(palette = \"Set2\")\n}\n\nDon’t worry about understanding all this code yet! We’ll break it down later.\n\n\n2.9.3 Your First Analysis Pipeline\nNow we can use these functions to analyze development finance:\n\n# With pipes - clear and readable\nget_gcdf3_dataset() |&gt; \n  calculate_yearly_commitments(country = \"Angola\") |&gt; \n  plot_loan_commitments(country = \"Angola\")\n\n\n\n\n\n\n\n\nLet’s read this pipeline using “and then”:\n\nGet the GCDF dataset AND THEN\nCalculate yearly commitments for Angola AND THEN\nCreate a plot showing those commitments\n\n\n\n2.9.4 Why Pipes Make Life Easier\nThe pipe operator (|&gt;) simply takes what comes before it and puts it into the first argument of what comes after it. It’s that simple! Here’s our analysis without pipes:\n\n# Without pipes - like Excel formulas, hard to read and debug!\nplot_loan_commitments(calculate_yearly_commitments(get_gcdf3_dataset(), country = \"Angola\"), country = \"Angola\")\n\n\n\n\n\n\n\n\nSee how much harder that is to read? You have to read from the inside out, just like those nested Excel formulas that give everyone headaches! The pipe makes our code read like a story - first we do this, then we do that, then we do the next thing.\n\n\n\n\n\n\nA Tale of Two Pipes: |&gt; vs %&gt;%\n\n\n\nR has two pipe operators that both do the same basic job - they help make code more readable by passing data through a sequence of functions:\n\n|&gt; is the native R pipe (added in R 4.1)\n%&gt;% is the magrittr pipe (from the tidyverse)\n\nEither works fine, but we recommend using the native pipe |&gt; since it’s now built into R. You can set this as your default in RStudio under Tools → Global Options → Code → “Use native pipe operator”.\nKeyboard shortcut for adding a pipe:\n\nMac: Cmd+Shift+M\nWindows: Ctrl+Shift+M\n\n\n\n\n\n2.9.5 Understanding Our Code with AI\nLet’s use Claude or ChatGPT to understand our code better. Try these prompts:\n\nFor our simple function:\n\n\"Can you explain how this function works?\"\n\nto_billions &lt;- function(amount) {\n  amount / 10^9\n}\"\n\nFor understanding the pipeline:\n\n\"Can you explain what each step of this pipeline does?\n\nget_gcdf3_dataset() |&gt; \n  calculate_yearly_commitments(country = 'Angola') |&gt; \n  plot_loan_commitments(country = 'Angola')\"\n\n\n2.9.6 Understanding Complex Functions with AI\nNow let’s look at a more sophisticated function. We’ll use AI to help us understand how it works:\nTry this prompt with Claude, ChatGPT, or DeepSeek:\n\n“I’m new to R and trying to understand this function. Could you explain what each line does in simple terms? Please be specific about what each function (like filter, group_by, and summarize) is doing with our data.\n\n\ncalculate_yearly_commitments &lt;- function(data, country) {\n  data |&gt; \n    filter(\n      recommended_for_aggregates == 'Yes',\n      country_name == country\n    ) |&gt; \n    group_by(\n      commitment_year,\n      flow_class\n    ) |&gt; \n    summarize(\n      amount_constant_usd_2021_bn = sum(\n        amount_constant_usd_2021, \n        na.rm = TRUE\n      ) |&gt; \n        to_billions(),\n      .groups = 'drop'\n    )\n}\n\n\n\n2.9.7 Practice Time\nLet’s try some analyses:\n\nUse to_billions() with some large numbers\nModify the country in our pipeline to analyze different countries\nUse AI to help understand any patterns you see\n\n\n\n\n\n\n\nTip\n\n\n\nWhen you see an interesting pattern in your visualization, paste a screenshot into your favorite LLM and ask: “Why might [country] show high commitments in [year]?”\nThis is a great way to test the limits of AI. As domain experts, you probably know exactly why commitments spiked in certain years. Compare what the AI says with your expert domain knowledge - you might be surprised by how often it makes confident but incorrect assertions! This is a valuable lesson in both the power and limitations of AI tools.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: Getting Started (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_1_in_class.html#work-smarter-not-harder-automating-repetitive-tasks-with-map-functions",
    "href": "week_1_in_class.html#work-smarter-not-harder-automating-repetitive-tasks-with-map-functions",
    "title": "2  Week 1: Getting Started (In-Class)",
    "section": "2.10 Work Smarter, Not Harder: Automating Repetitive Tasks with Map Functions",
    "text": "2.10 Work Smarter, Not Harder: Automating Repetitive Tasks with Map Functions\n\n2.10.1 The Problem: Repetitive Analysis\nLet’s say we want to analyze several countries. We could copy and paste our code:\n\n# Analysis for Pakistan\nget_gcdf3_dataset() |&gt; \n  calculate_yearly_commitments(\"Pakistan\") |&gt; \n  plot_loan_commitments(\"Pakistan\")\n\n\n\n\n\n\n\n# Analysis for Ethiopia\nget_gcdf3_dataset() |&gt; \n  calculate_yearly_commitments(\"Ethiopia\") |&gt; \n  plot_loan_commitments(\"Ethiopia\")\n\n\n\n\n\n\n\n# Analysis for Sri Lanka...\n\nBut this is: - Tedious to write - Easy to make mistakes - Hard to maintain - Not scalable (imagine doing this for 100 countries!)\n\n\n2.10.2 A Better Way: Map Functions\nInstead of repeating ourselves, we can tell R to do something for each item in a list. Here’s a simple example using our to_billions() function:\n\n# Some amounts to convert\namounts &lt;- c(1000000000, 2000000000, 3000000000)\n# Instead of:\nto_billions(amounts[1])\n\n[1] 1\n\nto_billions(amounts[2])\n\n[1] 2\n\nto_billions(amounts[3])\n\n[1] 3\n\n# We can just write:\nmap_dbl(\n    amounts,          # The list of values we want to work with\n    to_billions      # The function to apply to each value (no parentheses needed!)\n)\n\n[1] 1 2 3\n\n\nThe map_dbl() function:\n\nTakes a list of things (our amounts)\nDoes something to each thing (applies to_billions)\nReturns a list of results\n\n\n\n\n\n\n\nMap Functions vs For Loops\n\n\n\nIf you’ve programmed before, you might be familiar with for loops. Both map functions and for loops let you repeat tasks, but map functions are often clearer to read and harder to mess up. Compare these approaches:\n```{r}\n# For loop approach\nresults &lt;- numeric(length(amounts))  # Have to pre-allocate\nfor(i in seq_along(amounts)) {      # Need to manage indices\n    results[i] &lt;- to_billions(amounts[i])\n}\n\n# Map approach\nresults &lt;- map_dbl(amounts, to_billions)  # Clear and concise\n```\nWhy tidyverse prefers map functions:\n\nThey’re simpler to read and write\nThey protect your data from accidental modifications (a common pitfall with for loops)\n\n\n\n\n\n\n\n\n\nMap Functions Family\n\n\n\n\nWe use map_dbl() because we know we want numbers (doubles) back\nThere’s also map() for general use, map_chr() for text, etc.\nSee the full purrr map documentation for more mapping functions\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nNotice that when we use to_billions in map_dbl(), we don’t include the parentheses. Think of it as giving R the recipe (the function) rather than the finished dish (the result of calling the function).\n\n\n\n\n2.10.3 Analyzing Multiple Countries\nLet’s apply this to our country analysis:\n\n# List of countries we want to analyze\ncountries &lt;- c(\"Pakistan\", \"Ethiopia\", \"Sri Lanka\")\n\n# First, let's make a function that does our whole analysis\nanalyze_country &lt;- function(country) {\n  get_gcdf3_dataset() |&gt; \n    calculate_yearly_commitments(country) |&gt; \n    plot_loan_commitments(country)\n}\n\n# Now we can easily analyze any country\nanalyze_country(\"Sri Lanka\")\n\n\n\n\n\n\n\n# And we can use map to do many countries\n# map(data to work with, function to apply)\nplots &lt;- map(\n  countries,        # First argument: list of countries\n  analyze_country   # Second argument: what to do with each country\n)\n\nLet’s break down what’s happening:\n\nWe create a list of countries\nmap() takes each country and…\nRuns our analysis pipeline for that country\nSaves all the plots in a list\n\n\n\n2.10.4 Why This Matters\nThis approach:\n\nMakes your code more concise and readable\nReduces chances for error\nMakes it easy to add or remove countries\nScales effortlessly (100 countries takes the same amount of code)\n\n\n\n2.10.5 Practice Time\nLet’s try some exercises:\n\nBasic mapping:\n\n\n# Convert these amounts to billions\nbig_numbers &lt;- c(1234567890, 9876543210, 5555555555)\nmap_dbl(big_numbers, to_billions)\n\n[1] 1.234568 9.876543 5.555556\n\n\n\nTry with different countries:\n\n\n# Analyze your own list of countries\nyour_countries &lt;- c(\"Vietnam\", \"Indonesia\", \"Laos\")\nmap(your_countries, analyze_country)  # Simple and clear!\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\nCalculate total commitments:\n\n\n# First, make a function for the calculation\nget_total_commitments &lt;- function(country) {\n  get_gcdf3_dataset() |&gt; \n    calculate_yearly_commitments(country) |&gt; \n    summarize(total = sum(amount_constant_usd_2021_bn)) |&gt; \n    pull(total)\n}\n\n# Then use it with map_dbl\n# map_dbl(data to work with, function to apply)\nmap_dbl(\n  your_countries,        # First argument: list of countries\n  get_total_commitments  # Second argument: what to do with each country\n)\n\n[1] 28.94673 55.18729 21.56447\n\n\n\n\n\n\n\n\nGetting Help from AI\n\n\n\nTry this prompt to understand map functions better:\n\"I'm new to R and trying to understand this code. Can you explain what map_dbl does and how it's different from a regular for loop?\n\n```{r}\namounts &lt;- c(1000000000, 2000000000, 3000000000)\nmap_dbl(amounts, to_billions)\n```\n\n\n\n\n2.10.6 Next Steps\nNow that we can easily work with multiple countries at once, we’re ready to learn how to generate automated reports. The same principles we just learned about doing things repeatedly will help us create professional reports for any country with just a few lines of code!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: Getting Started (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_1_in_class.html#creating-reports-for-multiple-countries",
    "href": "week_1_in_class.html#creating-reports-for-multiple-countries",
    "title": "2  Week 1: Getting Started (In-Class)",
    "section": "2.11 Creating Reports for Multiple Countries",
    "text": "2.11 Creating Reports for Multiple Countries\n\n2.11.1 The Problem: Manual Report Creation\nImagine your boss asks for reports on Chinese development finance in:\n\nAll countries in Southeast Asia\nEvery country with commitments over $1 billion\nThe top 10 recipient countries\n\nWithout automation, you’d need to:\n\nCopy your Quarto template\nChange the country name in multiple places\nRender each report separately\nKeep track of all the files\n\nLet’s automate this!\n\n\n2.11.2 Step 1: Save Our Functions\nFirst, let’s save our functions in week_1/R/functions.R:\n\n# week_1/R/functions.R\n\n# Convert to billions for readability\nto_billions &lt;- function(amount) {\n  amount / 10^9\n}\n\n# Calculate yearly commitments for a country\ncalculate_yearly_commitments &lt;- function(data, country) {\n  data |&gt; \n    filter(\n      recommended_for_aggregates == \"Yes\",\n      country_name == country\n    ) |&gt; \n    group_by(\n      commitment_year,\n      flow_class\n    ) |&gt; \n    summarize(\n      amount_constant_usd_2021_bn = sum(\n        amount_constant_usd_2021, \n        na.rm = TRUE\n      ) |&gt; \n        to_billions(),\n      .groups = \"drop\"\n    )\n}\n\n# Create visualization\nplot_loan_commitments &lt;- function(data, country) {\n  data |&gt; \n    ggplot(\n      aes(\n        x = commitment_year, \n        y = amount_constant_usd_2021_bn,\n        fill = flow_class\n      )\n    ) +\n    geom_col() +\n    labs(\n      title = str_glue(\"Chinese Development Finance Commitments to {country}\"),\n      subtitle = \"By Flow Class, 2000-2021\",\n      x = \"Commitment Year\",\n      y = \"Commitments (Constant 2021 USD, Billions)\",\n      fill = \"Flow Class\"\n    ) +\n    theme_minimal() +\n    scale_fill_brewer(palette = \"Set2\")\n}\n\n\n\n2.11.3 Step 2: Create a Report Template\nNow create a new file called week_1/R/country_report.qmd:\n---\ntitle: \"Chinese Development Finance in `{r} params$country`\"\nauthor: \"Your Name\"\ndate: today\nformat: \n  html:\n    theme: cosmo\n    toc: true\n    embed-resources: true\nparams:\n  country: \"Angola\"  # Default country\n---\n\n\n\n\n\n\nTip\n\n\n\nThe params: section is like fill-in-the-blanks for our report. We can change these values when we render the report.\n\n\nAdd this content to the report template:\n```{r}\n#| label: setup\n#| include: false\n\n# Load required packages\nlibrary(tidyverse)\nlibrary(chinadevfin3)\nlibrary(glue)\nlibrary(here)\n\n# Load our functions\nsource(here::here(\"week_1\", \"R\", \"functions.R\"))\n```\n\n## Overview\n\nThis report analyzes Chinese development finance commitments to `{r} params$country`.\n\n## Visualization\n\n```{r}\n#| label: commitments-plot\nget_gcdf3_dataset() |&gt; \n  calculate_yearly_commitments(params$country) |&gt; \n  plot_loan_commitments(params$country)\n```\n\n## Summary Statistics\n\n```{r}\n#| label: summary-stats\ncommitments &lt;- get_gcdf3_dataset() |&gt; \n  calculate_yearly_commitments(params$country)\n\ntotal_commitment &lt;- commitments |&gt; \n  summarize(total = sum(amount_constant_usd_2021_bn)) |&gt; \n  pull(total) |&gt; \n  round(2)\n```\n\nTotal commitments to `{r} params$country` from 2000-2021: \n$`{r} total_commitment` billion (2021 USD)\n\n\n\n\n\n\nThe {here} Package: Making File Paths Work Everywhere\n\n\n\nEver tried opening someone else’s R project and gotten errors like “file not found” even though you can see the file right there? This happens because of absolute file paths like:\n\nWindows: \"C:/Users/YourName/Documents/Project/data.csv\"\nMac: \"/Users/YourName/Documents/Project/data.csv\"\n\nThese paths only work on the original computer! Even relative paths like \"../data/file.csv\" can break if you:\n\nOpen your project from a different folder\nShare your code with colleagues\nMove your files around\n\nThe {here} package solves this by:\n\nAutomatically finding your project root folder\nBuilding file paths that work everywhere\n\nInstead of:\nsource(\"../R/functions.R\")  # Fragile!\nUse:\nsource(here::here(\"week_1\", \"R\", \"functions.R\"))  # Robust!\nThis works regardless of:\n\nWhat computer you’re on\nWhere you opened the project\nWhat your working directory is\n\n\n\n\n\n2.11.4 Step 3: Create a Rendering Script\nCreate a new file called week_1/R/render_reports.R:\n\n# week_1/R/render_reports.R\nlibrary(tidyverse)  # For data manipulation and pipe operator\nlibrary(quarto)     # For rendering Quarto documents\nlibrary(here)       # For reliable file paths\nlibrary(withr)     # For safe working with file paths\nlibrary(fs)         # For file system operations\n\n# List of countries to analyze\nsea_countries &lt;- c(\n  \"Vietnam\", \n  \"Indonesia\", \n  \"Thailand\", \n  \"Malaysia\"\n)\n\n# Function to render a report for one country\nrender_country_report &lt;- function(country) {\n  # Create output directory if it doesn't exist\n  output_dir &lt;- here::here(\"week_1\", \"outputs\")\n  dir_create(output_dir)\n  \n  # We'll use withr::with_dir() instead of setwd()\n  # It automatically restores the working directory when done\n  withr::with_dir(\n    here::here(\"week_1\", \"R\"),\n    {\n      # Render the Quarto document\n      quarto::quarto_render(\n        input = \"country_report.qmd\",\n        output_file = str_glue(\"{country}_analysis.html\"),\n        execute_params = list(country = country)\n      )\n      \n      # Move the rendered file to outputs directory\n      file_move(\n        path = str_glue(\"{country}_analysis.html\"),\n        new_path = path(output_dir, str_glue(\"{country}_analysis.html\"))\n      )\n    }\n  )\n}\n\n# Create a safer version of our render function that won't error\nsafe_render &lt;- possibly(\n  render_country_report,\n  otherwise = \"Failed to render report\" # What to return if there's an error\n)\n\n# Generate reports and capture results\nresults &lt;- map(\n  sea_countries,\n  safe_render\n)\n\n# Check for any failures\nfailed_countries &lt;- sea_countries[results == \"Failed to render report\"]\nif (length(failed_countries) &gt; 0) {\n  message(\"Failed to render reports for: \", str_c(failed_countries, collapse = \", \"))\n}\n\n\n\n2.11.5 Step 4: Generate Reports\n\nOpen week_1/R/render_reports.R in RStudio\nClick “Source” (or press Cmd/Ctrl + Shift + S)\nCheck week_1/outputs/ for your generated reports!\n\nYou should see:\n\nvietnam_analysis.html\nindonesia_analysis.html\nthailand_analysis.html\nmalaysia_analysis.html\n\n\n\n2.11.6 Real-World Applications\nThis approach is incredibly powerful for:\n\nRegular Reporting\n\nWeekly/monthly/quarterly updates\nReports for different stakeholders\nCountry monitoring\n\nAd Hoc Analysis\n\nQuick responses to specific requests\nComparative analysis across regions\nDeep dives into specific countries\n\nQuality Control\n\nConsistent analysis across reports\nEasy to spot unusual patterns\nReproducible results\n\n\n\n\n2.11.7 Practice Time\nLet’s try some exercises:\n\nAdd a new visualization to country_report.qmd\nGenerate reports for a different set of countries\nAdd more summary statistics to the report\n\n\n\n\n\n\n\nFile Organization\n\n\n\nRemember:\n\nR scripts and Quarto documents go in R/\nGenerated reports go in outputs/\nUse relative paths (like \"R/functions.R\" and \"../outputs/\")",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: Getting Started (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_1_in_class.html#wrapping-up-the-cool-things-first-approach",
    "href": "week_1_in_class.html#wrapping-up-the-cool-things-first-approach",
    "title": "2  Week 1: Getting Started (In-Class)",
    "section": "2.12 Wrapping up: The Cool Things First Approach",
    "text": "2.12 Wrapping up: The Cool Things First Approach\nThe data science workflow typically follows these steps:\n\nGet Data: Import and clean your data\nTransform Data: Calculate summaries and find patterns\nCommunicate: Create visualizations and reports\n\nLook at our analysis pipeline:\n\nget_gcdf3_dataset() |&gt;                     # Step 1: Get Data\n  calculate_yearly_commitments(\"Angola\") |&gt; # Step 2: Transform\n  plot_loan_commitments(\"Angola\")          # Step 3: Communicate\n\n\n\n\n\n\n\n\nBut here’s the twist: we’re learning these steps in reverse! Why?\n\nWeek 1 & 2: Communication (Reporting & Data Visualization)\n\nBecause seeing your results is exciting!\nCreates motivation to learn the underlying steps\n\nWeek 3: Data Transformation\n\nNow that we know what we want to show, we’ll learn how to wrangle data into shape\nFind actionable insights from dirty real world data\n\nWeek 4: Data Import & Cleaning\n\nThe foundation of all good analysis\nLLMs make data cleaning much easier\n\n\n\n\n\n\n\ngraph TB\n    %% Standard Workflow\n    subgraph Traditional[\"Data Science Workflow\"]\n        A(\"Get Data&lt;br&gt;(Import & Clean)\") --&gt; B(\"Transform Data&lt;br&gt;(Analyze & Summarize)\")\n        B --&gt; C(\"Communicate&lt;br&gt;(Visualize & Report)\")\n    end\n    \n    %% Our Learning Path\n    subgraph Course[\"Our Learning Path\"]\n        direction TB\n        W1(\"Week 1:&lt;br&gt;Introduction to Quarto&lt;br&gt;(Professional Reports)\")\n        W2(\"Week 2:&lt;br&gt;Data Visualization&lt;br&gt;(The Fun Part!)\")\n        W3(\"Week 3:&lt;br&gt;Data Transformation&lt;br&gt;(Making Data Useful)\")\n        W4(\"Week 4:&lt;br&gt;Data Import & Cleaning&lt;br&gt;(Building Strong Foundations)\")\n        W1 --&gt; W2\n        W2 --&gt; W3\n        W3 --&gt; W4\n    end\n\n    %% Connecting arrow with explanation\n    C -..-&gt; W1\n    \n    %% Styles for better visualization - now with fill colors\n    style A fill:#fff3e0,stroke:#f57c00,stroke-width:2px\n    style B fill:#e3f2fd,stroke:#1976d2,stroke-width:2px\n    style C fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px\n    \n    style W1 fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px\n    style W2 fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px\n    style W3 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px\n    style W4 fill:#fff3e0,stroke:#f57c00,stroke-width:2px\n\n\n\n\n\n\nThis cool things first approach helps you:\n\nSee the value of R immediately\nBuild motivation through quick wins\nUnderstand why each step matters\nProvides the motivation to learn the details of why code works",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: Getting Started (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_1_in_class.html#wrapping-up-what-weve-accomplished",
    "href": "week_1_in_class.html#wrapping-up-what-weve-accomplished",
    "title": "2  Week 1: Getting Started (In-Class)",
    "section": "2.13 Wrapping Up: What We’ve Accomplished",
    "text": "2.13 Wrapping Up: What We’ve Accomplished\n\n2.13.1 Today’s Achievements\nLet’s look back at what we’ve accomplished in just 90 minutes:\n\nGetting Comfortable with RStudio\n\nSet up an organized project structure\nLearned to navigate the RStudio interface\nCreated our first R scripts and Quarto documents\n\nTaking First Steps with Quarto\n\nCreated our first Quarto document\nCombined code, text, and visualizations\nGenerated reports in multiple formats\n\nBuilding Efficiency Tools\n\nWrote our first function to avoid repetitive work\nUsed map functions to process multiple countries\nCreated a parameterized report template\n\n\nMost importantly, you’ve seen how these tools can make your work at AidData more efficient and reproducible. While it takes time to master these skills, you now have working examples that you can build upon and adapt for your own analysis needs.\n\n\n2.13.2 Resources for Continued Learning\n\n2.13.2.1 R Fundamentals\nEven with AI assistance, a solid foundation in R basics will make you much more effective. Here are some excellent starting points:\n\nInteractive Learning\n\nDataCamp’s Free Introduction to R\n\nRecommended starting point\nCovers essential R concepts\nInteractive exercises with immediate feedback\n\n\nVideo Tutorial\n\nR Programming Crash Course (1 hour)\n\nQuick overview of key concepts\nGood for visual learners\nCovers most common operations\n\n\n\n\n\n2.13.2.2 Quarto Documentation & Tutorials\n\nOfficial Resources\n\nQuarto Documentation\n\nComprehensive reference\nMany examples and tutorials\n\nGetting Started with Quarto (Video)\n\nExcellent visual introduction\nShows Quarto in action\n\n\nBook Chapters\n\nR for Data Science (2e):\n\nChapter 29: Quarto\nChapter 30: Quarto Formats\n\n\n\n\n\n2.13.2.3 Functions & Iteration\n\nR for Data Science Chapters\n\nWriting Functions\n\nComprehensive guide to function writing\nBest practices and examples\n\nIteration\n\nDeep dive into map functions\nPractical examples\n\n\nAdditional Resources\n\npurrr documentation\n\nReference for map functions\nComprehensive examples\n\nWalk This Way: A gentle introduction to purrr\n\nBeginner-friendly blog post\nClear explanations and examples\n\n\n\n\n\n\n2.13.3 Next Steps\n\nPractice with Your Own Data\n\nTry modifying today’s examples for your specific needs\nStart small - maybe automate one regular task\nUse AI tools to help understand and adapt code\n\nPrepare for Next Week\n\nWe’ll dive deeper into data visualization\nFocus on creating compelling graphics for Chinese development finance data\nBuild on the foundations we’ve established today\n\nGet Help When Needed\n\nUse AI tools (Claude, ChatGPT) for code explanation\nReference the resources above\nAsk questions in our course forum\nShare challenges and solutions with colleagues\n\n\nRemember: Learning R is a journey. You don’t need to memorize everything - knowing where to find help is often more important than memorizing syntax. Focus on understanding the concepts and how they can make your work easier and more reproducible.\nSee you next week!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 1: Getting Started (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_pre_class.html",
    "href": "week_2_pre_class.html",
    "title": "3  Week 2: Make Cool Charts, Right Away (Pre-Class)",
    "section": "",
    "text": "3.1 Overview\nThis pre-class preparation should take about 45 minutes to complete.\nBefore we dive into code, let’s understand what we’re about to learn. {ggplot2} is an incredibly powerful data visualization tool used by data journalists at the Financial Times, The Economist, and other leading publications. With it, you can create virtually any visualization you can imagine - from simple scatter plots to complex, publication-ready graphics. And it’s completely free.\nWhile it takes practice to create professional-level visualizations, the basics are surprisingly accessible. The secret lies in understanding ggplot2’s underlying system: the Grammar of Graphics. Just as you can create endless sentences from basic grammar rules, you can create endless visualizations by combining basic graphical elements.\nToday, we’ll start by building this intuition. Instead of getting bogged down in syntax, we’ll use a point-and-click interface called Esquisse to create increasingly sophisticated visualizations. As we do this, we’ll examine the code it generates to understand how ggplot2 builds plots layer by layer.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_pre_class.html#overview",
    "href": "week_2_pre_class.html#overview",
    "title": "3  Week 2: Make Cool Charts, Right Away (Pre-Class)",
    "section": "",
    "text": "3.1.1 Video Lecture\nWatch this video lecture before our interactive session:",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_pre_class.html#learning-objectives",
    "href": "week_2_pre_class.html#learning-objectives",
    "title": "3  Week 2: Make Cool Charts, Right Away (Pre-Class)",
    "section": "3.2 Learning Objectives",
    "text": "3.2 Learning Objectives\nBy completing this pre-class work, you will:\n\nLearn to create visualizations using Esquisse’s point-and-click interface\nUnderstand how ggplot2 builds plots by layering:\n\nData\nGeometric shapes (points, lines, bars)\nVisual mappings (color, size, position)\nScales\nLabels and themes\n\nKnow where to find help and resources for continued learning\n\n\n\n\n\n\n\nUsing AI to Learn ggplot2\n\n\n\nLarge Language Models (LLMs) like ChatGPT and Claude are excellent learning companions for ggplot2. You can:\n\nGet Code Explanations:\n# Ask: \"Can you explain what each line of this code does?\"\nggplot(data) +\n  aes(x = year, y = amount) +\n  geom_point()\nUnderstand Concepts:\n\n\n“Why do we use + instead of |&gt; in ggplot2?”\n“What’s the difference between color and fill?”\n“When should I use geom_bar() vs geom_col()?”\n\n\nGet Visualization Suggestions:\n\n\n“I want to show the distribution of project sizes by region. What’s the best way to visualize this?”\n“How can I make this plot more readable?”\n\n\nDebug Issues:\n\n\nShare your code and error messages\nAsk for suggestions to improve your plots",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_pre_class.html#setup",
    "href": "week_2_pre_class.html#setup",
    "title": "3  Week 2: Make Cool Charts, Right Away (Pre-Class)",
    "section": "3.3 Setup",
    "text": "3.3 Setup\nLet’s get our workspace ready. First, create a new Quarto file to use as your lab notebook:\n\nIn RStudio, click File → New File → Quarto Document\nSave it as week_2_visualization_preclass.qmd in your week_2/R folder\n\nNext, we’ll install Esquisse, a tool that will help us learn ggplot2 visually:\n\npak::pkg_install(\"esquisse\")\n\nNow load the packages we’ll need:\n\nlibrary(tidyverse)    # Core data science tools, including ggplot2\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(chinadevfin3) # GCDF 3.0 data\nlibrary(esquisse)     # ggplot2 point-and-click interface",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_pre_class.html#create-an-initial-dataset",
    "href": "week_2_pre_class.html#create-an-initial-dataset",
    "title": "3  Week 2: Make Cool Charts, Right Away (Pre-Class)",
    "section": "3.4 Create An Initial Dataset",
    "text": "3.4 Create An Initial Dataset\nBefore we start visualizing, let’s prepare some interesting data to work with. The code below creates a dataset that combines project sizes, data quality scores, and other features that might help us understand patterns in Chinese development finance.\nDon’t worry if the data preparation code looks complex - in Week 3, you’ll learn how to transform data like this. For now, just run the code:\n\n# Helper function from Week 1\nto_billions &lt;- function(amount) {\n  amount / 10^9\n}\n\n# Create dataset for exploring project characteristics\ngcdf_project_features &lt;- get_gcdf3_dataset() |&gt;\n  filter(\n    recommended_for_aggregates == \"Yes\",\n    !is.na(source_quality_score), \n    !is.na(data_completeness_score)\n  ) |&gt;\n  mutate(\n    total_amount_bn = to_billions(amount_constant_usd_2021),\n    data_quality = source_quality_score + data_completeness_score\n  ) |&gt;\n  select(\n    total_amount_bn,\n    data_quality,\n    flow_class,\n    commitment_year,\n    total_source_count\n  )\n\ngcdf_project_features\n\n# A tibble: 17,957 × 5\n   total_amount_bn data_quality flow_class commitment_year total_source_count\n             &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;                &lt;int&gt;              &lt;int&gt;\n 1         0.00711            8 ODA-like              2021                  7\n 2         0.0126             8 ODA-like              2021                  9\n 3         0.0144             7 ODA-like              2021                  2\n 4         0.013              9 ODA-like              2021                 11\n 5         0.0075             9 ODA-like              2021                  5\n 6        NA                  6 ODA-like              2021                  1\n 7         0.0036             7 ODA-like              2021                 10\n 8        NA                  6 ODA-like              2021                  1\n 9        NA                  6 ODA-like              2021                  2\n10        NA                  6 ODA-like              2021                  1\n# ℹ 17,947 more rows\n\n\n\n\n\n\n\n\nTip\n\n\n\nCurious what this code does? Paste it into ChatGPT or Claude and ask them to explain it step by step. Understanding data preparation will be important later, but for now, let’s focus on visualization!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_pre_class.html#building-your-first-visualization",
    "href": "week_2_pre_class.html#building-your-first-visualization",
    "title": "3  Week 2: Make Cool Charts, Right Away (Pre-Class)",
    "section": "3.5 Building Your First Visualization",
    "text": "3.5 Building Your First Visualization\nLet’s start by exploring some interesting relationships in Chinese development finance data. Does project size relate to data quality? Do different types of flows show different patterns? We’ll build a visualization step by step to find out.\n\n3.5.1 Step 1: Basic Scatter Plot\n\nIn RStudio, click Addins → ggplot2 builder (Esquisse)\n\n\n\nWhen prompted, select gcdf_project_features as your dataset\n\n\n\nLet’s create a basic scatter plot to start exploring relationships:\n\n\nDrag data_quality to x-axis\nDrag total_amount_bn to y-axis\nClick “Point” as the chart type in the top left\n\n\n\nAt the bottom of the Esquisse window, click “Code” to see what ggplot2 code creates this plot\n\n\nCopy and run this code in your Quarto document:\n\nggplot(gcdf_project_features) +\n  aes(x = data_quality, y = total_amount_bn) +\n  geom_point(colour = \"#112446\") +\n  theme_minimal()\n\nWarning: Removed 7286 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nYou’ve just created your first ggplot2 visualization! While simple, this already shows us something interesting: there seems to be a relationship between project size and data quality. Let’s make this visualization more informative by adding more dimensions to our data.\n\n\n\n\n\n\nAbout Those Warnings\n\n\n\nYou’ll see warnings like this:\nWarning: Removed 7286 rows containing missing values or values outside the scale range (`geom_point()`).\nDon’t worry! This just means some projects had missing data or values that couldn’t be plotted. This is normal when working with real-world data, especially financial data where we often have incomplete information.\nIf you want to hide these warnings in your documents, add this to the top of your code chunk:\n#| warning: false\nFor example:\n```{r}\n#| warning: false\nggplot(gcdf_project_features) +\n  aes(x = data_quality, y = total_amount_bn) +\n  geom_point()\n```\n\n\n\n\n3.5.2 Step 2: Add Color by Flow Class\n\n\n\n\n\n\nA Smoother Workflow\n\n\n\nNow that you understand how to use Esquisse, stay in the Esquisse window as we add features. Each time we enhance our plot: 1. Make the change in Esquisse 2. Look at the code it generates (using the Code button) 3. Compare it to our code examples & outputs below\nThis way you can experiment freely without having to restart Esquisse for each change. All the code is in this document for when you want to recreate these visualizations later.\n\n\nIn Esquisse, drag flow_class to the color box. When you do this, notice how the code changes:\n\n#|warning: false\nggplot(gcdf_project_features) +\n  aes(\n    x = data_quality,\n    y = total_amount_bn,\n    colour = flow_class\n  ) +\n  geom_point() +\n  scale_color_hue(direction = 1) +\n  theme_minimal()\n\nWarning: Removed 7286 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nNotice how color = flow_class was added inside aes(). In ggplot2, aes() is where we map data variables to visual properties. Now our plot reveals not just the relationship between project size and data quality, but also shows how different types of flows (ODA-like, OOF-like, etc.) might have different patterns.\n\n\n3.5.3 Step 3: Size by Source Count\nLet’s add another dimension by varying point sizes. In Esquisse, drag total_source_count to the size box. The code will now look like this:\n\n#|warning: false\nggplot(gcdf_project_features) +\n  aes(\n    x = data_quality,\n    y = total_amount_bn,\n    colour = flow_class,\n    size = total_source_count\n  ) +\n  geom_point() +\n  scale_color_hue(direction = 1) +\n  theme_minimal()\n\nWarning: Removed 7286 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nOur visualization now shows several relationships simultaneously: - Data quality (x-axis) - Project size (y-axis) - Number of sources (point size) - Flow class (color)\nLook at how larger dots tend to appear toward the right side of the plot. This suggests that projects with more sources tend to have better documentation. That makes sense.\n\n\n3.5.4 Step 4: Dealing with Overlapping Points\nYou might notice that many points overlap, especially at certain data quality scores. This happens because our data quality scores are whole numbers (0-10), so many projects have exactly the same score.\nIn Esquisse, look at the different geometry options on the left. Instead of the regular point plot, try the “jitter” option. This adds small random offsets to each point, making overlapping points visible. Here’s the code it generates:\n\n#|warning: false\nggplot(gcdf_project_features) +\n  aes(\n    x = data_quality,\n    y = total_amount_bn,\n    colour = flow_class,\n    size = total_source_count\n  ) +\n  geom_jitter() +\n  scale_color_hue(direction = 1) +\n  theme_minimal()\n\nWarning: Removed 7286 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is jittering?\n\n\n\ngeom_jitter() adds a small amount of random noise to each point’s position. This helps us see overlapping points without changing the fundamental patterns in our data. It’s particularly useful when you have: - Whole number data (like our quality scores) - Many observations with the same values - Dense clusters of points\n\n\n\n\n3.5.5 Step 5: Adding Clear Labels\nNow let’s make our plot more informative for our audience. In Esquisse’s “Labels & Title” tab, add these labels: - Title: “Larger Chinese Development Projects Have Better Documentation” - X-axis: “Data Quality Score” - Y-axis: “Project Size (2021 USD, Billions)” - Color legend: “Flow Class” - Size legend: “Number of Sources”\nThe code will now include proper labels:\n\n#|warning: false\nggplot(gcdf_project_features) +\n  aes(\n    x = data_quality,\n    y = total_amount_bn,\n    colour = flow_class,\n    size = total_source_count\n  ) +\n  geom_jitter() +\n  scale_color_hue(direction = 1) +\n  labs(\n    x = \"Data Quality Score\",\n    y = \"Project Size (2021 USD, Billions)\",\n    title = \"Larger Chinese Development Projects Have Better Documentation\",\n    color = \"Flow Class\",\n    size = \"Number of Sources\"\n  ) +\n  theme_minimal()\n\nWarning: Removed 7286 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n3.5.6 Step 6: Making Project Sizes More Visible\nOur plot still has a challenge: the huge range in project sizes (from millions to billions) makes it hard to see patterns. Small projects cluster at the bottom while large projects stretch the y-axis. This is a common issue when values span several orders of magnitude.\nWe can fix this using a logarithmic scale. In Esquisse’s “Axes” tab, look for the y-axis options and select “log10”. Here’s what the code looks like:\n\n#|warning: false\nggplot(gcdf_project_features) +\n  aes(\n    x = data_quality,\n    y = total_amount_bn,\n    colour = flow_class,\n    size = total_source_count\n  ) +\n  geom_jitter() +\n  scale_color_hue(direction = 1) +\n  scale_y_continuous(trans = \"log10\") +\n  labs(\n    x = \"Data Quality Score\",\n    y = \"Project Size (2021 USD, Billions, Log Scale)\",\n    title = \"Larger Chinese Development Projects Have Better Documentation\",\n    color = \"Flow Class\",\n    size = \"Number of Sources\"\n  ) +\n  theme_minimal()\n\nWarning: Removed 7286 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy Use Log Scales?\n\n\n\nLog scales are perfect for data that spans several orders of magnitude. They help us see patterns across both small and large values. In Chinese lending, where projects can range from $1 million to $10 billion, log scales are essential for clear visualization.\nNotice how the pattern is much clearer now: larger projects (higher on the y-axis) tend to have higher data quality scores (further right), regardless of flow class.\n\n\n\n\n3.5.7 Step 7: Changing the Look\nFinally, let’s try a different theme. In Esquisse’s Theme tab, switch from “minimal” to “gray”. This will give us a slightly different look:\n\n#|warning: false\nggplot(gcdf_project_features) +\n  aes(\n    x = data_quality,\n    y = total_amount_bn,\n    colour = flow_class,\n    size = total_source_count\n  ) +\n  geom_jitter() +\n  scale_color_hue(direction = 1) +\n  scale_y_continuous(trans = \"log10\") +\n  labs(\n    x = \"Data Quality Score\",\n    y = \"Project Size (2021 USD, Billions, Log Scale)\",\n    title = \"Larger Chinese Development Projects Have Better Documentation\",\n    color = \"Flow Class\",\n    size = \"Number of Sources\"\n  ) +\n  theme_gray()\n\nWarning: Removed 7286 rows containing missing values or values outside the scale range\n(`geom_point()`).",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_pre_class.html#understanding-the-grammar-of-graphics",
    "href": "week_2_pre_class.html#understanding-the-grammar-of-graphics",
    "title": "3  Week 2: Make Cool Charts, Right Away (Pre-Class)",
    "section": "3.6 Understanding the Grammar of Graphics",
    "text": "3.6 Understanding the Grammar of Graphics\nWhat we’ve just created illustrates a powerful idea in data visualization: the Grammar of Graphics. Just as English grammar gives us rules for combining words into meaningful sentences, the Grammar of Graphics gives us rules for combining visual elements into meaningful plots.\nLet’s break down our final visualization to understand each component:\n\n#|warning: false\nggplot(gcdf_project_features) +                    # 1. Start with data\n  aes(                                             # 2. Map data to visuals\n    x = data_quality,                              #    - x position\n    y = total_amount_bn,                           #    - y position\n    colour = flow_class,                           #    - color\n    size = total_source_count                      #    - size\n  ) +\n  geom_jitter() +                                  # 3. Choose how to display\n  scale_color_hue(direction = 1) +                 # 4. Adjust scales\n  scale_y_continuous(trans = \"log10\") +            #    - log scale for y\n  labs(                                            # 5. Add labels\n    x = \"Data Quality Score\",\n    y = \"Project Size (2021 USD, Billions)\",\n    title = \"Larger Chinese Development Projects Have Better Documentation\",\n    color = \"Flow Class\",\n    size = \"Number of Sources\"\n  ) +\n  theme_gray()                                     # 6. Choose overall look\n\nWarning: Removed 7286 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThink of each component as answering a specific question:\n\nData: What are we visualizing?\n\nggplot(gcdf_project_features)\nLike choosing your ingredients before cooking\n\nAesthetics: How should data map to visual properties?\n\naes(x = ..., y = ..., colour = ..., size = ...)\nLike assigning roles to your ingredients\n\nGeometries: What shapes should represent our data?\n\ngeom_jitter()\nLike choosing how to prepare your ingredients\n\nScales: How should values convert to visual properties?\n\nscale_y_continuous(trans = \"log10\")\nLike adjusting cooking temperature and time\n\nLabels: How do we explain what we’re showing?\n\nlabs(title = ..., x = ..., y = ...)\nLike writing the recipe name and instructions\n\nTheme: What should the overall look be?\n\ntheme_gray()\nLike choosing the serving dish and presentation\n\n\nUnderstanding this grammar is powerful because:\n\nYou can create any visualization by combining these elements\nChanges are as simple as modifying one component\nThe same principles work for any type of plot\n\n\n\n\n\n\n\nWhy Does ggplot2 Use + Instead of |&gt;?\n\n\n\nYou might wonder why ggplot2 uses + to combine elements instead of the pipe operator (|&gt;) we use elsewhere. This reflects R’s evolution as a living language:\n\nggplot2 was created in 2005, long before the pipe operator existed\nThe + operator was chosen because plots are built by adding layers\nBy the time the pipe became popular, too much code already used +\nChanging it would break thousands of existing scripts\n\nThis is a great example of how programming languages evolve while maintaining backwards compatibility.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_pre_class.html#the-tip-of-the-iceberg",
    "href": "week_2_pre_class.html#the-tip-of-the-iceberg",
    "title": "3  Week 2: Make Cool Charts, Right Away (Pre-Class)",
    "section": "3.7 The Tip of the Iceberg",
    "text": "3.7 The Tip of the Iceberg\nUnderstanding this grammar gives you access to ggplot2’s full power. Let’s look at some common visualization needs in Chinese development finance analysis. First, we’ll prepare some useful datasets:\n\n# Annual flow data\ngcdf_annual_flows &lt;- get_gcdf3_dataset() |&gt;\n  filter(recommended_for_aggregates == \"Yes\") |&gt;\n  group_by(commitment_year, flow_class) |&gt;\n  summarize(\n    total_amount_bn = sum(amount_constant_usd_2021, na.rm = TRUE) |&gt; \n      to_billions(),\n    .groups = \"drop\"\n  )\n\n# Add cumulative amounts\ngcdf_annual_flows &lt;- gcdf_annual_flows |&gt;\n  group_by(flow_class) |&gt;\n  mutate(\n    cumulative_amount_bn = cumsum(total_amount_bn)\n  ) |&gt;\n  ungroup()\n\n# Project-level data\ngcdf_projects &lt;- get_gcdf3_dataset() |&gt;\n  filter(recommended_for_aggregates == \"Yes\") |&gt;\n  mutate(\n    amount_constant_usd_2021_bn = to_billions(amount_constant_usd_2021)\n  )\n\nNow let’s see different ways to visualize this data using the grammar we’ve learned.\n\n3.7.1 Chart Types and Their Geometries\nThink of geometries (geom_*) as different ways to draw your data. Here are some you’ll commonly use at AidData:\nTime Series (showing lending trends):\n\n# Stacked bar chart of annual lending by flow class\nggplot(gcdf_annual_flows) + \n  aes(x = commitment_year, \n      y = total_amount_bn,\n      fill = flow_class) +\n  geom_col() +\n  labs(\n    title = \"Chinese Development Finance Over Time\",\n    x = \"Year\",\n    y = \"Amount (2021 USD, Billions)\",\n    fill = \"Flow Class\"\n  ) +\n  theme_gray()\n\n\n\n\n\n\n\n# Line plot showing cumulative amounts\nggplot(gcdf_annual_flows) +\n  aes(x = commitment_year, \n      y = cumulative_amount_bn,\n      color = flow_class) +\n  geom_line(linewidth = 1) +\n  labs(\n    title = \"Cumulative Chinese Development Finance\",\n    x = \"Year\",\n    y = \"Cumulative Amount (2021 USD, Billions)\",\n    color = \"Flow Class\"\n  ) +\n  theme_gray()\n\n\n\n\n\n\n\n\nDistributions (understanding project size patterns):\n\n# Histogram of project sizes\nggplot(gcdf_projects) +\n  aes(x = amount_constant_usd_2021_bn) +\n  geom_histogram(bins = 50) +\n  scale_x_log10() +\n  labs(\n    title = \"Distribution of Chinese Development Finance Project Sizes\",\n    x = \"Project Size (2021 USD, Billions, Log Scale)\",\n    y = \"Number of Projects\"\n  ) +\n  theme_gray()\n\nWarning: Removed 7286 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n# Box plots comparing flow types\nggplot(gcdf_projects) +\n  aes(x = flow_class, y = amount_constant_usd_2021_bn) +\n  geom_boxplot() +\n  scale_y_log10() +\n  labs(\n    title = \"Project Sizes by Flow Class\",\n    x = \"Flow Class\",\n    y = \"Project Size (2021 USD, Billions, Log Scale)\"\n  ) +\n  theme_gray() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nWarning: Removed 7286 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhich Chart When?\n\n\n\nFor time series: - Use geom_col() to show yearly totals - Use geom_line() to show trends or cumulative values\nFor distributions: - Use geom_histogram() to see overall patterns - Use geom_boxplot() to compare across categories - Remember to consider log scales for financial data!\n\n\n\n\n3.7.2 Making Adjustments with Scales\nScales control how your data translates to visual properties. For Chinese development finance data, here are some essential scale adjustments:\n\n# Better handling of wide-ranging financial values\nggplot(gcdf_projects) +\n  aes(x = commitment_year, y = amount_constant_usd_2021_bn) +\n  geom_point(alpha = 0.5) +\n  scale_y_continuous(\n    trans = \"log10\",\n    labels = scales::label_number(prefix = \"$\", suffix = \"B\")\n  ) +\n  labs(\n    title = \"Project Sizes Over Time\",\n    y = \"Amount (2021 USD, Log Scale)\"\n  ) +\n  theme_gray()\n\nWarning: Removed 7286 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n# Color-blind friendly palettes for flow types\nggplot(gcdf_annual_flows) + \n  aes(x = commitment_year, \n      y = total_amount_bn,\n      fill = flow_class) +\n  geom_col() +\n  scale_fill_brewer(palette = \"Set2\") +  # Color-blind friendly\n  labs(title = \"Using Color Brewer Palettes\") +\n  theme_gray()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCommon Scale Adjustments\n\n\n\n\nUse scale_y_log10() for financial amounts of multiple orders of magnitude\nUse scale_fill_brewer() or scale_color_brewer() for categorical variables\nUse scale_*_continuous(limits = ...) to focus on specific ranges\n\n\n\n\n\n3.7.3 Setting the Look with Themes\nThemes control the overall appearance. Different contexts need different looks:\nFirst, we’ll install {ggthemes}, a ggplot2 extension package, which provides extra themes.\n\n# First, install ggthemes\npak::pkg_install(\"ggthemes\")\n\n\n# Load ggthemes\nlibrary(ggthemes)\n\n# Create a base plot to try different themes\nbase_plot &lt;- ggplot(gcdf_annual_flows) + \n  aes(x = commitment_year, \n      y = total_amount_bn,\n      fill = flow_class) +\n  geom_col() +\n  labs(\n    title = \"Chinese Development Finance Over Time\",\n    subtitle = \"Annual Commitments by Flow Class\",\n    x = \"Year\",\n    y = \"Amount (2021 USD, Billions)\"\n  )\n\n# Like The Economist magazine\nbase_plot + \n  theme_economist() +\n  scale_fill_economist() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\n\n\n\n\n\n\n# Like the Wall Street Journal\nbase_plot + \n  theme_wsj() +\n  scale_fill_wsj() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n\n\n\n\n\n\n\n\nThese publication themes aren’t just for fun - they demonstrate how consistent visual styling helps build a publication’s brand. The Economist’s clean, professional look and the Wall Street Journal’s distinctive style are instantly recognizable to readers.\nThink about how this can apply to AidData.\n\n\n\n\n\n\nProfessional Publication Themes\n\n\n\nThe {ggthemes} package lets you mimic the style of major publications. While we might not use these for academic work, they’re: - Fun to play with - Great for presentations - Show how flexible ggplot2 can be - Demonstrate the power of consistent visual styling\n\n\n\n\n\n\n\n\nChoosing Themes\n\n\n\n\nUse theme_gray() (default) for exploration\nUse theme_minimal() for presentations\nUse theme_classic() or theme_bw() for publications\nRemember you can customize any theme with theme()",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_pre_class.html#resources-for-learning-more",
    "href": "week_2_pre_class.html#resources-for-learning-more",
    "title": "3  Week 2: Make Cool Charts, Right Away (Pre-Class)",
    "section": "3.8 Resources for Learning More",
    "text": "3.8 Resources for Learning More\nNow that you’ve seen the power of ggplot2, here are the key resources to help you keep learning:\n\n3.8.1 Essential References\n\nggplot2 cheatsheet\n\nTwo-page visual reference of ggplot2’s most useful features\nKeep this open while you work!\nPrint it and put it on your wall\n\nOfficial Documentation\n\nGetting Started with ggplot2: Clear introduction to core concepts\nComplete Function Reference: When you need details about specific functions\n\n\n\n\n3.8.2 Learning Resources\n\nData Visualization chapter in R for Data Science\n\nComprehensive introduction\nLots of examples\nFree online!\n\nVideo Tutorials\n\nBeautiful Charts with R & ggplot2 by Albert Rapp\nPerfect for learning by watching\nShows step-by-step process\n\n\n\n\n\n\n\n\nLearning Strategy\n\n\n\n\nStart simple - get something on the screen\nAdd complexity one layer at a time\nUse the cheatsheet to discover new features\nLook up details in the documentation when needed\nUse AI tools (like ChatGPT or Claude) to:\n\nExplain code you don’t understand\nSuggest improvements\nHelp debug issues",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_pre_class.html#next-steps",
    "href": "week_2_pre_class.html#next-steps",
    "title": "3  Week 2: Make Cool Charts, Right Away (Pre-Class)",
    "section": "3.9 Next Steps",
    "text": "3.9 Next Steps\nIn our class session, we’ll:\n\nReview any questions about the grammar of graphics\nPractice creating publication-ready visualizations\nWork with your own Chinese development finance questions\nLearn some advanced ggplot2 features\n\nRemember: The goal isn’t to memorize every option, but to understand the general approach to building visualizations layer by layer. With the grammar of graphics as your foundation, you can create any visualization you need!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_in_class.html",
    "href": "week_2_in_class.html",
    "title": "4  Week 2: Make Cool Charts, Right Away (In-Class)",
    "section": "",
    "text": "4.1 Learning Objectives\nBy the end of this session, you will be able to:",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_in_class.html#learning-objectives",
    "href": "week_2_in_class.html#learning-objectives",
    "title": "4  Week 2: Make Cool Charts, Right Away (In-Class)",
    "section": "",
    "text": "Create exploratory visualizations to understand patterns in Chinese development finance data\nLayer multiple aesthetic mappings to reveal complex relationships\nTransform exploratory visualizations into publication-ready graphics\nApply AidData’s visual style using the aiddataviz package\nUse AI tools effectively to assist with both exploration and polish",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_in_class.html#todays-agenda-90-minutes",
    "href": "week_2_in_class.html#todays-agenda-90-minutes",
    "title": "4  Week 2: Make Cool Charts, Right Away (In-Class)",
    "section": "4.2 Today’s Agenda (90 minutes)",
    "text": "4.2 Today’s Agenda (90 minutes)\n\nThe Two Purposes of Data Visualization (10 min)\n\nExploration vs. Communication\nThe power of visual thinking\nWhen to use each approach\n\nPart 1: Exploratory Data Visualization (35 min)\n\nIntroduction (5 min)\n\nThe value of quick, iterative visualization\nMaking lots of charts to find patterns\n\nDemo: Layering for Insight (15 min)\n\nCase study: Interest rates and commitment size\nAdding variables through aesthetic mappings\nUsing AI to suggest visualization approaches\n\nInteractive Exercise: Chart Detective (15 min)\n\nGroup exploration of Chinese development finance data\nCreating multiple visualizations\nFinding and sharing insights\n\n\nBreak & Discussion (5 min)\n\nShare key insights from exploration\nIdentify visualizations worth polishing\n\nPart 2: Creating Publication-Ready Visualizations (35 min)\n\nFrom Exploration to Publication (15 min)\n\nThe 6-step process for polishing visualizations\nUsing aiddataviz for consistent styling\nBest practices for professional charts\n\nInteractive Exercise: Polish & Present (20 min)\n\nTransform exploratory charts into publication quality\nApply AidData visual identity\nPeer review and feedback\n\n\nWrap-up & Resources (5 min)\n\nKey takeaways\nAdditional resources\nPreview of next week\n\n\n\n\n\n\n\n\nWhy This Matters for TUFF Analysis\n\n\n\nExploratory Visualization\n\nTUFF data is complex and often messy\nVisual exploration helps spot patterns that spreadsheets might miss\nQuick iteration helps generate hypotheses about Chinese lending behavior\nVisual thinking can reveal outliers that need deeper investigation\n\nProfessional Visualization\n\nTurn insights into compelling evidence for reports and blogs\nCreate consistent, branded graphics that build AidData’s reputation\nMove efficiently from analysis to publication\nTell clear stories about Chinese development finance\n\nThe skills you’re learning today directly support AidData’s mission of bringing transparency to Chinese overseas development finance.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_in_class.html#setup",
    "href": "week_2_in_class.html#setup",
    "title": "4  Week 2: Make Cool Charts, Right Away (In-Class)",
    "section": "4.3 Setup",
    "text": "4.3 Setup\nBefore we begin exploring data visualization, let’s get our environment ready. We’ll need to:\n\nInstall the experimental aiddataviz package\nInstall recommended fonts (optional)\nLoad required packages\n\n\n4.3.1 Installing aiddataviz\nFirst, install the aiddataviz package from GitHub:\n\npak::pak(\"Teal-Insights/aiddataviz\")\n\n\n\n\n\n\n\naiddataviz Package Status\n\n\n\nThe aiddataviz package is currently under active development. While it’s already useful for creating AidData-styled visualizations:\n\nExpect breaking changes in the coming weeks\nSome features may change or be refined\nYour feedback will help shape its development\nTreat it as experimental for now\n\nDocumentation is available at the aiddataviz website.\n\n\n\n\n4.3.2 Installing Fonts (Optional)\nThe package works best with specific fonts that match AidData’s visual identity. You can install these fonts with:\n\naiddataviz::install_aiddata_fonts()\n\n\n\n\n\n\n\nNote\n\n\n\nDon’t worry if the font installation doesn’t work - the package will automatically use appropriate backup fonts. We’re still refining this functionality!\n\n\n\n\n4.3.3 Loading Required Packages\nNow let’s load the packages we’ll need:\n\nlibrary(tidyverse)      # For data manipulation and visualization\nlibrary(chinadevfin3)   # For Chinese development finance data\nlibrary(aiddataviz)     # For AidData visualization tools\n\n\n\n4.3.4 Verifying Setup\nLet’s make sure everything is working by creating a simple visualization:\n\ngcdf_yearly_flows |&gt;\n  ggplot(\n    aes(x = commitment_year, \n        y = commitments_bn,\n        fill = flow_class)\n  ) +\n  geom_col() +\n  scale_fill_aiddata() +\n  theme_aiddata() +\n  labs(\n    title = \"Chinese Development Finance Flows\",\n    x = \"Year\",\n    y = \"Commitments (USD Billions)\"\n  )\n\n\n\n\n\n\n\n\nIf you see a chart with AidData’s colors and styling, you’re ready to go! If you run into any issues, don’t worry - we’ll troubleshoot together during class.\n\n\n\n\n\n\nGetting Help\n\n\n\nIf you encounter setup issues: 1. Check the aiddataviz documentation 2. Post in our course Slack channel",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_in_class.html#part-1-exploratory-data-visualization",
    "href": "week_2_in_class.html#part-1-exploratory-data-visualization",
    "title": "4  Week 2: Make Cool Charts, Right Away (In-Class)",
    "section": "4.4 Part 1: Exploratory Data Visualization",
    "text": "4.4 Part 1: Exploratory Data Visualization\nData visualization isn’t just about creating polished graphics for reports. One of its most powerful uses is as a tool for understanding your data and generating new hypotheses. As you explore data, you should:\n\nMake lots of charts quickly\nFocus on insight, not appearance\nLet each visualization suggest the next\nUse charts to generate questions\n\n\n4.4.1 A Case Study in Visual Exploration\nLet’s explore a specific question about Chinese overseas lending: Is there a relationship between the size of lending commitments and interest rates? And how does this relationship vary across different types of countries?\nThis is a perfect example of how we can use visualization to understand complex relationships in our data. We’ll build our visualization step by step, with each step adding new insights.\n\n4.4.1.1 Step 1: The Basic Relationship\nLet’s start with the simplest possible visualization of our question - a basic scatter plot:\n\ngcdf_country_commitments |&gt; \n  # Remove any rows with NA in key variables\n  filter(!is.na(weighted_interest_rate), \n         !is.na(total_commitments_bn)) |&gt;\n  ggplot(\n    aes(x = total_commitments_bn,\n        y = weighted_interest_rate)\n  ) + \n  geom_point()\n\n\n\n\n\n\n\n\nThis initial plot already shows there might be a relationship, but it’s hard to see the pattern clearly because of how financial data is distributed.\n\n\n4.4.1.2 Step 2: Making the Scale Intuitive\nFinancial data often spans several orders of magnitude - from millions to billions of dollars. Regular scales make it hard to see patterns across these different sizes. Let’s improve this with three changes:\n\nUse a log scale to spread out the data\nFormat the labels to be readable\nSet reasonable limits to use the space well\n\n\ngcdf_country_commitments |&gt; \n  filter(!is.na(weighted_interest_rate), \n         !is.na(total_commitments_bn)) |&gt;\n  ggplot(\n    # scale 1 billion --&gt; 1, we deal with scale below\n    aes(x = total_commitments_bn *1e9,\n        y = weighted_interest_rate)\n  ) + \n  geom_point() +\n  scale_x_log10(\n    labels = scales::label_number(\n      scale_cut = scales::cut_short_scale(),\n      prefix = \"$\"\n    ),\n    limits = c(15 * 1e6, 175 * 1e9)  # From roughly $15M to $175B\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe {scales} Package\n\n\n\nThe {scales} package is an amazing resource for making your axes readable and professional. It can:\n\nFormat numbers (e.g., label_number())\nHandle currencies (e.g., label_dollar())\nShow percentages (e.g., label_percent())\nAbbreviate large numbers (e.g., scale_cut_short_scale())\n\nWhile scales offers many sophisticated options for publication-quality graphics, for exploratory work we just want readable labels. Using scale_cut_short_scale() to show “$1B” instead of “1e9” makes our chart more intuitive to read.\nTip: LLMs are great at reformatting scales.\n\n\n\n\n4.4.1.3 Step 3: Adding Country Labels\nThe scatter plot shows a pattern, but which countries are where? Let’s add labels:\n\ngcdf_country_commitments |&gt; \n  filter(!is.na(weighted_interest_rate), \n         !is.na(total_commitments_bn)) |&gt;\n  ggplot(\n    aes(x = total_commitments_bn * 1e9,\n        y = weighted_interest_rate)\n  ) + \n  geom_text(aes(label = iso3c), size = 3) +\n  scale_x_log10(\n    labels = scales::label_number(\n      scale_cut = scales::cut_short_scale(),\n      prefix = \"$\"\n    ),\n    limits = c(15 * 1e6, 175 * 1e9)  \n  )\n\n\n\n\n\n\n\n\nNow we can identify specific countries, and some interesting outliers appear. For example, why does Nicaragua have such a high interest rate relative to its commitment size?\n\n\n4.4.1.4 Step 4: Adding Regional Context\nAre there regional patterns? Let’s color-code by region:\n\ngcdf_country_commitments |&gt; \n  filter(!is.na(weighted_interest_rate), \n         !is.na(total_commitments_bn)) |&gt;\n  ggplot(\n    aes(x = total_commitments_bn * 1e9,\n        y = weighted_interest_rate)\n  ) + \n  geom_text(\n    aes(label = iso3c,\n        color = region_name),\n    size = 3\n  ) +\n   scale_x_log10(\n    labels = scales::label_number(\n      scale_cut = scales::cut_short_scale(),\n      prefix = \"$\"\n    ),\n    limits = c(15 * 1e6, 175 * 1e9) \n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAesthetic Mapping Levels\n\n\n\nIn ggplot2, you can map aesthetics (like color, size, etc.) at different levels:\n\nIn the main ggplot(aes()): applies to ALL layers\nIn individual geoms like geom_text(aes()): applies only to that layer\n\nHere, we put label and color in geom_text(aes()) because:\n\nWe want these aesthetics to only affect the country labels\nWhen we add trend lines later, we want them calculated on ALL data, not by region\nIf we put color = region_name in the main ggplot(aes()), our trend lines would be calculated separately for each region\n\n\n\n\n\n\n\n\n\nUsing AI for Exploration\n\n\n\nTry asking AI assistants questions like:\n\n“What patterns do you notice in this visualization?”\n“Can you help me fix my chart’s scales?”\n“How could I modify this code to explore [specific aspect]?”\n\n\n\n\n\n4.4.1.5 Step 4: Adding Statistical Context\nIs there an overall relationship? Let’s add a trend line:\n\ngcdf_country_commitments |&gt; \n  filter(!is.na(weighted_interest_rate), \n         !is.na(total_commitments_bn)) |&gt;\n  ggplot(\n    aes(x = total_commitments_bn * 1e9,\n        y = weighted_interest_rate)\n  ) + \n  geom_text(\n    aes(label = iso3c,\n        color = region_name),\n    size = 3\n  ) +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  scale_x_log10(\n    labels = scales::label_number(\n      scale_cut = scales::cut_short_scale(),\n      prefix = \"$\"\n    ),\n    limits = c(15 * 1e6, 175 * 1e9)  \n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrend Lines with geom_smooth()\n\n\n\ngeom_smooth() adds a trend line to your plot to help visualize patterns. It can:\n\nUse different methods (lm for linear, loess for local, etc.)\nShow uncertainty with confidence intervals\nHelp identify relationships in noisy data\n\nFor example:\nLinear trend: geom_smooth(method = \"lm\")\nLocal smoothing (good for non-linear patterns): geom_smooth(method = \"loess\")\nLearn more in the geom_smooth() documentation.\n\n\n\n\n4.4.1.6 Step 5: Breaking Out by Income Level\nDoes this relationship vary by country income level? Let’s use faceting to find out:\n\ngcdf_country_commitments |&gt; \n  filter(!is.na(weighted_interest_rate), \n         !is.na(total_commitments_bn)) |&gt;\n  ggplot(\n    aes(x = total_commitments_bn * 1e9,\n        y = weighted_interest_rate)\n  ) + \n  geom_text(\n    aes(label = iso3c,\n        color = region_name),\n    size = 2\n  ) +\n  scale_x_log10(\n    labels = scales::label_number(\n      scale_cut = scales::cut_short_scale(),\n      prefix = \"$\"\n    ),\n    limits = c(15 * 1e6, 175 * 1e9)\n  ) +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  facet_wrap(~income_level_name)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFaceting for Multiple Views facet_wrap() creates small multiples of your plot, split by a variable. It’s great for:\n\nComparing patterns across groups\nSpotting differences in relationships\nDealing with overlapping data\n\nThe ~ in facet_wrap(~variable) is a formula that tells R which variable to use for splitting. Key options:\nscales = \"free\": Let axes vary between facets\nncol or nrow: Control layout\nLearn more in the facet_wrap() documentation\n\n\n\n\n\n4.4.2 What Have We Learned?\nThis exploratory process has revealed several interesting patterns:\n\nThere appears to be a positive relationship between commitment size and interest rates\nThis relationship varies by income level\nThere are some notable outliers worth investigating\nRegional patterns exist within income groups\n\nNot all exploratory analysis yields profound implications. It’s valuable nevertheless.\n\n\n4.4.3 What Questions Does This Raise?\nGood exploratory visualization often raises more questions than it answers:\n\nWhy does Niger have such a high interest rate relative to its peers?\nWhat explains the different slopes across income groups?\nAre these relationships stable over time?\nWhat other factors might explain these patterns?\n\n\n\n4.4.4 Next Steps\nThis exploration suggests several promising directions:\n\nFurther Research: Look into specific outlier cases\nAdditional Visualization: Explore how these patterns change over time\nStatistical Analysis: Consider formal modeling of these relationships\nDomain Expert Input: Discuss findings with colleagues who know specific countries\n\n\n\n\n\n\n\nFrom Exploration to Communication\n\n\n\nIf you find patterns worth sharing:\n\nFor colleagues: Add clear titles, labels, and notes\nFor reports: Transform into publication-quality visualizations\nFor presentations: Simplify to emphasize key points\n\n\n\n\n\n4.4.5 Practice Exercise: Understanding Distributions\nLet’s explore the distributions of key variables in our Chinese development finance data. We’ll use histograms and box plots to understand both overall patterns and how they vary across groups.\n\n\n\n\n\n\nExploring Distributions\n\n\n\nWhen examining a variable’s distribution, it’s helpful to:\n\nLook at the overall shape first (histogram)\nThen compare across groups (box plots)\nConsider whether you need to transform scales (often for financial data)\n\n\n\nExplore these two key variables:\n\nWeighted Interest Rates\n\n\nStart with overall distribution\nCompare across regions\nCompare across income groups\nConsider: What patterns do you see? Any surprises?\n\n\nTotal Commitments\n\n\nLook at the overall distribution\nTry with and without log scale\nLook at regional patterns\nExamine patterns by income group\nThink about: Where is China lending the most? Least?\n\n\n\n\n\n\n\nUseful geoms for Distribution Analysis\n\n\n\n\ngeom_histogram(): Overall shape of distribution\ngeom_boxplot(): Compare distributions across groups\ngeom_density(): Smooth version of histogram\ngeom_violin(): Combination of density and box plot\n\nTry different ones to see which reveals patterns best!\n\n\nRemember:\n\nMake lots of charts\nTry different visualization approaches\nNote interesting patterns\nGenerate questions for further research\n\nShare what you discover with your colleagues - sometimes fresh eyes see new patterns!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_in_class.html#part-2-from-exploration-to-publication-ready-graphics",
    "href": "week_2_in_class.html#part-2-from-exploration-to-publication-ready-graphics",
    "title": "4  Week 2: Make Cool Charts, Right Away (In-Class)",
    "section": "4.5 Part 2: From Exploration to Publication-Ready Graphics",
    "text": "4.5 Part 2: From Exploration to Publication-Ready Graphics\n\n4.5.1 Creating Publication-Ready Graphics with aiddataviz\nIn the first part of this class, we explored how to use visualization to understand patterns in our data. Now we’ll learn how to transform those exploratory visualizations into polished, professional graphics suitable for reports and presentations.\n\n\n\n\n\n\nHelp Shape aiddataviz\n\n\n\nThe aiddataviz package is brand new and actively evolving. While it’s already useful for creating AidData-styled visualizations:\n\nExpect the package to change significantly in coming weeks\nSome features may be added or refined\nDocumentation will be expanded\nInstallation processes will be streamlined\n\nYour Input Matters!\nWe’re actively seeking feedback from AidData staff & communications team to make this package truly useful for your work. We’d love your input on:\n\nColor palettes that work well for your analysis\nFont choices that match AidData’s brand\nOutput formats you commonly need\nCommon visualization types you create\nFeatures that would save you time\n\nThis is your chance to help build a tool that makes your work easier!\n\n\n\n\n4.5.2 Our Target: Professional Publication Quality\nLet’s work through transforming an exploratory visualization into something publication-ready. We’ll recreate this visualization from AidData’s Belt and Road Reboot Report:\n\nThis visualization effectively communicates several key pieces of information:\n\nTotal lending volumes over time\nComposition of lending by flow class\nKey periods in the Belt and Road Initiative\nClear source attribution and professional styling\n\n\n\n4.5.3 Building Our Publication-Ready Visualization\nLet’s transform our exploratory visualization into a polished, publication-ready graphic step by step. Think of it like building with Legos - each piece adds something specific and manageable.\n\n4.5.3.1 Step 1: Start with Basic Structure\nFirst, let’s create our basic stacked bar chart:\n\ngcdf_yearly_flows |&gt; \n  ggplot(\n    aes(\n      x = commitment_year,\n      y = commitments_bn,\n      fill = flow_class\n    ) \n  ) + \n  geom_col() \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis basic structure already shows our key information - lending volumes over time by flow class. Now we’ll enhance it step by step.\n\n\n\n\n4.5.3.2 Step 2: Improve Visual Organization\nWe’ll reorder the flow classes to create a more intuitive stacking order:\n\np &lt;- gcdf_yearly_flows |&gt; \n  ggplot(\n    aes(\n      x = commitment_year,\n      y = commitments_bn,\n      fill = fct_reorder2(\n        .f = flow_class,\n        .x = commitment_year,\n        .y = commitments_bn,\n        .desc = FALSE\n    )\n  ) \n  )+ \n  geom_col() +\n  labs(fill = \"\")\np\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFactor Reordering: Static vs Time Series Data The forcats package gives us two key tools for reordering factors: fct_reorder(): Best for static data (like sorted bar charts)\nOrders categories by a single value Perfect when you want to rank things from highest to lowest\nfct_reorder2(): Designed specifically for time series data\nTakes both time and value into account Creates stable ordering over time Particularly useful for stacked charts like ours\nThink: “Static = fct_reorder(), Time Series = fct_reorder2()”\n\n\n\n\n4.5.3.3 Step 3: Apply AidData’s Visual Style\nNow we’ll transform the look using AidData’s color palette and theme:\n\n#Using predefined colors from aiddataviz\naiddata_custom_colors &lt;- c(\n  \"ODA-like\" = unname(aiddata_colors$wren_twilight),\n  \"OOF-like\" = unname(aiddata_colors$spirit_gold),\n  \"Vague (Official Finance)\" = unname(aiddata_colors$silver)\n)\n\np2 &lt;- p +\n  # allows you to define your own colors\n  scale_fill_manual(values = aiddata_custom_colors) +\n  theme_aiddata() +\n  theme(\n    panel.grid.major.x = element_blank()  # Remove vertical gridlines\n  )\np2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAidData’s Color System\n\n\n\nThe colors we’re using come from William & Mary’s brand guidelines and have been chosen to:\n\nEnsure readability\nMaintain institutional identity\nWork well together in various combinations\n\n\n\n\n\n4.5.3.4 Step 4: Add Direct Labels\nLet’s replace the legend with direct labels, making it easier for readers to identify categories:\n\np3 &lt;- p2 +\n  annotate(\n    \"text\", \n    x = 2022, \n    y = c(82, 68, 40), \n    label = c(\"Vague\", \"ODA\", \"OOF\"), \n    # Match colors to labels explicitly\n    color = c(\n      unname(aiddata_colors$silver),          # For \"Vague\"\n      unname(aiddata_colors$wren_twilight),   # For \"ODA\"\n      unname(aiddata_colors$spirit_gold)      # For \"OOF\"\n    ),\n    size = 4, \n    hjust = 0\n  ) +\n  # add space for the labels\n  xlim(2000, 2023) +\n  # get rid of the old clunky legend\n  theme(legend.position = \"none\")\np3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nDirect labels eliminate the need for readers to look back and forth between the visualization and a legend, making the chart easier to understand quickly.\n\n\n\n\n4.5.3.5 Step 5: Add Context with Annotations\nNow we’ll add the BRI period markers to provide important context:\n\np4 &lt;- p3 +\n  # Add vertical lines for BRI periods\n  geom_vline(\n    xintercept = c(2013.5, 2017.5),\n    linetype = \"dashed\",\n    color = aiddata_colors$gray50,\n    alpha = 0.5\n  ) +\n  # Add BRI period annotations\n  annotate(\n    \"text\",\n    x = 2015.5,\n    y = 165,\n    label = \"Early BRI\\n(2014-2017)\",\n    size = 3.5,\n    color = aiddata_colors$gray50\n  ) +\n  annotate(\n    \"text\",\n    x = 2019.5,\n    y = 165,\n    label = \"Late BRI\\n(2018-2021)\",\n    size = 3.5,\n    color = aiddata_colors$gray50\n  )\np4\n\n\n\n\n\n\n\n\n\n\n4.5.3.6 Step 6: Polish with Professional Labeling\nFinally, we’ll add clear titles, format axes, and include proper source attribution:\n\np5 &lt;- p4 +\n  labs(\n    title = \"Official financial flows from China to the developing world,&lt;br&gt;2000-2021\",\n    subtitle = \"Constant 2021 USD Billions\",\n    x = NULL,\n    y = NULL,\n    caption = \"Source: AidData's Global Chinese Development Finance Dataset, Version 3.0\"\n  ) +\n  scale_y_continuous(\n    labels = scales::label_currency(suffix = \" B\"),\n    limits = c(0,170)\n  )\np5\n\n\n\n\n\n\n\n\nLet’s compare it to the original:\n\nLooks pretty close! That’s something you can easily learn to do well.\nIf we wanted to, we could take a few more steps:\n\ndraw lines from our labels to the columns\nmake the axis titles lighter to draw attention away from them\n\nOnce you get to that level, it’s worth talking with your communications team. They are professionals.\n\n\n\n4.5.4 Key Elements of Professional Visualizations\nOur final visualization incorporates several key elements that make it publication-ready:\n\nClear Visual Hierarchy\n\nOrdered stacking of categories\nDirect labels instead of legend\nRemoval of unnecessary grid lines\n\nConsistent Branding\n\nAidData color palette\nProfessional typography\nClean, minimal theme\n\nContextual Information\n\nClear title and subtitle\nImportant period markers\nProper source attribution\n\nReadable Formatting\n\nWell-formatted axis labels\nAppropriate scale limits\nBalanced use of space\n\n\n\n\n\n\n\n\nCreating Your Own Publication Graphics\n\n\n\nCreate a checklist for your visualizations:\n\nIs the main message immediately clear?\nAre all elements properly labeled?\nIs the styling consistent with your organization’s brand?\nHave you removed unnecessary visual elements?\nIs the source clearly attributed?",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_in_class.html#resources-for-data-visualization",
    "href": "week_2_in_class.html#resources-for-data-visualization",
    "title": "4  Week 2: Make Cool Charts, Right Away (In-Class)",
    "section": "4.6 Resources for Data Visualization",
    "text": "4.6 Resources for Data Visualization\n\n4.6.1 Essential References\n\nggplot2 Documentation\n\nComprehensive function reference\nClear examples for each feature\nBest place to look up specific details\n\nR for Data Science (2e)\n\nSection 2 focuses entirely on visualization\nWritten by ggplot2’s creator, Hadley Wickham\nPerfect balance of theory and practice\nFree online!\n\n\n\n\n4.6.2 Finding Inspiration & Solutions\n\nggplot2 Extensions Gallery\n\nBrowse specialized visualization packages\nFind new ways to present your data\nAll compatible with ggplot2\n\nR Graph Gallery\n\nExamples of many chart types\nStep-by-step instructions\nCode you can adapt\n\n\n\n\n\n\n\n\nQuick Tip\n\n\n\nWhen you need to create a new type of visualization:\n\nCheck the R Graph Gallery for examples\nLook for relevant ggplot2 extensions\nAsk AI tools to help adapt example code\n\n\n\n\n\n4.6.3 Advanced Learning\n\nStorytelling with Data\n\nBeyond technical skills\nFocus on communication\nKey concepts:\n\nUnderstanding context and audience\nChoosing the right visualization\nEliminating chart clutter\nUsing design principles\nBuilding effective narratives\n\n\nGraphic Design with ggplot2\n\n💫 Highly Recommended!\nComprehensive workshop materials\nFree online access\nTopics include:\n\nAdvanced ggplot2 techniques\nColor theory and typography\nLayout and composition\nCreating publication-quality graphics\n\n\n\n\n\n\n\n\n\nLearning Path Suggestion\n\n\n\n\nStart with R4DS for foundations\nUse the galleries for inspiration\nReference ggplot2 docs for details\nMove to advanced resources when ready\n\n\n\n\n\n4.6.4 Practice Exercise\nTake one of the exploratory visualizations you created today and:\n\nFind a similar example in the R Graph Gallery\nIdentify ways to enhance it\nUse the ggplot2 documentation to implement improvements\nShare your before/after with colleagues\n\nRemember: Great visualization is an iterative process. Start simple, then enhance step by step.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_2_in_class.html#wrapping-up-the-power-of-data-visualization",
    "href": "week_2_in_class.html#wrapping-up-the-power-of-data-visualization",
    "title": "4  Week 2: Make Cool Charts, Right Away (In-Class)",
    "section": "4.7 Wrapping Up: The Power of Data Visualization",
    "text": "4.7 Wrapping Up: The Power of Data Visualization\n\n4.7.1 Today’s Achievements\nLet’s look back at what we’ve accomplished in just 90 minutes:\n\nMastered Two Types of Visualization\n\n\nCreated exploratory visualizations to understand data\nTransformed rough charts into publication-ready graphics\nLearned when to use each approach\n\n\nUsed Visualization for Discovery\n\n\nLayered multiple variables into single charts\nDiscovered patterns in Chinese development finance\nGenerated new questions for research\nLearned to use aesthetic mappings effectively\n\n\nCreated Professional Graphics\n\n\nApplied AidData’s visual identity\nBuilt complex visualizations step by step\nUsed the aiddataviz package for consistent styling\nAdded professional touches like annotations and labels\n\nMost importantly, you now have a toolkit for both exploring data and communicating your findings effectively. While mastering data visualization takes time and practice, you have working examples you can build upon and adapt for your own analysis needs.\n\n\n4.7.2 Checking Our Learning Objectives\nLet’s review what we set out to achieve:\n✅ Create exploratory visualizations\n\nYou’ve learned to build layered visualizations\nYou know how to map multiple variables to aesthetics\nYou can use faceting to compare across groups\n\n✅ Layer aesthetic mappings\n\nYou understand how different mappings reveal patterns\nYou can combine multiple variables in one visualization\nYou know how to choose effective aesthetic mappings\n\n✅ Transform exploratory charts into publication graphics\n\nYou can follow the 6-step process for polishing charts\nYou understand the elements of professional visualization\nYou can use aiddataviz for consistent styling\n\n✅ Apply AidData’s visual identity\n\nYou know how to use AidData’s color palettes\nYou can apply consistent styling with theme_aiddata()\nYou understand the importance of visual consistency\n\n✅ Use AI tools effectively\n\nYou’ve seen how AI can help with visualization code\nYou know what questions to ask AI assistants\nYou understand how to verify AI suggestions\n\n\n\n4.7.3 Resources for Continued Learning\nRemember, you have several resources available:\n\nOur course textbook and examples\nThe comprehensive resources we just covered\nThe aiddataviz package (though remember it’s still evolving!)\nAI tools to help with coding and troubleshooting\n\n\n\n4.7.4 Next Steps\n\nPractice with Your Own Data\n\n\nTry creating exploratory visualizations of your current projects\nApply the 6-step process to polish important charts\nUse AI tools to help when you get stuck\n\n\nPrepare for Next Week\n\n\nWe’ll dive into data transformation\nThink about what patterns you’d like to investigate\nConsider how visualization and transformation work together\n\n\nGet Help When Needed\n\n\nUse AI tools for code help\nReference the resources we covered\nAsk questions in our course forum\nShare challenges and solutions with colleagues\n\nRemember: Learning data visualization is a journey. Focus on understanding the fundamentals and building your skills step by step. You don’t need to memorize everything - knowing where to find help is often more important than memorizing syntax.\nSee you next week!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 2: Make Cool Charts, Right Away (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_pre_class.html",
    "href": "week_3_pre_class.html",
    "title": "5  Week 3: Find Actionable Insights, Quickly (Pre-Class)",
    "section": "",
    "text": "5.1 Overview\nThis pre-class preparation should take about 45-60 minutes to complete.\nNow that you can create visualizations and automated reports, it’s time to learn how to transform your data to find meaningful insights. This week focuses on data transformation - the process of taking raw data and reshaping it to answer specific questions. We’ll use the tidyverse’s powerful dplyr package, which makes complex data operations surprisingly intuitive.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_pre_class.html#overview",
    "href": "week_3_pre_class.html#overview",
    "title": "5  Week 3: Find Actionable Insights, Quickly (Pre-Class)",
    "section": "",
    "text": "5.1.1 Video Lecture\nWatch this video lecture before our interactive session:",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_pre_class.html#learning-objectives",
    "href": "week_3_pre_class.html#learning-objectives",
    "title": "5  Week 3: Find Actionable Insights, Quickly (Pre-Class)",
    "section": "5.2 Learning Objectives",
    "text": "5.2 Learning Objectives\nBy completing this pre-class work, you will:\n\nUnderstand the core data transformation verbs in dplyr\nLearn to chain operations together using the pipe operator |&gt;\nBegin thinking about data transformation patterns\nPractice with real Chinese development finance data\nUse AI tools to assist with data transformation tasks",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_pre_class.html#setup",
    "href": "week_3_pre_class.html#setup",
    "title": "5  Week 3: Find Actionable Insights, Quickly (Pre-Class)",
    "section": "5.3 Setup",
    "text": "5.3 Setup\nLet’s get our workspace ready. First, create a new Quarto document for your notes:\n# Create a new Quarto document\n# File → New File → Quarto Document\n# Save as \"week_3_transformation_preclass.qmd\" in your week_3/R folder\nLoad the packages we’ll need:\n\nlibrary(tidyverse)    # For data transformation tools\nlibrary(chinadevfin3) # For Chinese development finance data",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_pre_class.html#a-mini-dataset-for-learning",
    "href": "week_3_pre_class.html#a-mini-dataset-for-learning",
    "title": "5  Week 3: Find Actionable Insights, Quickly (Pre-Class)",
    "section": "5.4 A Mini Dataset for Learning",
    "text": "5.4 A Mini Dataset for Learning\nBefore diving into data transformation, let’s create a small dataset we’ll use for learning. This contains the two largest loans for five countries:\n\nmini_gcdf &lt;- get_gcdf3_dataset() |&gt; \n    filter(\n        recommended_for_aggregates == \"Yes\",\n        flow_type == \"Loan\",\n        recipient %in% c(\n            \"Angola\",\n            \"Zambia\",\n            \"Venezuela\",\n            \"Indonesia\",\n            \"Pakistan\"\n        )\n    ) |&gt; \n    group_by(recipient) |&gt; \n    slice_max(\n        order_by = amount_constant_usd_2021,\n        n = 2\n    ) |&gt; \n    select(\n        recipient,\n        recipient_region,\n        sector_name,\n        commitment_year,\n        amount_constant_usd_2021 \n    ) |&gt; \n    ungroup()\n\n# Also create a dataset for year-over-year analysis\nangola_annual_flows &lt;- get_gcdf3_dataset() |&gt;\n    filter(\n        recommended_for_aggregates == \"Yes\",\n        flow_type == \"Loan\",\n        recipient == \"Angola\"\n    ) |&gt;\n    group_by(commitment_year) |&gt;\n    summarize(\n        total_amount = sum(amount_constant_usd_2021, na.rm = TRUE),\n        .groups = \"drop\"\n    )\n\n# Look at our mini dataset\nmini_gcdf\n\n# A tibble: 10 × 5\n   recipient recipient_region sector_name commitment_year amount_constant_usd_…¹\n   &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;                 &lt;int&gt;                  &lt;dbl&gt;\n 1 Angola    Africa           ENERGY                 2016            8147551108.\n 2 Angola    Africa           OTHER SOCI…            2010            3481817339.\n 3 Indonesia Asia             INDUSTRY, …            2009            2853819092.\n 4 Indonesia Asia             TRANSPORT …            2017            2743140983.\n 5 Pakistan  Asia             BANKING AN…            2020            4855813054.\n 6 Pakistan  Asia             BANKING AN…            2021            4651162791.\n 7 Venezuela America          OTHER MULT…            2010           14402361186.\n 8 Venezuela America          OTHER MULT…            2010           13927269358.\n 9 Zambia    Africa           ENERGY                 2017             881870586.\n10 Zambia    Africa           ENERGY                 2017             881870586.\n# ℹ abbreviated name: ¹​amount_constant_usd_2021\n\n\nDon’t worry if the code that created this dataset looks complex - by the end of this pre-class material, you’ll understand every line! For now, just notice that:\n\nWe have 10 rows (2 loans each from 5 countries)\nCountries are from 3 different regions (Africa, Asia, America)\nEach loan has a sector, year, and amount\nThe amounts are in constant 2021 USD\n\nThis small dataset will help us learn the fundamentals before working with the full GCDF database.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_pre_class.html#the-five-core-verbs-of-data-transformation",
    "href": "week_3_pre_class.html#the-five-core-verbs-of-data-transformation",
    "title": "5  Week 3: Find Actionable Insights, Quickly (Pre-Class)",
    "section": "5.5 The Five Core verbs of Data Transformation",
    "text": "5.5 The Five Core verbs of Data Transformation\nThink of data transformation as having five fundamental operations, just like basic arithmetic has addition, subtraction, multiplication, and division. In dplyr, these operations are:\n\nfilter(): Pick rows based on their values\narrange(): Change the order of rows\nselect(): Pick columns by their names\nmutate(): Create new columns from existing ones\nsummarize(): Collapse multiple rows into a single summary\n\nLet’s explore each one using examples from Chinese development finance data.\n\n5.5.1 Verb 1. filter(): Subsetting Your Data\nfilter() helps you focus on specific parts of your data. Think of it like a sieve that keeps only the rows you want:\n\n# Using mini dataset: African loans over $1 billion\nmini_gcdf |&gt;\n  filter(\n    recipient_region == \"Africa\",\n    amount_constant_usd_2021 &gt;= 1 * 1e9\n  )\n\n# A tibble: 2 × 5\n  recipient recipient_region sector_name  commitment_year amount_constant_usd_…¹\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;                  &lt;int&gt;                  &lt;dbl&gt;\n1 Angola    Africa           ENERGY                  2016            8147551108.\n2 Angola    Africa           OTHER SOCIA…            2010            3481817339.\n# ℹ abbreviated name: ¹​amount_constant_usd_2021\n\n# Real world example: Large ODA-like projects\nget_gcdf3_dataset() |&gt;\n  filter(\n    flow_class == \"ODA-like\",\n    amount_constant_usd_2021 &gt;= 100 * 1e6,\n    recommended_for_aggregates == \"Yes\"\n  )\n\n# A tibble: 292 × 129\n   country_name     iso3c country_or_regional aid_data_record_id\n   &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;                            &lt;int&gt;\n 1 Sri Lanka        LKA   country                          89483\n 2 Tajikistan       TJK   country                          92674\n 3 Uzbekistan       UZB   country                          92623\n 4 Cambodia         KHM   country                          94984\n 5 North Korea      PRK   country                          93442\n 6 North Korea      PRK   country                          93443\n 7 North Korea      PRK   country                          95607\n 8 Congo - Kinshasa COD   country                          92575\n 9 Ghana            GHA   country                          92600\n10 Kazakhstan       KAZ   country                          92613\n# ℹ 282 more rows\n# ℹ 125 more variables: recommended_for_aggregates &lt;chr&gt;,\n#   aid_data_parent_id &lt;chr&gt;, umbrella &lt;chr&gt;, financier_country &lt;chr&gt;,\n#   recipient &lt;chr&gt;, recipient_iso_3 &lt;chr&gt;, recipient_region &lt;chr&gt;,\n#   commitment_year &lt;int&gt;, implementation_start_year &lt;int&gt;,\n#   completion_year &lt;int&gt;, title &lt;chr&gt;, description &lt;chr&gt;,\n#   staff_comments &lt;chr&gt;, status &lt;chr&gt;, intent &lt;chr&gt;, flow_type &lt;chr&gt;, …\n\n\nCommon filtering operations you’ll use:\n\n# Projects from recent years\nget_gcdf3_dataset() |&gt;\n  filter(commitment_year &gt;= 2018)\n\n# A tibble: 6,528 × 129\n   country_name iso3c country_or_regional aid_data_record_id\n   &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;                            &lt;int&gt;\n 1 Afghanistan  AFG   country                          94556\n 2 Afghanistan  AFG   country                          94564\n 3 Afghanistan  AFG   country                          94565\n 4 Afghanistan  AFG   country                          94567\n 5 Afghanistan  AFG   country                          94568\n 6 Afghanistan  AFG   country                          94613\n 7 Afghanistan  AFG   country                          94619\n 8 Afghanistan  AFG   country                          95312\n 9 Afghanistan  AFG   country                          95322\n10 Afghanistan  AFG   country                          95323\n# ℹ 6,518 more rows\n# ℹ 125 more variables: recommended_for_aggregates &lt;chr&gt;,\n#   aid_data_parent_id &lt;chr&gt;, umbrella &lt;chr&gt;, financier_country &lt;chr&gt;,\n#   recipient &lt;chr&gt;, recipient_iso_3 &lt;chr&gt;, recipient_region &lt;chr&gt;,\n#   commitment_year &lt;int&gt;, implementation_start_year &lt;int&gt;,\n#   completion_year &lt;int&gt;, title &lt;chr&gt;, description &lt;chr&gt;,\n#   staff_comments &lt;chr&gt;, status &lt;chr&gt;, intent &lt;chr&gt;, flow_type &lt;chr&gt;, …\n\n# Projects in specific countries\nget_gcdf3_dataset() |&gt;\n  filter(recipient %in% c(\"Angola\", \"Ethiopia\", \"Kenya\"))\n\n# A tibble: 963 × 129\n   country_name iso3c country_or_regional aid_data_record_id\n   &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;                            &lt;int&gt;\n 1 Angola       AGO   country                          92519\n 2 Angola       AGO   country                          93104\n 3 Angola       AGO   country                          93281\n 4 Angola       AGO   country                          93286\n 5 Angola       AGO   country                          95331\n 6 Ethiopia     ETH   country                          91947\n 7 Ethiopia     ETH   country                          92357\n 8 Ethiopia     ETH   country                          95864\n 9 Ethiopia     ETH   country                          95866\n10 Ethiopia     ETH   country                          95869\n# ℹ 953 more rows\n# ℹ 125 more variables: recommended_for_aggregates &lt;chr&gt;,\n#   aid_data_parent_id &lt;chr&gt;, umbrella &lt;chr&gt;, financier_country &lt;chr&gt;,\n#   recipient &lt;chr&gt;, recipient_iso_3 &lt;chr&gt;, recipient_region &lt;chr&gt;,\n#   commitment_year &lt;int&gt;, implementation_start_year &lt;int&gt;,\n#   completion_year &lt;int&gt;, title &lt;chr&gt;, description &lt;chr&gt;,\n#   staff_comments &lt;chr&gt;, status &lt;chr&gt;, intent &lt;chr&gt;, flow_type &lt;chr&gt;, …\n\n# Projects where we don't have an unknown (NA) commitment value\nget_gcdf3_dataset() |&gt;\n  filter(\n    !is.na(amount_constant_usd_2021),\n    recommended_for_aggregates == \"Yes\"\n  )\n\n# A tibble: 10,671 × 129\n   country_name     iso3c country_or_regional aid_data_record_id\n   &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;                            &lt;int&gt;\n 1 Afghanistan      AFG   country                          94556\n 2 Afghanistan      AFG   country                          94564\n 3 Afghanistan      AFG   country                          94565\n 4 Afghanistan      AFG   country                          94567\n 5 Afghanistan      AFG   country                          94568\n 6 Afghanistan      AFG   country                          94619\n 7 Afghanistan      AFG   country                          98007\n 8 Afghanistan      AFG   country                          98008\n 9 Africa, regional &lt;NA&gt;  regional                         92947\n10 Algeria          DZA   country                          94808\n# ℹ 10,661 more rows\n# ℹ 125 more variables: recommended_for_aggregates &lt;chr&gt;,\n#   aid_data_parent_id &lt;chr&gt;, umbrella &lt;chr&gt;, financier_country &lt;chr&gt;,\n#   recipient &lt;chr&gt;, recipient_iso_3 &lt;chr&gt;, recipient_region &lt;chr&gt;,\n#   commitment_year &lt;int&gt;, implementation_start_year &lt;int&gt;,\n#   completion_year &lt;int&gt;, title &lt;chr&gt;, description &lt;chr&gt;,\n#   staff_comments &lt;chr&gt;, status &lt;chr&gt;, intent &lt;chr&gt;, flow_type &lt;chr&gt;, …\n\n\n\n\n\n\n\n\nLogical Operators in filter()\n\n\n\n\n==: Exactly equals\n!=: Does not equal\n&gt;, &gt;=: Greater than, Greater than or equal to\n&lt;, &lt;=: Less than, Less than or equal to\n%in%: Is in a set of values\n!is.na(): Is not missing\n&: And (multiple conditions)\n|: Or (either condition)\n\n\n\n\n\n5.5.2 Verb 2. arrange(): Ordering Your Data\narrange() lets you sort your data. By default, it sorts in ascending order (smallest to largest):\n\n# Using mini dataset: Sort by size (largest first)\nmini_gcdf |&gt;\n  arrange(desc(amount_constant_usd_2021))\n\n# A tibble: 10 × 5\n   recipient recipient_region sector_name commitment_year amount_constant_usd_…¹\n   &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;                 &lt;int&gt;                  &lt;dbl&gt;\n 1 Venezuela America          OTHER MULT…            2010           14402361186.\n 2 Venezuela America          OTHER MULT…            2010           13927269358.\n 3 Angola    Africa           ENERGY                 2016            8147551108.\n 4 Pakistan  Asia             BANKING AN…            2020            4855813054.\n 5 Pakistan  Asia             BANKING AN…            2021            4651162791.\n 6 Angola    Africa           OTHER SOCI…            2010            3481817339.\n 7 Indonesia Asia             INDUSTRY, …            2009            2853819092.\n 8 Indonesia Asia             TRANSPORT …            2017            2743140983.\n 9 Zambia    Africa           ENERGY                 2017             881870586.\n10 Zambia    Africa           ENERGY                 2017             881870586.\n# ℹ abbreviated name: ¹​amount_constant_usd_2021\n\n# Real world example: Sort projects by multiple columns\nget_gcdf3_dataset() |&gt;\n  filter(recommended_for_aggregates == \"Yes\") |&gt;\n  arrange(\n    recipient,  # First by country A-Z\n    desc(commitment_year)  # Then by most recent year\n  )\n\n# A tibble: 17,957 × 129\n   country_name iso3c country_or_regional aid_data_record_id\n   &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt;                            &lt;int&gt;\n 1 Afghanistan  AFG   country                          94556\n 2 Afghanistan  AFG   country                          94564\n 3 Afghanistan  AFG   country                          94565\n 4 Afghanistan  AFG   country                          94567\n 5 Afghanistan  AFG   country                          94568\n 6 Afghanistan  AFG   country                          94613\n 7 Afghanistan  AFG   country                          94619\n 8 Afghanistan  AFG   country                          95322\n 9 Afghanistan  AFG   country                          95323\n10 Afghanistan  AFG   country                          95324\n# ℹ 17,947 more rows\n# ℹ 125 more variables: recommended_for_aggregates &lt;chr&gt;,\n#   aid_data_parent_id &lt;chr&gt;, umbrella &lt;chr&gt;, financier_country &lt;chr&gt;,\n#   recipient &lt;chr&gt;, recipient_iso_3 &lt;chr&gt;, recipient_region &lt;chr&gt;,\n#   commitment_year &lt;int&gt;, implementation_start_year &lt;int&gt;,\n#   completion_year &lt;int&gt;, title &lt;chr&gt;, description &lt;chr&gt;,\n#   staff_comments &lt;chr&gt;, status &lt;chr&gt;, intent &lt;chr&gt;, flow_type &lt;chr&gt;, …\n\n\n\n\n\n\n\n\nNote\n\n\n\nUse desc() to sort in descending order. When sorting by multiple columns, each one is used as a tie-breaker for the previous ones.\n\n\n\n\n5.5.3 Verb 3. select(): Choosing Columns\nselect() helps you focus on specific variables. It’s particularly useful when you have datasets with many columns:\n\n# Using mini dataset: Select key columns\nmini_gcdf |&gt;\n  select(\n    recipient,\n    commitment_year,\n    amount_constant_usd_2021\n  )\n\n# A tibble: 10 × 3\n   recipient commitment_year amount_constant_usd_2021\n   &lt;chr&gt;               &lt;int&gt;                    &lt;dbl&gt;\n 1 Angola               2016              8147551108.\n 2 Angola               2010              3481817339.\n 3 Indonesia            2009              2853819092.\n 4 Indonesia            2017              2743140983.\n 5 Pakistan             2020              4855813054.\n 6 Pakistan             2021              4651162791.\n 7 Venezuela            2010             14402361186.\n 8 Venezuela            2010             13927269358.\n 9 Zambia               2017               881870586.\n10 Zambia               2017               881870586.\n\n# Real world example: Select columns by pattern\nget_gcdf3_dataset() |&gt;\n  select(\n    starts_with(\"amount\"),\n    contains(\"year\")\n  )\n\n# A tibble: 20,985 × 7\n   amount_original_currency amount_estimated amount_constant_usd_2021\n                      &lt;dbl&gt; &lt;chr&gt;                               &lt;dbl&gt;\n 1                550000000 &lt;NA&gt;                             7111456.\n 2                 12600000 Yes                             12600000 \n 3                 14400000 Yes                             14400000 \n 4                 13000000 &lt;NA&gt;                            13000000 \n 5                  7500000 &lt;NA&gt;                             7500000 \n 6                       NA &lt;NA&gt;                                  NA \n 7                  3600000 Yes                              3600000 \n 8                 30000000 &lt;NA&gt;                             4651163.\n 9                       NA &lt;NA&gt;                                  NA \n10                       NA &lt;NA&gt;                                  NA \n# ℹ 20,975 more rows\n# ℹ 4 more variables: amount_nominal_usd &lt;dbl&gt;, commitment_year &lt;int&gt;,\n#   implementation_start_year &lt;int&gt;, completion_year &lt;int&gt;\n\n\n\n\n\n\n\n\nHelpful select() Helpers\n\n\n\n\nstarts_with(): Columns starting with a prefix\nends_with(): Columns ending with a suffix\ncontains(): Columns containing a string\nmatches(): Columns matching a regular expression\neverything(): All remaining columns\n\n\n\n\n\n5.5.4 Verb 4. mutate(): Creating New Variables\nmutate() lets you create new columns based on existing ones. Let’s look at some examples:\n\n# Using mini dataset: Calculate billions and shares\nmini_gcdf |&gt;\n  group_by(recipient_region) |&gt;\n  mutate(\n    amount_bn = amount_constant_usd_2021 / 1e9,\n    share_of_region = amount_constant_usd_2021 / sum(amount_constant_usd_2021) * 100\n  ) |&gt;\n  ungroup()\n\n# A tibble: 10 × 7\n   recipient recipient_region sector_name commitment_year amount_constant_usd_…¹\n   &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;                 &lt;int&gt;                  &lt;dbl&gt;\n 1 Angola    Africa           ENERGY                 2016            8147551108.\n 2 Angola    Africa           OTHER SOCI…            2010            3481817339.\n 3 Indonesia Asia             INDUSTRY, …            2009            2853819092.\n 4 Indonesia Asia             TRANSPORT …            2017            2743140983.\n 5 Pakistan  Asia             BANKING AN…            2020            4855813054.\n 6 Pakistan  Asia             BANKING AN…            2021            4651162791.\n 7 Venezuela America          OTHER MULT…            2010           14402361186.\n 8 Venezuela America          OTHER MULT…            2010           13927269358.\n 9 Zambia    Africa           ENERGY                 2017             881870586.\n10 Zambia    Africa           ENERGY                 2017             881870586.\n# ℹ abbreviated name: ¹​amount_constant_usd_2021\n# ℹ 2 more variables: amount_bn &lt;dbl&gt;, share_of_region &lt;dbl&gt;\n\n# Real world example: Year-over-year growth\nangola_annual_flows |&gt;\n  mutate(\n    prev_year_amount = lag(total_amount),\n    yoy_growth = (total_amount - prev_year_amount) / prev_year_amount * 100\n  )\n\n# A tibble: 21 × 4\n   commitment_year total_amount prev_year_amount yoy_growth\n             &lt;int&gt;        &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;\n 1            2001    15087227.              NA        NA  \n 2            2002   489893161.        15087227.     3147. \n 3            2003    26796701.       489893161.      -94.5\n 4            2004   989972579.        26796701.     3594. \n 5            2005  2857495673.       989972579.      189. \n 6            2006  2453696747.      2857495673.      -14.1\n 7            2007  3895910151.      2453696747.       58.8\n 8            2008   198727773.      3895910151.      -94.9\n 9            2009  3388534669.       198727773.     1605. \n10            2010  4300740778.      3388534669.       26.9\n# ℹ 11 more rows\n\n\n\n\n\n\n\n\nWhat’s Happening Here?\n\n\n\nIn the regional shares example:\n\nGroup by region so calculations happen within each region\nConvert amounts to billions (divide by 1e9)\nCalculate each project’s share of its regional total\nRemove grouping when done\n\nIn the growth example:\n\nlag(total_amount) gets previous year’s value\nCalculate percent change from previous year\n\n\n\n\n\n5.5.5 Verb 5. summarize(): Creating Summaries\nsummarize() collapses groups into single rows. This is especially powerful when combined with group_by():\n\n# Using mini dataset: Regional summaries\nmini_gcdf |&gt;\n  group_by(recipient_region) |&gt;\n  summarize(\n    total_amount_bn = sum(amount_constant_usd_2021) / 1e9,\n    project_count = n(),\n    avg_amount_bn = mean(amount_constant_usd_2021) / 1e9,\n    .groups = \"drop\"\n  )\n\n# A tibble: 3 × 4\n  recipient_region total_amount_bn project_count avg_amount_bn\n  &lt;chr&gt;                      &lt;dbl&gt;         &lt;int&gt;         &lt;dbl&gt;\n1 Africa                      13.4             4          3.35\n2 America                     28.3             2         14.2 \n3 Asia                        15.1             4          3.78\n\n# Real world example: Annual lending by flow class\nget_gcdf3_dataset() |&gt;\n  filter(recommended_for_aggregates == \"Yes\") |&gt;\n  group_by(commitment_year, flow_class) |&gt;\n  summarize(\n    total_amount_bn = sum(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    project_count = n(),\n    .groups = \"drop\"\n  )\n\n# A tibble: 66 × 4\n   commitment_year flow_class               total_amount_bn project_count\n             &lt;int&gt; &lt;chr&gt;                              &lt;dbl&gt;         &lt;int&gt;\n 1            2000 ODA-like                          1.44             138\n 2            2000 OOF-like                          3.99              34\n 3            2000 Vague (Official Finance)          0.0128             2\n 4            2001 ODA-like                          3.50             175\n 5            2001 OOF-like                          4.16              33\n 6            2001 Vague (Official Finance)          0.204              6\n 7            2002 ODA-like                          2.27             199\n 8            2002 OOF-like                          4.89              38\n 9            2002 Vague (Official Finance)          0.429              8\n10            2003 ODA-like                          3.52             236\n# ℹ 56 more rows\n\n\nCommon summary functions:\n\nsum(): Total values\nmean(): Average\nmedian(): Middle value\nsd(): Standard deviation\nn(): Count rows\nn_distinct(): Count unique values\n\n\n\n\n\n\n\nImportant\n\n\n\nAlways use na.rm = TRUE when working with financial data! Missing values are common and can break your calculations if not handled properly.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_pre_class.html#understanding-groups-a-powerful-way-to-organize-analysis",
    "href": "week_3_pre_class.html#understanding-groups-a-powerful-way-to-organize-analysis",
    "title": "5  Week 3: Find Actionable Insights, Quickly (Pre-Class)",
    "section": "5.6 Understanding Groups: A Powerful Way to Organize Analysis",
    "text": "5.6 Understanding Groups: A Powerful Way to Organize Analysis\nIf you’ve used Excel, you’re probably familiar with pivot tables - they let you organize data by categories and calculate summaries for each group. The group_by() function in R serves a similar purpose but is even more powerful. Just like in Excel when you:\n\nCreate a pivot table to see total lending by region\nCalculate what percent each project is of its country’s total\nFind the largest project in each sector\n\nIn R, group_by() lets you do all this and more. Let’s explore how it works using our mini dataset.\n\n5.6.1 Three Key Grouping Patterns\nThere are three main ways you’ll use grouping in your analysis:\n\nSummarize by Group: Calculate totals, averages, or counts for each group\nCalculate Within Groups: Create new columns based on group calculations\nFind Extremes Within Groups: Identify top/bottom values in each group\n\nLet’s look at each pattern:\n\n\n5.6.2 Pattern 1: Summarize by Group\nFirst, let’s see what happens without grouping:\n\n# Without grouping - one summary for everything\nmini_gcdf |&gt;\n  summarize(\n    total_amount_bn = sum(amount_constant_usd_2021) / 1e9,\n    avg_amount_bn = mean(amount_constant_usd_2021) / 1e9\n  )\n\n# A tibble: 1 × 2\n  total_amount_bn avg_amount_bn\n            &lt;dbl&gt;         &lt;dbl&gt;\n1            56.8          5.68\n\n# With grouping - summaries for each region\nmini_gcdf |&gt;\n  group_by(recipient_region) |&gt;\n  summarize(\n    total_amount_bn = sum(amount_constant_usd_2021) / 1e9,\n    avg_amount_bn = mean(amount_constant_usd_2021) / 1e9,\n    .groups = \"drop\"\n  )\n\n# A tibble: 3 × 3\n  recipient_region total_amount_bn avg_amount_bn\n  &lt;chr&gt;                      &lt;dbl&gt;         &lt;dbl&gt;\n1 Africa                      13.4          3.35\n2 America                     28.3         14.2 \n3 Asia                        15.1          3.78\n\n\n\n\n\n\n\n\nWhat’s Happening Here?\n\n\n\nWhen you group by recipient_region, R essentially:\n\nSplits the data into three pieces (Africa, America, Asia)\nRuns the calculations separately on each piece\nCombines the results back into one table\n\nThis is just like choosing “Region” as the row variable in a pivot table!\n\n\n\n\n5.6.3 Pattern 2: Calculate Within Groups\nSometimes you want to compare values within their group, like calculating each loan’s share of its regional total:\n\n# Calculate share of regional total\nmini_gcdf |&gt;\n  group_by(recipient_region) |&gt;\n  mutate(\n    region_total = sum(amount_constant_usd_2021),\n    share_of_region = amount_constant_usd_2021 / region_total * 100\n  ) |&gt;\n  select(recipient, recipient_region, amount_constant_usd_2021, share_of_region) |&gt;  # Just show relevant columns\n  ungroup()\n\n# A tibble: 10 × 4\n   recipient recipient_region amount_constant_usd_2021 share_of_region\n   &lt;chr&gt;     &lt;chr&gt;                               &lt;dbl&gt;           &lt;dbl&gt;\n 1 Angola    Africa                        8147551108.           60.8 \n 2 Angola    Africa                        3481817339.           26.0 \n 3 Indonesia Asia                          2853819092.           18.9 \n 4 Indonesia Asia                          2743140983.           18.2 \n 5 Pakistan  Asia                          4855813054.           32.1 \n 6 Pakistan  Asia                          4651162791.           30.8 \n 7 Venezuela America                      14402361186.           50.8 \n 8 Venezuela America                      13927269358.           49.2 \n 9 Zambia    Africa                         881870586.            6.58\n10 Zambia    Africa                         881870586.            6.58\n\n\n\n\n\n\n\n\nWhat’s Happening Here?\n\n\n\nFor each region:\n\nsum(amount_constant_usd_2021) adds up all loans in that region\nEach loan’s amount is divided by its region’s total\nThe share will always be between 0 and 100% within each region\n\nThis is similar to Excel’s “Show Values As” → “% of Parent Row Total” in pivot tables!\n\n\n\n\n5.6.4 Pattern 3: Find Extremes Within Groups\nOften you want to find the largest or smallest values within each group:\n\n# Largest loan in each region\nmini_gcdf |&gt;\n  group_by(recipient_region) |&gt;\n  slice_max(order_by = amount_constant_usd_2021, n = 1) |&gt;\n  ungroup()\n\n# A tibble: 3 × 5\n  recipient recipient_region sector_name  commitment_year amount_constant_usd_…¹\n  &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;                  &lt;int&gt;                  &lt;dbl&gt;\n1 Angola    Africa           ENERGY                  2016            8147551108.\n2 Venezuela America          OTHER MULTI…            2010           14402361186.\n3 Pakistan  Asia             BANKING AND…            2020            4855813054.\n# ℹ abbreviated name: ¹​amount_constant_usd_2021\n\n# Real world example: Top 3 loans by region\nget_gcdf3_dataset() |&gt;\n  filter(\n    recommended_for_aggregates == \"Yes\",\n    !is.na(amount_constant_usd_2021)\n  ) |&gt;\n  group_by(recipient_region) |&gt;\n  slice_max(order_by = amount_constant_usd_2021, n = 3) |&gt;\n  select(recipient_region, recipient, amount_constant_usd_2021, commitment_year) |&gt;\n  ungroup()\n\n# A tibble: 22 × 4\n   recipient_region recipient             amount_constant_usd_…¹ commitment_year\n   &lt;chr&gt;            &lt;chr&gt;                                  &lt;dbl&gt;           &lt;int&gt;\n 1 Africa           Angola                           8147551108.            2016\n 2 Africa           Angola                           3481817339.            2010\n 3 Africa           Democratic Republic …            3094756963.            2008\n 4 America          Argentina                       21421774753.            2018\n 5 America          Argentina                       21270602003.            2019\n 6 America          Argentina                       21041856567.            2020\n 7 Asia             Turkmenistan                     6008040193.            2009\n 8 Asia             Kazakhstan                       5717197207.            2008\n 9 Asia             Kazakhstan                       5717197207.            2008\n10 Europe           Russia                          37225206222.            2013\n# ℹ 12 more rows\n# ℹ abbreviated name: ¹​amount_constant_usd_2021\n\n\n\n\n\n\n\n\nWhat’s Happening Here?\n\n\n\nFor each region: 1. Sort loans by amount (largest to smallest) 2. Keep the top one (n = 1) or top three (n = 3) 3. Move on to the next region\nThis is like filtering a pivot table to show only the maximum value in each group!\n\n\n\n\n5.6.5 The Importance of ungroup()\nNotice how we often end with ungroup()? This is important! When you group data:\n\nThe grouping stays active until you explicitly remove it\nThis can affect later calculations in unexpected ways\nungroup() removes the grouping when you’re done with it\n\nLet’s see what can go wrong:\n\n# THIS IS WRONG! (still grouped when calculating overall_share)\nmini_gcdf |&gt;\n  group_by(recipient_region) |&gt;\n  mutate(\n    # This gives regional share (correct)\n    region_share = amount_constant_usd_2021 / sum(amount_constant_usd_2021),\n    # This gives same result because we're still grouped! (wrong)\n    overall_share = amount_constant_usd_2021 / sum(amount_constant_usd_2021)\n  )\n\n# A tibble: 10 × 7\n# Groups:   recipient_region [3]\n   recipient recipient_region sector_name commitment_year amount_constant_usd_…¹\n   &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;                 &lt;int&gt;                  &lt;dbl&gt;\n 1 Angola    Africa           ENERGY                 2016            8147551108.\n 2 Angola    Africa           OTHER SOCI…            2010            3481817339.\n 3 Indonesia Asia             INDUSTRY, …            2009            2853819092.\n 4 Indonesia Asia             TRANSPORT …            2017            2743140983.\n 5 Pakistan  Asia             BANKING AN…            2020            4855813054.\n 6 Pakistan  Asia             BANKING AN…            2021            4651162791.\n 7 Venezuela America          OTHER MULT…            2010           14402361186.\n 8 Venezuela America          OTHER MULT…            2010           13927269358.\n 9 Zambia    Africa           ENERGY                 2017             881870586.\n10 Zambia    Africa           ENERGY                 2017             881870586.\n# ℹ abbreviated name: ¹​amount_constant_usd_2021\n# ℹ 2 more variables: region_share &lt;dbl&gt;, overall_share &lt;dbl&gt;\n\n# THIS IS RIGHT! (ungroup before overall calculation)\nmini_gcdf |&gt;\n  group_by(recipient_region) |&gt;\n  mutate(\n    region_share = amount_constant_usd_2021 / sum(amount_constant_usd_2021)\n  ) |&gt;\n  ungroup() |&gt;\n  mutate(\n    overall_share = amount_constant_usd_2021 / sum(amount_constant_usd_2021)\n  )\n\n# A tibble: 10 × 7\n   recipient recipient_region sector_name commitment_year amount_constant_usd_…¹\n   &lt;chr&gt;     &lt;chr&gt;            &lt;chr&gt;                 &lt;int&gt;                  &lt;dbl&gt;\n 1 Angola    Africa           ENERGY                 2016            8147551108.\n 2 Angola    Africa           OTHER SOCI…            2010            3481817339.\n 3 Indonesia Asia             INDUSTRY, …            2009            2853819092.\n 4 Indonesia Asia             TRANSPORT …            2017            2743140983.\n 5 Pakistan  Asia             BANKING AN…            2020            4855813054.\n 6 Pakistan  Asia             BANKING AN…            2021            4651162791.\n 7 Venezuela America          OTHER MULT…            2010           14402361186.\n 8 Venezuela America          OTHER MULT…            2010           13927269358.\n 9 Zambia    Africa           ENERGY                 2017             881870586.\n10 Zambia    Africa           ENERGY                 2017             881870586.\n# ℹ abbreviated name: ¹​amount_constant_usd_2021\n# ℹ 2 more variables: region_share &lt;dbl&gt;, overall_share &lt;dbl&gt;\n\n\n\n\n\n\n\n\nWhen to ungroup()\n\n\n\n\nAfter summarize(): Usually automatic (but watch for warnings)\nAfter mutate(): If you’re done with group calculations\nAfter slice_*(): Almost always\nWhen in doubt: ungroup()! It never hurts.\n\n\n\n\n\n5.6.6 Real World Example: Time Series Analysis\nLet’s apply these patterns to analyze year-over-year changes in Angola’s loan commitments:\n\n# Calculate year-over-year changes\nangola_annual_flows |&gt;\n  mutate(\n    prev_year_amount = lag(total_amount),\n    yoy_change = (total_amount - prev_year_amount) / prev_year_amount * 100\n  ) |&gt;\n  filter(!is.na(yoy_change))  # Remove first year (no previous year to compare)\n\n# A tibble: 20 × 4\n   commitment_year total_amount prev_year_amount yoy_change\n             &lt;int&gt;        &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;\n 1            2002   489893161.        15087227.    3147.  \n 2            2003    26796701.       489893161.     -94.5 \n 3            2004   989972579.        26796701.    3594.  \n 4            2005  2857495673.       989972579.     189.  \n 5            2006  2453696747.      2857495673.     -14.1 \n 6            2007  3895910151.      2453696747.      58.8 \n 7            2008   198727773.      3895910151.     -94.9 \n 8            2009  3388534669.       198727773.    1605.  \n 9            2010  4300740778.      3388534669.      26.9 \n10            2011  2764770648.      4300740778.     -35.7 \n11            2012  1567120325.      2764770648.     -43.3 \n12            2013  5155360714.      1567120325.     229.  \n13            2014  4980964328.      5155360714.      -3.38\n14            2015  6206188709.      4980964328.      24.6 \n15            2016 17920526346.      6206188709.     189.  \n16            2017  2999075287.     17920526346.     -83.3 \n17            2018  4340735198.      2999075287.      44.7 \n18            2019   119578481.      4340735198.     -97.2 \n19            2020    64776546.       119578481.     -45.8 \n20            2021    79700000         64776546.      23.0 \n\n\n\n\n\n\n\n\nWhat’s Happening Here?\n\n\n\n\nlag(total_amount) gets the previous year’s value\nCalculate percent change from previous year\nRemove the first year (which has no previous year)\n\nThis kind of analysis is common when looking at lending trends over time!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_pre_class.html#common-transformation-patterns-in-development-finance",
    "href": "week_3_pre_class.html#common-transformation-patterns-in-development-finance",
    "title": "5  Week 3: Find Actionable Insights, Quickly (Pre-Class)",
    "section": "5.7 Common Transformation Patterns in Development Finance",
    "text": "5.7 Common Transformation Patterns in Development Finance\nNow that we understand both the basic operations and grouping, let’s look at some common patterns you’ll use when analyzing Chinese development finance data:\n\n5.7.1 Pattern 1: Annual Flows By Region\nThis pattern helps understand how lending varies across regions and time:\n\nget_gcdf3_dataset() |&gt;\n  filter(recommended_for_aggregates == \"Yes\") |&gt;\n  group_by(commitment_year, recipient_region) |&gt;\n  summarize(\n    total_amount_bn = sum(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    project_count = n(),\n    avg_project_size_bn = mean(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    .groups = \"drop\"\n  ) |&gt;\n  arrange(recipient_region, commitment_year)\n\n# A tibble: 147 × 5\n   commitment_year recipient_region total_amount_bn project_count\n             &lt;int&gt; &lt;chr&gt;                      &lt;dbl&gt;         &lt;int&gt;\n 1            2000 Africa                      1.35            80\n 2            2001 Africa                      3.09           110\n 3            2002 Africa                      2.68           126\n 4            2003 Africa                      4.24           144\n 5            2004 Africa                      2.64           150\n 6            2005 Africa                      7.10           215\n 7            2006 Africa                      7.42           274\n 8            2007 Africa                     15.9            351\n 9            2008 Africa                     12.4            295\n10            2009 Africa                     16.5            342\n# ℹ 137 more rows\n# ℹ 1 more variable: avg_project_size_bn &lt;dbl&gt;\n\n\n\n\n5.7.2 Pattern 2: Portfolio Composition\nUnderstanding the sectoral focus of lending:\n\nget_gcdf3_dataset() |&gt;\n  filter(\n    recommended_for_aggregates == \"Yes\",\n    commitment_year &gt;= 2018  # Focus on recent years\n  ) |&gt;\n  group_by(sector_name) |&gt;\n  summarize(\n    total_amount_bn = sum(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    project_count = n(),\n    avg_amount_bn = mean(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    .groups = \"drop\"\n  ) |&gt;\n  arrange(desc(total_amount_bn)) |&gt;\n  slice_head(n = 10)  # Top 10 sectors\n\n# A tibble: 10 × 4\n   sector_name                    total_amount_bn project_count avg_amount_bn\n   &lt;chr&gt;                                    &lt;dbl&gt;         &lt;int&gt;         &lt;dbl&gt;\n 1 BANKING AND FINANCIAL SERVICES          143.             163       0.897  \n 2 INDUSTRY, MINING, CONSTRUCTION           56.5            205       0.304  \n 3 TRANSPORT AND STORAGE                    54.7            315       0.215  \n 4 ENERGY                                   43.4            210       0.241  \n 5 GENERAL BUDGET SUPPORT                   24.0             43       0.572  \n 6 COMMUNICATIONS                            7.78           124       0.101  \n 7 UNALLOCATED/UNSPECIFIED                   7.06            70       0.116  \n 8 BUSINESS AND OTHER SERVICES               6.80            78       0.101  \n 9 OTHER MULTISECTOR                         5.59           101       0.119  \n10 HEALTH                                    4.23          2314       0.00311\n\n\n\n\n5.7.3 Pattern 3: Country Risk Analysis\nAnalyzing lending patterns for specific countries:\n\nget_gcdf3_dataset() |&gt;\n  filter(\n    recommended_for_aggregates == \"Yes\",\n    recipient %in% c(\"Angola\", \"Kenya\", \"Ethiopia\")\n  ) |&gt;\n  group_by(recipient, flow_class) |&gt;\n  summarize(\n    total_amount_bn = sum(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    project_count = n(),\n    .groups = \"drop\"\n  ) |&gt;\n  arrange(recipient, desc(total_amount_bn))\n\n# A tibble: 9 × 4\n  recipient flow_class               total_amount_bn project_count\n  &lt;chr&gt;     &lt;chr&gt;                              &lt;dbl&gt;         &lt;int&gt;\n1 Angola    OOF-like                          54.8             202\n2 Angola    Vague (Official Finance)          10.0              65\n3 Angola    ODA-like                           0.310           101\n4 Ethiopia  OOF-like                          18.0              64\n5 Ethiopia  ODA-like                           3.09            187\n6 Ethiopia  Vague (Official Finance)           0.276            10\n7 Kenya     OOF-like                           9.56             42\n8 Kenya     ODA-like                           2.80            152\n9 Kenya     Vague (Official Finance)           0.884            14",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_pre_class.html#practice-exercises",
    "href": "week_3_pre_class.html#practice-exercises",
    "title": "5  Week 3: Find Actionable Insights, Quickly (Pre-Class)",
    "section": "5.8 Practice Exercises",
    "text": "5.8 Practice Exercises\nTry these exercises to get comfortable with data transformation. Remember to use AI tools if you get stuck!\n\n5.8.1 Exercise 1: Basic Filtering\nFind all projects that are:\n\nODA-like or OOF-like\nCommitted between 2018-2021\nWorth at least $100 million\n\n\n\n5.8.2 Exercise 2: Regional Analysis\nFor each region, calculate:\n\nTotal lending volume\nNumber of projects\nAverage project size\nNumber of recipient countries\n\n\n\n5.8.3 Exercise 3: Sector Trends\nAnalyze how sector composition has changed:\n\nCompare 2013-2017 vs 2018-2021\nLook at both volume and project counts\nFocus on the top 5 sectors by volume\n\n\n\n\n\n\n\nGetting Help\n\n\n\nIf you get stuck:\n\nCheck the dplyr cheatsheet\nAsk AI tools for help\nLook at similar examples in this guide\nPost questions in our course Slack",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_pre_class.html#resources-for-learning-more",
    "href": "week_3_pre_class.html#resources-for-learning-more",
    "title": "5  Week 3: Find Actionable Insights, Quickly (Pre-Class)",
    "section": "5.9 Resources for Learning More",
    "text": "5.9 Resources for Learning More\n\n5.9.1 Essential References\n\nR for Data Science - Data Transformation\n\nComprehensive guide to dplyr\nMany practical examples\nFree online!\n\ndplyr cheatsheet\n\nQuick reference for common operations\nGreat to keep handy while working\n\n\n\n\n5.9.2 Video Tutorials\n\nAnimated versions of common dplyr functions\n\nClear, beginner-friendly overview\nShows live coding examples\nPerfect for visual learners",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_pre_class.html#next-steps",
    "href": "week_3_pre_class.html#next-steps",
    "title": "5  Week 3: Find Actionable Insights, Quickly (Pre-Class)",
    "section": "5.10 Next Steps",
    "text": "5.10 Next Steps\nIn our class session, we’ll:\n\nReview any questions about these concepts\nPractice more complex transformations\nWork with real analysis questions\nLearn some advanced dplyr features\n\nRemember: The goal isn’t to memorize every function, but to understand the basic patterns of data transformation. With these five core verbs and the pipe operator, you can handle most analysis tasks!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_in_class.html",
    "href": "week_3_in_class.html",
    "title": "6  Week 3: Find Actionable Insights, Quickly (In-Class)",
    "section": "",
    "text": "6.1 Today’s Agenda (90 minutes)",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_in_class.html#todays-agenda-90-minutes",
    "href": "week_3_in_class.html#todays-agenda-90-minutes",
    "title": "6  Week 3: Find Actionable Insights, Quickly (In-Class)",
    "section": "",
    "text": "Understanding Pivoting Power (25 min)\n\nWhy pivot at all? The insight toolkit concept\nDemo with mini dataset:\n\nHow humans naturally organize data (wide)\nWhy computers prefer tidy data (long)\nCreating insights through strategic pivoting\n\nKey pattern: longer-&gt;group-&gt;analyze-&gt;wider-&gt;compare\n\nLive Demo: Finding Non-Obvious Insights (20 min)\n\nExample: Comparing lending patterns\n\nPivot longer to analyze by group\nCalculate shares and growth rates\nPivot wider to compare countries/regions\nCreate “repeatable factoids”\n\nPattern recognition in Chinese development finance\n\nGuided Practice & Exploration (40 min)\n\nSuggested research questions like:\n\nHow has the sectoral composition of lending changed pre/post BRI?\nWhich countries have seen the biggest shifts in lending patterns?\nWhat regions show similar lending trajectories?\n\nSupport for individual exploration\nCreating compelling visualizations from insights\n\nShare Discoveries (5 min)\n\nQuick highlights of interesting findings\nPreview of next week’s data import & cleaning",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_in_class.html#learning-objectives",
    "href": "week_3_in_class.html#learning-objectives",
    "title": "6  Week 3: Find Actionable Insights, Quickly (In-Class)",
    "section": "6.2 Learning Objectives",
    "text": "6.2 Learning Objectives\nBy the end of this session, you will be able to:\n\nUnderstand tidy data principles and how they enable powerful data analysis\nUse pivoting strategically as a tool for finding meaningful patterns in data\nCreate clear comparisons that highlight key changes in lending patterns\nGenerate “repeatable factoids” that effectively communicate insights\nApply these techniques to find non-obvious patterns in Chinese development finance data\n\n\n\n\n\n\n\nWhy This Matters for TUFF Analysis\n\n\n\nThe skills you’re learning today directly support your work on the TUFF Initiative:\nData Analysis - Find patterns in project-level data more efficiently - Calculate changes in lending patterns over time - Compare lending across regions, sectors, and time periods - Generate insights for briefs and reports\nCommon TUFF Tasks Made Easier - Analyze how source quality varies across different types of projects - Track changes in sectoral composition of lending - Compare lending patterns before and after key events - Calculate shares of lending by region or country - Find similar projects across countries\nReal Benefits - Turn repetitive Excel tasks into efficient R workflows - Spend less time manipulating data, more time finding insights - Create consistent analysis across projects - Generate reproducible factoids for reports - Make compelling visualizations of findings\nRemember: While the “pivot dance” might seem abstract at first, it’s a powerful tool for the exact kind of analysis you do every day with Chinese overseas lending data.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_in_class.html#todays-video-lecture",
    "href": "week_3_in_class.html#todays-video-lecture",
    "title": "6  Week 3: Find Actionable Insights, Quickly (In-Class)",
    "section": "6.3 Today’s Video Lecture",
    "text": "6.3 Today’s Video Lecture\nWatch this video lecture to review the concepts from class 3:",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_in_class.html#setup",
    "href": "week_3_in_class.html#setup",
    "title": "6  Week 3: Find Actionable Insights, Quickly (In-Class)",
    "section": "6.4 Setup",
    "text": "6.4 Setup\nLet’s get our workspace ready. First, create a new Quarto document for your notes:\n# Create a new Quarto document\n# File → New File → Quarto Document\n# Save as \"week_3_transformation_in_class.qmd\" in your week_3/R folder\nInstall a few new packages:\n\npak::pkg_install(\n  c(\n    \"slider\",   # for rolling calculations\n    \"janitor\",  # for making column names snake_case\n    \"widyr\",    # for tidy correlation calculation\n    \"pheatmap\"  # for correlation matrix visualization\n  )\n )\n\nLoad the packages we’ll need:\n\nlibrary(tidyverse)    # For data transformation tools\nlibrary(janitor)      # for making column names snake_case\nlibrary(slider)       # for rolling calculations\nlibrary(widyr)        # for tidy correlation calculation\nlibrary(pheatmap)     # for correlation matrix visualization\nlibrary(chinadevfin3) # For Chinese development finance data\nlibrary(aiddataviz)   # For AidData themed visualizations",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_in_class.html#understanding-the-power-of-tidy-data-25-minutes",
    "href": "week_3_in_class.html#understanding-the-power-of-tidy-data-25-minutes",
    "title": "6  Week 3: Find Actionable Insights, Quickly (In-Class)",
    "section": "6.5 Understanding the Power of Tidy Data (25 minutes)",
    "text": "6.5 Understanding the Power of Tidy Data (25 minutes)\n\n6.5.1 The “Aha!” Moment: Why Tidy Data Matters\nThink of tidy data as the foundation of a building - get it right, and everything else becomes easier. Just as a well-organized kitchen makes cooking efficient, tidy data makes analysis smooth. It’s the secret ingredient that makes the tidyverse work.\nThree simple rules make data tidy\n\nEach variable is a column\nEach observation is a row\nEach value is a cell\n\n\n\n6.5.2 Why This Matters: A Concrete Example\nLet’s look at our mini dataset from pre-class in both “natural” and “tidy” formats:\n\n# How we often see data (wide format)\nmini_loans &lt;- tribble(\n  ~country,      ~\"2018\",  ~\"2019\",  ~\"2020\",\n  \"Angola\",         1.2,     2.1,     0.8,\n  \"Pakistan\",       2.3,     1.7,     3.1,\n  \"Indonesia\",      1.8,     2.2,     1.5\n)\n\nmini_loans\n\n# A tibble: 3 × 4\n  country   `2018` `2019` `2020`\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Angola       1.2    2.1    0.8\n2 Pakistan     2.3    1.7    3.1\n3 Indonesia    1.8    2.2    1.5\n\n# Same data in tidy format\nmini_loans_tidy &lt;- mini_loans |&gt;\n  pivot_longer(\n    cols = c(\"2018\", \"2019\", \"2020\"),\n    names_to = \"year\",\n    values_to = \"amount_bn\"\n  )\n\nmini_loans_tidy\n\n# A tibble: 9 × 3\n  country   year  amount_bn\n  &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n1 Angola    2018        1.2\n2 Angola    2019        2.1\n3 Angola    2020        0.8\n4 Pakistan  2018        2.3\n5 Pakistan  2019        1.7\n6 Pakistan  2020        3.1\n7 Indonesia 2018        1.8\n8 Indonesia 2019        2.2\n9 Indonesia 2020        1.5\n\n\nWatch what happens when we try to answer these questions:\n\nWhich country had the highest total lending?\n\nWide format (harder):\n\nmini_loans |&gt;\n  mutate(total = `2018` + `2019` + `2020`) |&gt;\n  arrange(desc(total))\n\n# A tibble: 3 × 5\n  country   `2018` `2019` `2020` total\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Pakistan     2.3    1.7    3.1   7.1\n2 Indonesia    1.8    2.2    1.5   5.5\n3 Angola       1.2    2.1    0.8   4.1\n\n\nImagine what this would look like if you had 30 years of data? Or if you wanted to switch years? It’s a pain.\nTidy format (easier):\n\nmini_loans_tidy |&gt;\n  group_by(country) |&gt;\n  summarize(total = sum(amount_bn)) |&gt;\n  arrange(desc(total))\n\n# A tibble: 3 × 2\n  country   total\n  &lt;chr&gt;     &lt;dbl&gt;\n1 Pakistan    7.1\n2 Indonesia   5.5\n3 Angola      4.1\n\n\n\nWhat was the year-over-year growth in lending?\n\nWide format (much harder):\n\nmini_loans |&gt;\n  mutate(\n    growth_18_19 = (`2019` - `2018`) / `2018` * 100,\n    growth_19_20 = (`2020` - `2019`) / `2019` * 100\n  )\n\n# A tibble: 3 × 6\n  country   `2018` `2019` `2020` growth_18_19 growth_19_20\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 Angola       1.2    2.1    0.8         75          -61.9\n2 Pakistan     2.3    1.7    3.1        -26.1         82.4\n3 Indonesia    1.8    2.2    1.5         22.2        -31.8\n\n\nTidy format (clearer):\n\nmini_loans_tidy |&gt;\n  group_by(country) |&gt;\n  arrange(year) |&gt;\n  mutate(\n    growth = (amount_bn - lag(amount_bn)) / lag(amount_bn) * 100\n  )\n\n# A tibble: 9 × 4\n# Groups:   country [3]\n  country   year  amount_bn growth\n  &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 Angola    2018        1.2   NA  \n2 Pakistan  2018        2.3   NA  \n3 Indonesia 2018        1.8   NA  \n4 Angola    2019        2.1   75  \n5 Pakistan  2019        1.7  -26.1\n6 Indonesia 2019        2.2   22.2\n7 Angola    2020        0.8  -61.9\n8 Pakistan  2020        3.1   82.4\n9 Indonesia 2020        1.5  -31.8\n\n\n\n\n\n\n\n\nWorking with Column Names: backticks vs clean_names()\n\n\n\nWhen working with messy column names, you’ll often need to handle spaces, special characters, or numbers at the start of names. Let’s look at your options:\n\n# Example dataset with messy column names\nmessy_names &lt;- tribble(\n  ~\"Country Name\",  ~\"2021 Amount\", ~\"% Change\",  ~\"Current.Status\",\n  \"Angola\",            1.2,            15,         \"Active\",\n  \"Pakistan\",          2.3,            -5,         \"Delayed\",\n  \"Indonesia\",         1.8,            10,         \"Active\"\n)\n\n# Look at original names\nnames(messy_names)\n\n[1] \"Country Name\"   \"2021 Amount\"    \"% Change\"       \"Current.Status\"\n\n# See what clean_names() does\nmessy_names |&gt;\n  clean_names() |&gt;\n  names()\n\n[1] \"country_name\"   \"x2021_amount\"   \"percent_change\" \"current_status\"\n\n\nclean_names() transforms column names to snake_case, which means:\n\nAll lowercase letters\nSpaces and dots replaced with underscores\nSpecial characters removed\nNumbers get an ‘x’ prefix\nNo spaces or special characters\n\nFor example:\n\n“Country Name” → “country_name”\n“2021 Amount” → “x2021_amount”\n“% Change” → “percent_change”\n“Current.Status” → “current_status”\n\nWhen to use clean_names():\n\nWorking with data you’ll analyze extensively\nWhen column names are inconsistent or messy\nIf you’re primarily doing analysis in R\n\nWhen to stick with backticks:\n\nIf you plan to pivot column names into observations\nWhen preserving original column formatting is important\nWhen working with data that will be exported back to other systems\n\nPro tip: If you need to restore original names later:\n\n# Store original names\noriginal_names &lt;- names(messy_names)\n\n# Clean for analysis\nclean_data &lt;- messy_names |&gt;\n  clean_names()\n\n# Analysis here...\n\n# Restore original names if needed\nnames(clean_data) &lt;- original_names\n\n\n\n\n\n6.5.3 The Pivoting Power Tools\nThink of pivot_longer() and pivot_wider() as power tools for data analysis:\n\npivot_longer(): Gets data ready for analysis\n\nMakes grouped calculations easy\nPerfect for time series analysis\nGreat for aesthetic mapping in ggplot2\n\npivot_wider(): Helps compare and present\n\nCreates comparison columns\nMakes it easy to calculate differences\nGreat for presentation tables\n\n\n\n\n6.5.4 Key Pattern: The Pivot Dance\nMany powerful insights come from this pattern:\n\nStart wide (how we get data)\nPivot longer (to analyze)\nDo calculations\nPivot wider (to compare)\nFind insights\n\nLet’s see this in action with Chinese development finance data…",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_in_class.html#live-demo-finding-non-obvious-insights-20-minutes",
    "href": "week_3_in_class.html#live-demo-finding-non-obvious-insights-20-minutes",
    "title": "6  Week 3: Find Actionable Insights, Quickly (In-Class)",
    "section": "6.6 Live Demo: Finding Non-Obvious Insights (20 minutes)",
    "text": "6.6 Live Demo: Finding Non-Obvious Insights (20 minutes)\n\n6.6.1 Setting Up Our Investigation\nLet’s use what we just learned to investigate something interesting: How has Chinese development finance shifted between regions and countries over time? This is a perfect example where pivoting can reveal patterns that aren’t obvious at first glance.\n\n# First, let's get our annual lending data by country\ncountry_lending &lt;- get_gcdf3_dataset() |&gt;\n  filter(recommended_for_aggregates == \"Yes\") |&gt;\n  select(\n    country_name,\n    commitment_year,\n    amount_constant_usd_2021,\n    flow_class\n  )\n\ncountry_lending\n\n# A tibble: 17,957 × 4\n   country_name commitment_year amount_constant_usd_2021 flow_class\n   &lt;chr&gt;                  &lt;int&gt;                    &lt;dbl&gt; &lt;chr&gt;     \n 1 Afghanistan             2021                 7111456. ODA-like  \n 2 Afghanistan             2021                12600000  ODA-like  \n 3 Afghanistan             2021                14400000  ODA-like  \n 4 Afghanistan             2021                13000000  ODA-like  \n 5 Afghanistan             2021                 7500000  ODA-like  \n 6 Afghanistan             2021                      NA  ODA-like  \n 7 Afghanistan             2021                 3600000  ODA-like  \n 8 Afghanistan             2021                      NA  ODA-like  \n 9 Afghanistan             2021                      NA  ODA-like  \n10 Afghanistan             2021                      NA  ODA-like  \n# ℹ 17,947 more rows\n\n\n\n\n6.6.2 Why Pivot? A Simple Example\nBefore we dive into complex analysis, let’s understand why pivoting helps. Imagine trying to answer this question: “For each country, what share of total Chinese lending did they receive in each year?”\nHere’s why this is tricky: 1. We need totals by year (denominator) 2. We need each country’s amount by year (numerator) 3. We need to divide these to get shares\nLet’s do this step by step:\n\n# Step 1: Calculate yearly totals\nyearly_totals &lt;- country_lending |&gt;\n  group_by(commitment_year) |&gt;\n  summarize(\n    total_lending = sum(amount_constant_usd_2021, na.rm = TRUE),\n    .groups = \"drop\"\n  )\nyearly_totals\n\n# A tibble: 22 × 2\n   commitment_year total_lending\n             &lt;int&gt;         &lt;dbl&gt;\n 1            2000   5449254748.\n 2            2001   7865090260.\n 3            2002   7583262571.\n 4            2003  10898980576.\n 5            2004   9633489123.\n 6            2005  30759430968.\n 7            2006  34404872463.\n 8            2007  37657969766.\n 9            2008  43062533399.\n10            2009 124014128471.\n# ℹ 12 more rows\n\n# Step 2: Calculate each country's yearly amount\ncountry_shares &lt;- country_lending |&gt;\n  group_by(commitment_year, country_name) |&gt;\n  summarize(\n    country_amount = sum(amount_constant_usd_2021, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  # Join with totals\n  left_join(yearly_totals, by = \"commitment_year\") |&gt;\n  # Calculate shares\n  mutate(share = country_amount / total_lending * 100)\n\ncountry_shares\n\n# A tibble: 2,594 × 5\n   commitment_year country_name     country_amount total_lending  share\n             &lt;int&gt; &lt;chr&gt;                     &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1            2000 Afghanistan            1283228.   5449254748. 0.0235\n 2            2000 Africa, regional             0    5449254748. 0     \n 3            2000 Albania                3079748.   5449254748. 0.0565\n 4            2000 Algeria                      0    5449254748. 0     \n 5            2000 Angola                       0    5449254748. 0     \n 6            2000 Bangladesh           284264555.   5449254748. 5.22  \n 7            2000 Belarus                1550075.   5449254748. 0.0284\n 8            2000 Benin                 46502250.   5449254748. 0.853 \n 9            2000 Botswana               6042354.   5449254748. 0.111 \n10            2000 Bulgaria               1550075.   5449254748. 0.0284\n# ℹ 2,584 more rows\n\n\n\n\n\n\n\n\nWhy This is Hard to Read\n\n\n\nNotice how this data is now in “long” format - each row is a country-year observation. While this is great for calculation, it’s hard to see patterns. For instance, can you easily tell how Angola’s share has changed over time compared to Ethiopia’s?\nThis is where strategic pivoting comes in!\n\n\n\n\n6.6.3 The Pivot Dance: Making Comparisons Clear\nLet’s use our “pivot dance” pattern to make this more insightful:\n\n# Pivot wider to compare countries over time\ncountry_shares_wide &lt;- country_shares |&gt;\n  select(commitment_year, country_name, share) |&gt;\n  pivot_wider(\n    names_from = commitment_year,\n    values_from = share,\n    values_fill = 0\n  )\n\ncountry_shares_wide\n\n# A tibble: 153 × 23\n   country_name     `2000`  `2001` `2002` `2003`   `2004`  `2005` `2006`  `2007`\n   &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 Afghanistan      0.0235  0.0358 0.237  0.159   0.759   0.183   0.0775 6.70e-2\n 2 Africa, regional 0       0.0637 0      0       0.00286 0       1.33   0      \n 3 Albania          0.0565  1.27   0      0.0145  0.0712  0.00871 0      0      \n 4 Algeria          0       0      0      0.461   0.0286  0.212   0      2.45e-3\n 5 Angola           0       0.211  6.52   0.246  10.3     9.30    7.14   1.04e+1\n 6 Bangladesh       5.22   10.2    0.637  0       0.0224  0.366   0.0370 1.11e-2\n 7 Belarus          0.0284  0.0384 0.0398 0.0141  0.0143  1.67    0      2.49e-1\n 8 Benin            0.853   0.309  0.901  0       0.0534  0.552   0.0222 1.01e-1\n 9 Botswana         0.111   0.454  0      0.748   0       0       0.159  9.37e-2\n10 Bulgaria         0.0284  0.660  0      0       0       0.00438 0      3.77e-4\n# ℹ 143 more rows\n# ℹ 14 more variables: `2008` &lt;dbl&gt;, `2009` &lt;dbl&gt;, `2010` &lt;dbl&gt;, `2011` &lt;dbl&gt;,\n#   `2012` &lt;dbl&gt;, `2013` &lt;dbl&gt;, `2014` &lt;dbl&gt;, `2015` &lt;dbl&gt;, `2016` &lt;dbl&gt;,\n#   `2017` &lt;dbl&gt;, `2018` &lt;dbl&gt;, `2019` &lt;dbl&gt;, `2020` &lt;dbl&gt;, `2021` &lt;dbl&gt;\n\n# Now we can easily see how shares have changed\ncountry_shares_wide |&gt;\n  # Calculate change in share from 2013 to 2021\n  mutate(\n    share_change = `2021` - `2013`\n  ) |&gt;\n  arrange(desc(share_change)) |&gt;\n  head(10) |&gt;  # Top 10 countries with increasing shares \n  select(\n    country_name,\n    share_change,\n    `2013`,\n    `2021`\n  )\n\n# A tibble: 10 × 4\n   country_name share_change  `2013` `2021`\n   &lt;chr&gt;               &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 Argentina           25.6  0.00349  25.7 \n 2 Pakistan            14.1  2.06     16.2 \n 3 Turkey              10.8  0.122    10.9 \n 4 Egypt                4.77 0         4.77\n 5 Iraq                 2.64 0.401     3.04\n 6 Sri Lanka            2.53 0.603     3.13\n 7 Sierra Leone         2.51 0.0850    2.60\n 8 Brazil               2.21 0.200     2.41\n 9 Bangladesh           1.68 0.323     2.00\n10 Mongolia             1.34 1.02      2.37\n\n\n\n\n\n\n\n\nThe Power of Pivoting\n\n\n\nNotice what just happened:\n\nWe started with country-year data (long format)\nDid our calculations (shares)\nPivoted wider to make years into columns\nCould easily calculate changes across years\n\nThis would be much harder without pivoting!\n\n\n\n\n6.6.4 Finding “Repeatable Factoids”\nOne of the most valuable skills in data analysis is finding “repeatable factoids” - clear, specific insights that tell a story. Let’s use our pivoted data to find some:\n\n# Focus on BRI corridor countries\nbri_changes &lt;- country_shares_wide |&gt;\n  filter(country_name %in% c(\n    \"Pakistan\", \"Kazakhstan\", \"Indonesia\",\n    \"Vietnam\", \"Bangladesh\"\n  )) |&gt;\n  mutate(\n    early_bri = (`2014` + `2015` + `2016` + `2017`) / 4,  # Average early BRI\n    late_bri = (`2018` + `2019` + `2020` + `2021`) / 4    # Average late BRI\n  )\n\n# Calculate the biggest changes\nbri_changes |&gt;\n  mutate(\n    change = (late_bri - early_bri),\n    pct_change = (late_bri / early_bri - 1) * 100\n  ) |&gt;\n  arrange(desc(change)) |&gt; \n  select(\n    country_name,\n    early_bri:pct_change # select all columns btw early_bri and pct_change\n  )\n\n# A tibble: 5 × 5\n  country_name early_bri late_bri change pct_change\n  &lt;chr&gt;            &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Pakistan         8.88    12.4    3.48        39.2\n2 Bangladesh       0.807    3.47   2.67       331. \n3 Kazakhstan       2.18     1.43  -0.754      -34.6\n4 Vietnam          2.23     0.847 -1.39       -62.1\n5 Indonesia        4.80     1.95  -2.85       -59.5\n\n\n\n\n\n\n\n\nFrom Numbers to Insights\n\n\n\nThis analysis might reveal something like: “Pakistan’s share of Chinese development finance increased from X% before BRI to Y% after BRI, a Z-fold increase.”\nThese kinds of clear, specific insights are powerful in reports and presentations!\n\n\n\n\n6.6.5 The Pivot Dance, Visualized\nLet’s revisit the steps we just took:\n\n\n\n\n\nflowchart TD\n    subgraph Pattern\n        A[Wide Data] --&gt;|pivot_longer| B[Long Data]\n        B --&gt;|group_by & calculate| C[Analysis Results]\n        C --&gt;|pivot_wider| D[Comparison View]\n        D --&gt;|mutate| E[Final Insights]\n    end\n\n    subgraph Example[Chinese Development Finance Example]\n        A1[Years as Columns] --&gt;|pivot_longer| B1[Year Column]\n        B1 --&gt;|group_by country,&lt;br&gt;calculate shares| C1[Country Shares by Year]\n        C1 --&gt;|pivot_wider| D1[Years as Columns Again]\n        D1 --&gt;|calculate changes| E1[Share Changes Over Time]\n    end\n\n    style Pattern fill:#f0f7ff,stroke:#4a90e2\n    style Example fill:#fff3e0,stroke:#f5a623\n    style A1 fill:#e8f5e9\n    style B1 fill:#e8f5e9\n    style C1 fill:#e8f5e9\n    style D1 fill:#e8f5e9\n    style E1 fill:#e8f5e9\n\n\n\n\n\n\n\n\n6.6.6 Your Turn: More Complex Patterns\nLet’s try something more sophisticated. What if we want to understand how the composition of lending (ODA-like vs OOF-like) has changed in different regions?\n\n# Start with the data\nlending_composition &lt;- get_gcdf3_dataset() |&gt;\n  filter(recommended_for_aggregates == \"Yes\") |&gt;\n  group_by(commitment_year, recipient_region, flow_class) |&gt;\n  summarize(\n    amount_bn = sum(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    .groups = \"drop\"\n  )\nlending_composition\n\n# A tibble: 371 × 4\n   commitment_year recipient_region flow_class               amount_bn\n             &lt;int&gt; &lt;chr&gt;            &lt;chr&gt;                        &lt;dbl&gt;\n 1            2000 Africa           ODA-like                   0.359  \n 2            2000 Africa           OOF-like                   0.994  \n 3            2000 America          ODA-like                   0.0890 \n 4            2000 America          OOF-like                   0      \n 5            2000 America          Vague (Official Finance)   0      \n 6            2000 Asia             ODA-like                   0.964  \n 7            2000 Asia             OOF-like                   2.55   \n 8            2000 Europe           ODA-like                   0.00308\n 9            2000 Europe           OOF-like                   0.00438\n10            2000 Middle East      ODA-like                   0.00248\n# ℹ 361 more rows\n\n# Now let's pivot to make comparisons easy\ncomposition_wide &lt;- lending_composition |&gt;\n  pivot_wider(\n    names_from = flow_class,\n    values_from = amount_bn,\n    values_fill = 0 # what to put when there is no value\n  ) |&gt;\n  mutate(\n    total = `ODA-like` + `OOF-like` + `Vague (Official Finance)`,\n    oda_share = `ODA-like` / total * 100\n  )\n\ncomposition_wide\n\n# A tibble: 147 × 7\n   commitment_year recipient_region `ODA-like` `OOF-like` Vague (Official Fina…¹\n             &lt;int&gt; &lt;chr&gt;                 &lt;dbl&gt;      &lt;dbl&gt;                  &lt;dbl&gt;\n 1            2000 Africa              0.359      0.994                  0      \n 2            2000 America             0.0890     0                      0      \n 3            2000 Asia                0.964      2.55                   0      \n 4            2000 Europe              0.00308    0.00438                0      \n 5            2000 Middle East         0.00248    0.416                  0      \n 6            2000 Oceania             0.0272     0.0276                 0.0128 \n 7            2001 Africa              2.56       0.505                  0.0234 \n 8            2001 America             0.0804     0.880                  0.00911\n 9            2001 Asia                0.834      1.53                   0.0714 \n10            2001 Europe              0.0121     0.0589                 0.0996 \n# ℹ 137 more rows\n# ℹ abbreviated name: ¹​`Vague (Official Finance)`\n# ℹ 2 more variables: total &lt;dbl&gt;, oda_share &lt;dbl&gt;\n\n\n\n\n\n\n\n\nWhy This Pattern Works\n\n\n\n\nGroup and summarize first (get the numbers we want)\nPivot wider to create columns for each flow class\nCalculate new metrics using these columns\nReady for visualization or further analysis!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_in_class.html#guided-practice-exploration-40-minutes",
    "href": "week_3_in_class.html#guided-practice-exploration-40-minutes",
    "title": "6  Week 3: Find Actionable Insights, Quickly (In-Class)",
    "section": "6.7 Guided Practice & Exploration (40 minutes)",
    "text": "6.7 Guided Practice & Exploration (40 minutes)\n\n6.7.1 Research Questions to Explore\nHere are several interesting questions about Chinese development finance that we can investigate using our pivoting toolkit. Feel free to explore these or follow your own curiosity!\n\n\n6.7.2 Question Set 1: Regional Patterns & Shifts\n\nRegional Focus Shifts\n\nHow has China’s regional focus changed before and after BRI?\nWhich regions have seen the biggest changes in their share of total lending?\nAre there regions that show similar patterns over time?\n\n\nHere’s a starting point:\n\n# Start with annual regional totals\nregional_patterns &lt;- get_gcdf3_dataset() |&gt;\n  filter(recommended_for_aggregates == \"Yes\") |&gt;\n  group_by(commitment_year, recipient_region) |&gt;\n  summarize(\n    amount_bn = sum(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    .groups = \"drop\"\n  )\n\nregional_patterns\n\n# A tibble: 147 × 3\n   commitment_year recipient_region amount_bn\n             &lt;int&gt; &lt;chr&gt;                &lt;dbl&gt;\n 1            2000 Africa             1.35   \n 2            2000 America            0.0890 \n 3            2000 Asia               3.51   \n 4            2000 Europe             0.00746\n 5            2000 Middle East        0.419  \n 6            2000 Oceania            0.0677 \n 7            2001 Africa             3.09   \n 8            2001 America            0.970  \n 9            2001 Asia               2.44   \n10            2001 Europe             0.171  \n# ℹ 137 more rows\n\n# Pivot to calculate regional shares over time\nregional_shares &lt;- regional_patterns |&gt;\n  group_by(commitment_year) |&gt;\n  mutate(\n    year_total = sum(amount_bn),\n    share = amount_bn / year_total * 100\n  ) |&gt;\n  ungroup()\n\nregional_shares\n\n# A tibble: 147 × 5\n   commitment_year recipient_region amount_bn year_total  share\n             &lt;int&gt; &lt;chr&gt;                &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n 1            2000 Africa             1.35          5.45 24.8  \n 2            2000 America            0.0890        5.45  1.63 \n 3            2000 Asia               3.51          5.45 64.5  \n 4            2000 Europe             0.00746       5.45  0.137\n 5            2000 Middle East        0.419         5.45  7.69 \n 6            2000 Oceania            0.0677        5.45  1.24 \n 7            2001 Africa             3.09          7.87 39.3  \n 8            2001 America            0.970         7.87 12.3  \n 9            2001 Asia               2.44          7.87 31.0  \n10            2001 Europe             0.171         7.87  2.17 \n# ℹ 137 more rows\n\n# Now you could:\n# 1. Pivot wider to compare regions\n# 2. Calculate changes between periods\n# 3. Visualize the trends\n\n\n\n6.7.3 Question Set 2: Sector Evolution\n\nSectoral Changes\n\nWhich sectors dominated pre-BRI vs post-BRI?\nAre certain sectors more prominent in certain regions?\nHas the average project size changed differently across sectors?\n\n\nTry this approach:\n\n# Look at sector patterns\nsector_patterns &lt;- get_gcdf3_dataset() |&gt;\n  filter(recommended_for_aggregates == \"Yes\") |&gt;\n  mutate(\n    period = if_else(\n      commitment_year &gt;= 2014,\n      \"Post-BRI (2014-2021)\",\n      \"Pre-BRI (2000-2013)\"\n    )\n  ) |&gt;\n  group_by(period, sector_name) |&gt;\n  summarize(\n    total_amount_bn = sum(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    project_count = n(),\n    avg_size_bn = total_amount_bn / project_count,\n    .groups = \"drop\"\n  )\n\nsector_patterns\n\n# A tibble: 48 × 5\n   period               sector_name    total_amount_bn project_count avg_size_bn\n   &lt;chr&gt;                &lt;chr&gt;                    &lt;dbl&gt;         &lt;int&gt;       &lt;dbl&gt;\n 1 Post-BRI (2014-2021) ACTION RELATI…           6.76            190     0.0356 \n 2 Post-BRI (2014-2021) AGRICULTURE, …           5.77            401     0.0144 \n 3 Post-BRI (2014-2021) BANKING AND F…         217.              307     0.708  \n 4 Post-BRI (2014-2021) BUSINESS AND …          12.6             153     0.0824 \n 5 Post-BRI (2014-2021) COMMUNICATIONS          23.1             279     0.0829 \n 6 Post-BRI (2014-2021) DEVELOPMENTAL…           0.977           188     0.00520\n 7 Post-BRI (2014-2021) DISASTER PREV…           0.226            27     0.00838\n 8 Post-BRI (2014-2021) EDUCATION                5.47           1647     0.00332\n 9 Post-BRI (2014-2021) EMERGENCY RES…           1.30            563     0.00230\n10 Post-BRI (2014-2021) ENERGY                 162.              611     0.266  \n# ℹ 38 more rows\n\n# Pivot wider to compare periods\nsector_comparison &lt;- sector_patterns |&gt;\n  pivot_wider(\n    names_from = period,\n    values_from = c(total_amount_bn, project_count, avg_size_bn),\n    values_fill = 0\n  )\n\nsector_comparison\n\n# A tibble: 24 × 7\n   sector_name                     total_amount_bn_Post…¹ total_amount_bn_Pre-…²\n   &lt;chr&gt;                                            &lt;dbl&gt;                  &lt;dbl&gt;\n 1 ACTION RELATING TO DEBT                          6.76                15.4    \n 2 AGRICULTURE, FORESTRY, FISHING                   5.77                 9.30   \n 3 BANKING AND FINANCIAL SERVICES                 217.                  15.2    \n 4 BUSINESS AND OTHER SERVICES                     12.6                  5.93   \n 5 COMMUNICATIONS                                  23.1                 37.7    \n 6 DEVELOPMENTAL FOOD AID/FOOD SE…                  0.977                1.08   \n 7 DISASTER PREVENTION AND PREPAR…                  0.226                0.00819\n 8 EDUCATION                                        5.47                 3.82   \n 9 EMERGENCY RESPONSE                               1.30                 0.848  \n10 ENERGY                                         162.                 116.     \n# ℹ 14 more rows\n# ℹ abbreviated names: ¹​`total_amount_bn_Post-BRI (2014-2021)`,\n#   ²​`total_amount_bn_Pre-BRI (2000-2013)`\n# ℹ 4 more variables: `project_count_Post-BRI (2014-2021)` &lt;int&gt;,\n#   `project_count_Pre-BRI (2000-2013)` &lt;int&gt;,\n#   `avg_size_bn_Post-BRI (2014-2021)` &lt;dbl&gt;,\n#   `avg_size_bn_Pre-BRI (2000-2013)` &lt;dbl&gt;\n\n\n\n\n6.7.4 Question Set 3: Country Deep Dives\n\nCountry-Level Analysis\n\nWhich countries have seen the most dramatic changes in lending patterns?\nAre there countries that show similar trajectories?\nHow has the mix of ODA-like vs OOF-like lending evolved in key countries?\n\n\nExample approach:\n\n# Analyze lending patterns for top recipients\ncountry_patterns &lt;- get_gcdf3_dataset() |&gt;\n  filter(recommended_for_aggregates == \"Yes\") |&gt;\n  group_by(country_name) |&gt;\n  summarize(\n    total_amount_bn = sum(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    avg_amount_bn = mean(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    project_count = n(),\n    .groups = \"drop\"\n  ) |&gt;\n  # Focus on major recipients\n  slice_max(order_by = total_amount_bn, n = 20)\n\ncountry_patterns\n\n# A tibble: 20 × 4\n   country_name total_amount_bn avg_amount_bn project_count\n   &lt;chr&gt;                  &lt;dbl&gt;         &lt;dbl&gt;         &lt;int&gt;\n 1 Russia                 170.         0.874            251\n 2 Argentina              139.         1.06             168\n 3 Venezuela              113.         2.40             159\n 4 Pakistan               103.         0.323            433\n 5 Angola                  65.1        0.255            368\n 6 Kazakhstan              64.1        0.501            155\n 7 Indonesia               55.2        0.163            400\n 8 Brazil                  54.3        0.375            170\n 9 Vietnam                 28.9        0.183            178\n10 Turkey                  28.3        0.227            144\n11 Iran                    28.0        0.389             91\n12 Egypt                   27.0        0.351             94\n13 Ecuador                 26.6        0.218            189\n14 Mongolia                22.0        0.152            208\n15 Laos                    21.6        0.117            306\n16 Ethiopia                21.4        0.119            261\n17 South Africa            21.3        0.0949           304\n18 Bangladesh              20.8        0.245            138\n19 Sri Lanka               20.5        0.0975           271\n20 Sudan                   18.9        0.122            268\n\n\n\n\n\n\n\n\nAnalysis Strategy\n\n\n\n\nStart simple: Get basic numbers first\nLook for patterns: Use pivoting to compare across dimensions\nGo deeper: Follow interesting patterns you discover\nCreate visuals: Make your findings clear and compelling\nGenerate insights: Find those “repeatable factoids”",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_in_class.html#working-time-structure-30-minutes",
    "href": "week_3_in_class.html#working-time-structure-30-minutes",
    "title": "6  Week 3: Find Actionable Insights, Quickly (In-Class)",
    "section": "6.8 Working Time Structure (30 minutes)",
    "text": "6.8 Working Time Structure (30 minutes)\n\nFirst 5 minutes:\n\nChoose a question that interests you\nSketch out your analysis approach\nWhat comparisons will be most revealing?\n\nNext 20 minutes:\n\nWork on your analysis\nTry different approaches\nCreate visualizations\nLook for surprising patterns\n\nFinal 5 minutes:\n\nRefine your most interesting finding\nPrepare to share one insight\n\n\n\n\n\n\n\n\nGetting Unstuck\n\n\n\nIf you get stuck:\n\nBreak your question into smaller pieces\nTry printing intermediate results\nAsk yourself: “What comparison would make this clear?”\nRemember the pivot dance pattern:\n\nLonger for analysis\nWider for comparison",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_in_class.html#example-solutions-discoveries",
    "href": "week_3_in_class.html#example-solutions-discoveries",
    "title": "6  Week 3: Find Actionable Insights, Quickly (In-Class)",
    "section": "6.9 Example Solutions & Discoveries",
    "text": "6.9 Example Solutions & Discoveries\nLet’s work through one question from each set to demonstrate the full analysis process.\n\n6.9.1 Example 1: Regional Shifts in Focus\n\n\n\n\n\n\nUnderstanding Factor Ordering in ggplot2\n\n\n\nWhen working with categorical variables in R (like time periods, categories, or rankings), you’ll often need to control their display order. By default, R will either: - Order factors alphabetically - Keep them in the order they first appear in the data\nThis default behavior rarely matches what we want to show! Here’s how to take control:\n\nUnderstand factors: Think of factors as categorical variables with a specific order. They’re like a numbered list where each category gets a number determining its position.\nCreate ordered factors: Use factor() with two key arguments:\n\nx: Your categorical variable\nlevels: The desired order of categories\n\n\n# Example: Creating an ordered time period factor\ndf &lt;- df |&gt;\n  mutate(\n    period = factor(\n      period,\n      levels = c(\"Past\", \"Present\", \"Future\")\n    )\n  )\n\nWhy this matters: ggplot2 respects factor ordering for:\n\nAxis ordering\nLegend ordering\nFacet ordering\n\nQuick tip: If you need reverse ordering, just reverse your levels vector:\n\nlevels = rev(c(\"Past\", \"Present\", \"Future\"))\nRemember: Explicit ordering through factors is almost always better than relying on default ordering!\n\n\nLet’s investigate how China’s regional lending focus has changed from pre-BRI to post-BRI:\n\n# Create clear time periods and calculate regional lending\nregional_shifts &lt;- get_gcdf3_dataset() |&gt;\n  filter(recommended_for_aggregates == \"Yes\") |&gt;\n  mutate(\n    # Create period labels\n    period = case_when(\n      commitment_year &lt;= 2013 ~ \"Pre-BRI (2000-2013)\",\n      commitment_year &lt;= 2017 ~ \"Early BRI (2014-2017)\",\n      TRUE ~ \"Late BRI (2018-2021)\"\n    ),\n    # Convert to factor with explicit ordering - this matters for ggplot2\n    period = factor(\n      period,\n      levels = c(\n        \"Pre-BRI (2000-2013)\",\n        \"Early BRI (2014-2017)\", \n        \"Late BRI (2018-2021)\"\n      )\n    )\n  ) |&gt;\n  group_by(period, recipient_region) |&gt;\n  summarize(\n    total_amount_bn = sum(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    .groups = \"drop\"\n  )\n\nregional_shifts\n\n# A tibble: 21 × 3\n   period                recipient_region total_amount_bn\n   &lt;fct&gt;                 &lt;chr&gt;                      &lt;dbl&gt;\n 1 Pre-BRI (2000-2013)   Africa                    147.  \n 2 Pre-BRI (2000-2013)   America                   143.  \n 3 Pre-BRI (2000-2013)   Asia                      204.  \n 4 Pre-BRI (2000-2013)   Europe                    131.  \n 5 Pre-BRI (2000-2013)   Middle East                26.9 \n 6 Pre-BRI (2000-2013)   Multi-Region                3.39\n 7 Pre-BRI (2000-2013)   Oceania                     8.70\n 8 Early BRI (2014-2017) Africa                    113.  \n 9 Early BRI (2014-2017) America                   135.  \n10 Early BRI (2014-2017) Asia                      140.  \n# ℹ 11 more rows\n\n# Calculate shares within each period\nregional_shares &lt;- regional_shifts |&gt;\n  group_by(period) |&gt;\n  mutate(\n    period_total = sum(total_amount_bn),\n    share = total_amount_bn / period_total * 100\n  ) |&gt;\n  ungroup()\n\nregional_shares\n\n# A tibble: 21 × 5\n   period                recipient_region total_amount_bn period_total  share\n   &lt;fct&gt;                 &lt;chr&gt;                      &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n 1 Pre-BRI (2000-2013)   Africa                    147.           664. 22.2  \n 2 Pre-BRI (2000-2013)   America                   143.           664. 21.6  \n 3 Pre-BRI (2000-2013)   Asia                      204.           664. 30.7  \n 4 Pre-BRI (2000-2013)   Europe                    131.           664. 19.7  \n 5 Pre-BRI (2000-2013)   Middle East                26.9          664.  4.05 \n 6 Pre-BRI (2000-2013)   Multi-Region                3.39         664.  0.510\n 7 Pre-BRI (2000-2013)   Oceania                     8.70         664.  1.31 \n 8 Early BRI (2014-2017) Africa                    113.           469. 24.1  \n 9 Early BRI (2014-2017) America                   135.           469. 28.8  \n10 Early BRI (2014-2017) Asia                      140.           469. 29.8  \n# ℹ 11 more rows\n\n# Pivot wider to compare periods\nregional_comparison &lt;- regional_shares |&gt;\n  select(recipient_region, period, share) |&gt;\n  pivot_wider(\n    names_from = period,\n    values_from = share,\n    values_fill = 0\n  ) |&gt;\n  mutate(\n    early_bri_change = `Early BRI (2014-2017)` - `Pre-BRI (2000-2013)`,\n    late_bri_change = `Late BRI (2018-2021)` - `Early BRI (2014-2017)`\n  ) |&gt;\n  arrange(desc(late_bri_change))\n\nregional_comparison\n\n# A tibble: 7 × 6\n  recipient_region `Pre-BRI (2000-2013)` `Early BRI (2014-2017)`\n  &lt;chr&gt;                            &lt;dbl&gt;                   &lt;dbl&gt;\n1 Asia                            30.7                   29.8   \n2 America                         21.6                   28.8   \n3 Multi-Region                     0.510                  0.0239\n4 Europe                          19.7                   11.4   \n5 Oceania                          1.31                   0.868 \n6 Middle East                      4.05                   5.01  \n7 Africa                          22.2                   24.1   \n# ℹ 3 more variables: `Late BRI (2018-2021)` &lt;dbl&gt;, early_bri_change &lt;dbl&gt;,\n#   late_bri_change &lt;dbl&gt;\n\n# Visualize the changes\nregional_shares |&gt;\n  ggplot(aes(x = share, y = fct_rev(period), fill = recipient_region)) +\n  geom_col() +\n  theme_minimal() +\n  labs(\n    title = \"Regional Share of Chinese Development Finance\",\n    subtitle = \"By BRI Period\",\n    x = NULL,\n    y = \"Share of Total Lending (%)\",\n    fill = \"Region\"\n  ) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  facet_wrap(\n    ~recipient_region\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKey Insights from Regional Analysis\n\n\n\n\nPre vs Post BRI: Lending shifts from Europe to other regions.\nRegional Concentration: We can calculate a Herfindahl-Hirschman Index (HHI) to see if lending has become more concentrated\nTiming Patterns: Some regions show consistent growth while others are more volatile\n\n\n\n\n\n6.9.2 Example 2: Sector Evolution Deep Dive\nLet’s examine how sectoral focus has changed over time:\n\n# First, identify major sectors\nmajor_sectors &lt;- get_gcdf3_dataset() |&gt;\n  filter(recommended_for_aggregates == \"Yes\") |&gt;\n  group_by(sector_name) |&gt;\n  summarize(\n    total_amount_bn = sum(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    .groups = \"drop\"\n  ) |&gt;\n  slice_max(order_by = total_amount_bn, n = 5) |&gt;\n  pull(sector_name)\n\nmajor_sectors\n\n[1] \"INDUSTRY, MINING, CONSTRUCTION\" \"ENERGY\"                        \n[3] \"BANKING AND FINANCIAL SERVICES\" \"TRANSPORT AND STORAGE\"         \n[5] \"OTHER MULTISECTOR\"             \n\n# Analyze these sectors over time\nsector_evolution &lt;- get_gcdf3_dataset() |&gt;\n  filter(\n    recommended_for_aggregates == \"Yes\",\n    sector_name %in% major_sectors\n  ) |&gt;\n  group_by(commitment_year, sector_name) |&gt;\n  summarize(\n    amount_bn = sum(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    project_count = n(),\n    avg_project_size = amount_bn / project_count,\n    .groups = \"drop\"\n  )\n\nsector_evolution\n\n# A tibble: 109 × 5\n   commitment_year sector_name          amount_bn project_count avg_project_size\n             &lt;int&gt; &lt;chr&gt;                    &lt;dbl&gt;         &lt;int&gt;            &lt;dbl&gt;\n 1            2000 ENERGY                 1.26               14         0.0900  \n 2            2000 INDUSTRY, MINING, C…   2.03               30         0.0677  \n 3            2000 OTHER MULTISECTOR      0.00155             3         0.000517\n 4            2000 TRANSPORT AND STORA…   0.0927              7         0.0132  \n 5            2001 BANKING AND FINANCI…   0.0905              1         0.0905  \n 6            2001 ENERGY                 1.45               13         0.112   \n 7            2001 INDUSTRY, MINING, C…   0.695              14         0.0496  \n 8            2001 OTHER MULTISECTOR      0                   3         0       \n 9            2001 TRANSPORT AND STORA…   1.51               21         0.0720  \n10            2002 BANKING AND FINANCI…   0.632               3         0.211   \n# ℹ 99 more rows\n\n# Calculate moving averages to smooth volatility\nsector_trends &lt;- sector_evolution |&gt;\n  group_by(sector_name) |&gt;\n  mutate(\n    moving_avg = slider::slide_dbl(\n      amount_bn,\n      .f = mean,\n      .before = 2,\n      .after = 0,\n      .complete = TRUE\n    )\n  ) |&gt;\n  ungroup()\n\nsector_trends\n\n# A tibble: 109 × 6\n   commitment_year sector_name          amount_bn project_count avg_project_size\n             &lt;int&gt; &lt;chr&gt;                    &lt;dbl&gt;         &lt;int&gt;            &lt;dbl&gt;\n 1            2000 ENERGY                 1.26               14         0.0900  \n 2            2000 INDUSTRY, MINING, C…   2.03               30         0.0677  \n 3            2000 OTHER MULTISECTOR      0.00155             3         0.000517\n 4            2000 TRANSPORT AND STORA…   0.0927              7         0.0132  \n 5            2001 BANKING AND FINANCI…   0.0905              1         0.0905  \n 6            2001 ENERGY                 1.45               13         0.112   \n 7            2001 INDUSTRY, MINING, C…   0.695              14         0.0496  \n 8            2001 OTHER MULTISECTOR      0                   3         0       \n 9            2001 TRANSPORT AND STORA…   1.51               21         0.0720  \n10            2002 BANKING AND FINANCI…   0.632               3         0.211   \n# ℹ 99 more rows\n# ℹ 1 more variable: moving_avg &lt;dbl&gt;\n\n# Visualize trends\nsector_trends |&gt;\n  ggplot(aes(x = commitment_year, y = moving_avg, color = sector_name)) +\n  geom_line(linewidth = 1) +\n  theme_minimal() +\n  labs(\n    title = \"Evolution of Major Sectors in Chinese Development Finance\",\n    subtitle = \"3-Year Moving Average\",\n    x = NULL,\n    y = \"Annual Commitments (USD Billions)\",\n    color = \"Sector\"\n  )\n\nWarning: Removed 10 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\n\n\n6.9.3 Example 3: Country Trajectories\nLet’s identify countries with similar lending trajectories:\n\n# First, get the top 15 recipients \ntop_15_countries &lt;- get_gcdf3_dataset() |&gt;\n  filter(recommended_for_aggregates == \"Yes\") |&gt;\n  group_by(country_name) |&gt;\n  summarize(\n    total_amount_bn = sum(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    .groups = \"drop\"\n  ) |&gt;\n  slice_max(order_by = total_amount_bn, n = 15) |&gt;\n  pull(country_name)\n\ntop_15_countries\n\n [1] \"Russia\"     \"Argentina\"  \"Venezuela\"  \"Pakistan\"   \"Angola\"    \n [6] \"Kazakhstan\" \"Indonesia\"  \"Brazil\"     \"Vietnam\"    \"Turkey\"    \n[11] \"Iran\"       \"Egypt\"      \"Ecuador\"    \"Mongolia\"   \"Laos\"      \n\n# Get annual lending data and calculate correlations with {widyr}\ncountry_correlations &lt;- get_gcdf3_dataset() |&gt;\n  filter(\n    recommended_for_aggregates == \"Yes\",\n    country_name %in% top_15_countries\n  ) |&gt;\n  group_by(country_name, commitment_year) |&gt;\n  summarize(\n    amount_bn = sum(amount_constant_usd_2021, na.rm = TRUE) / 1e9,\n    .groups = \"drop\"\n  ) |&gt;\n  # Use widyr to calculate correlations\n  pairwise_cor(\n    item = country_name,\n    feature = commitment_year,\n    value = amount_bn\n  )\n\ncountry_correlations\n\n# A tibble: 210 × 3\n   item1      item2  correlation\n   &lt;chr&gt;      &lt;chr&gt;        &lt;dbl&gt;\n 1 Argentina  Angola     0.144  \n 2 Brazil     Angola     0.594  \n 3 Ecuador    Angola     0.504  \n 4 Egypt      Angola     0.0198 \n 5 Indonesia  Angola     0.481  \n 6 Iran       Angola     0.190  \n 7 Kazakhstan Angola    -0.00985\n 8 Laos       Angola     0.599  \n 9 Mongolia   Angola     0.480  \n10 Pakistan   Angola     0.213  \n# ℹ 200 more rows\n\n# Convert to matrix for heatmap\ncor_matrix &lt;- country_correlations |&gt;\n  pivot_wider(\n    names_from = item2,\n    values_from = correlation\n  ) |&gt;\n  column_to_rownames(\"item1\") |&gt;\n  as.matrix()\n\ncor_matrix\n\n                 Angola   Argentina    Brazil     Ecuador        Egypt\nArgentina   0.144040254          NA 0.2680697 -0.10169336  0.886191523\nBrazil      0.594197304  0.26806966        NA  0.13097493  0.193789238\nEcuador     0.504363398 -0.10169336 0.1309749          NA -0.178794605\nEgypt       0.019817744  0.88619152 0.1937892 -0.17879460           NA\nIndonesia   0.481157449  0.26154222 0.8200718  0.09665565  0.180560628\nIran        0.189533805  0.41856827 0.2573311  0.12946369  0.500507220\nKazakhstan -0.009853296 -0.15467907 0.3898341  0.04809748 -0.062208680\nLaos        0.598529987  0.48553084 0.4455089  0.34630253  0.420420081\nMongolia    0.479518467  0.87201111 0.5059099  0.22896507  0.684676834\nPakistan    0.212668436  0.86415461 0.4944549 -0.11868078  0.713147544\nRussia      0.411187087 -0.09051623 0.4635253  0.31502563 -0.102977986\nTurkey     -0.046570471  0.72642222 0.2128716 -0.15609482  0.682016296\nVenezuela   0.289127554 -0.18001270 0.3063249  0.52490876 -0.330961812\nVietnam     0.745416888  0.10525212 0.4175119  0.56848283  0.004267243\nAngola               NA  0.14404025 0.5941973  0.50436340  0.019817744\n            Indonesia        Iran   Kazakhstan        Laos    Mongolia\nArgentina  0.26154222  0.41856827 -0.154679070 0.485530840  0.87201111\nBrazil     0.82007179  0.25733109  0.389834131 0.445508938  0.50590987\nEcuador    0.09665565  0.12946369  0.048097481 0.346302534  0.22896507\nEgypt      0.18056063  0.50050722 -0.062208680 0.420420081  0.68467683\nIndonesia          NA  0.28895454  0.378417066 0.336854799  0.55663025\nIran       0.28895454          NA -0.069630425 0.494732472  0.50012901\nKazakhstan 0.37841707 -0.06963043           NA 0.009582959 -0.09638666\nLaos       0.33685480  0.49473247  0.009582959          NA  0.64705907\nMongolia   0.55663025  0.50012901 -0.096386655 0.647059071          NA\nPakistan   0.57311187  0.30315433 -0.050998255 0.435897921  0.86258558\nRussia     0.50981954 -0.07274509  0.250155487 0.147091271  0.19704934\nTurkey     0.07225434  0.12710981 -0.110587028 0.373406297  0.53184879\nVenezuela  0.29788955 -0.23682461  0.047042972 0.021136240  0.03706716\nVietnam    0.29754675  0.14806178  0.158572176 0.672768926  0.33138233\nAngola     0.48115745  0.18953381 -0.009853296 0.598529987  0.47951847\n              Pakistan      Russia      Turkey   Venezuela     Vietnam\nArgentina   0.86415461 -0.09051623  0.72642222 -0.18001270 0.105252118\nBrazil      0.49445487  0.46352530  0.21287165  0.30632485 0.417511939\nEcuador    -0.11868078  0.31502563 -0.15609482  0.52490876 0.568482828\nEgypt       0.71314754 -0.10297799  0.68201630 -0.33096181 0.004267243\nIndonesia   0.57311187  0.50981954  0.07225434  0.29788955 0.297546747\nIran        0.30315433 -0.07274509  0.12710981 -0.23682461 0.148061783\nKazakhstan -0.05099825  0.25015549 -0.11058703  0.04704297 0.158572176\nLaos        0.43589792  0.14709127  0.37340630  0.02113624 0.672768926\nMongolia    0.86258558  0.19704934  0.53184879  0.03706716 0.331382330\nPakistan            NA  0.03962180  0.65707926  0.02055394 0.134428821\nRussia      0.03962180          NA -0.04308038  0.26260519 0.069225155\nTurkey      0.65707926 -0.04308038          NA -0.09024336 0.046694362\nVenezuela   0.02055394  0.26260519 -0.09024336          NA 0.323409682\nVietnam     0.13442882  0.06922515  0.04669436  0.32340968          NA\nAngola      0.21266844  0.41118709 -0.04657047  0.28912755 0.745416888\n\n# Create heatmap using pheatmap package\npheatmap(\n  cor_matrix,\n  main = \"Correlation of Chinese Development Finance Patterns\",\n  color = colorRampPalette(c(\"red\", \"white\", \"blue\"))(100),\n  breaks = seq(-1, 1, length.out = 101),\n  display_numbers = TRUE,\n  number_format = \"%.2f\",\n  fontsize_number = 7\n)",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_in_class.html#wrap-up-preview-5-minutes",
    "href": "week_3_in_class.html#wrap-up-preview-5-minutes",
    "title": "6  Week 3: Find Actionable Insights, Quickly (In-Class)",
    "section": "6.10 Wrap-up & Preview (5 minutes)",
    "text": "6.10 Wrap-up & Preview (5 minutes)\n\n\n\n\n\n\nCreating Reusable Functions\n\n\n\nWant to make your analysis pipelines more efficient? Check out:\n\nThe Programming with dplyr vignette\nExamples of turning these patterns into functions\nHow to handle non-standard evaluation in dplyr functions\n\nThis is a great next step once you’re comfortable with the basic patterns!\n\n\n\n6.10.1 Key Takeaways from Today\n\nThe Power of Pivoting\n\nStrategic pivoting reveals patterns\nLong format for analysis, wide for comparison\nThink about what comparison will be most revealing\n\nFinding Insights\n\nStart with clear questions\nUse multiple approaches\nLook for surprising patterns\nCreate “repeatable factoids”\n\nVisualization Tips\n\nShow the most important comparison\nChoose appropriate scales\nMake titles informative",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_3_in_class.html#resources-for-data-transformation-tidying",
    "href": "week_3_in_class.html#resources-for-data-transformation-tidying",
    "title": "6  Week 3: Find Actionable Insights, Quickly (In-Class)",
    "section": "6.11 Resources for Data Transformation & Tidying",
    "text": "6.11 Resources for Data Transformation & Tidying\n\n6.11.1 Essential References\n\nR for Data Science (2e) - Data Tidying\n\nComprehensive introduction to tidy data principles\nClear examples and explanations\nPractice exercises to reinforce learning\n\nDocumentation & Cheatsheets\n\ntidyr cheatsheet\ntidyr documentation\ndplyr programming vignette\n\n\n\n\n6.11.2 Advanced Learning\n\nTidy Data Paper\n\nOriginal academic paper by Hadley Wickham\nDeep dive into tidy data principles\nAdvanced concepts and theory\n\nComplex Pivoting Examples\n\nAdvanced pivoting techniques\nHandling multiple variables\nDealing with complex data structures\n\n{widyr} UN Voting Correlations Vignette\n\nExplore UN Voting Patterns with {widyr}\nGreat practical example of power of pivoting to find interesting relationships\n\n\n\n\n6.11.3 Next Steps\n\nPractice Daily\n\nApply these techniques to your own work\nTry different pivoting approaches\nCreate your own “pivot patterns” library\n\nBuild Your Skills\n\nStart with simple pivots\nProgress to more complex transformations\nExperiment with different visualization approaches\n\nShare & Learn\n\nDiscuss approaches with colleagues\nShare interesting findings\nLearn from others’ techniques\n\n\nRemember: Data tidying is a foundational skill that enables all other analysis. Investing time in mastering these concepts will pay dividends throughout your career in data analysis.\n\n\n6.11.4 Preview of Next Week: Data Import & Cleaning\nNext week we’ll learn how to:\n\nImport data from various sources\nHandle common data quality issues\nCreate reproducible cleaning pipelines\nDocument data decisions\n\n\n\n\n\n\n\nPreparing for Next Week\n\n\n\n\nThink about data cleaning challenges you’ve faced\nReview this week’s pivoting patterns\nConsider how clean data enables better analysis",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Week 3: Find Actionable Insights, Quickly (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_pre_class.html",
    "href": "week_4_pre_class.html",
    "title": "7  Week 4: Import & Tidy Your Data (Pre-Class)",
    "section": "",
    "text": "7.1 Overview\nThis pre-class preparation should take about 45-60 minutes to complete.\nGetting data into R and preparing it for analysis is often your first challenge in any project. In this pre-class session, we’ll focus on importing data from spreadsheets and establishing good practices for data cleaning. You’ll learn reliable workflows that make your analysis more reproducible and easier to maintain.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_pre_class.html#overview",
    "href": "week_4_pre_class.html#overview",
    "title": "7  Week 4: Import & Tidy Your Data (Pre-Class)",
    "section": "",
    "text": "7.1.1 Video Lecture\nWatch this video lecture before our interactive session:",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_pre_class.html#learning-objectives",
    "href": "week_4_pre_class.html#learning-objectives",
    "title": "7  Week 4: Import & Tidy Your Data (Pre-Class)",
    "section": "7.2 Learning Objectives",
    "text": "7.2 Learning Objectives\nBy completing this pre-class work, you will:\n\nLearn to import data from Excel and CSV files into R\nSet up organized project structures\nEstablish reliable data cleaning workflows\nStandardize common variables like dates and country names\nPractice with real Chinese development finance data",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_pre_class.html#the-power-of-clean-data",
    "href": "week_4_pre_class.html#the-power-of-clean-data",
    "title": "7  Week 4: Import & Tidy Your Data (Pre-Class)",
    "section": "7.3 The Power of Clean Data",
    "text": "7.3 The Power of Clean Data\n\n7.3.1 Why Data Cleaning Matters\nData cleaning might not be anyone’s idea of fun, but here’s a secret: getting good at data cleaning is one of the highest-return skills you can develop as a researcher. Why? Because while lots of people can run sophisticated analyses on clean datasets, far fewer people can reliably turn messy real-world data into analysis-ready information.\nAt AidData, this matters even more. AidData’s mission isn’t just to analyze existing datasets - you create new ones that reveal previously hidden patterns in Chinese development finance. The ability to clean and standardize messy data is core to this mission.\n\n\n7.3.2 The Tidyverse Advantage\nThe tidyverse provides an extraordinarily powerful toolkit for importing and cleaning data, with specialized packages designed specifically for common cleaning tasks:\n\n7.3.2.1 Data Import Tools\n\n{readr} (cheatsheet): CSV and flat files\n{readxl}: Excel files\n{haven}: SPSS, Stata, and SAS files\n{httr2}: Web APIs\n\nThese are just the basics. There’s a whole universe of tidyverse-style data import packages for all varieties of file formats and APIs (“There’s a package for that…”).\n\n\n7.3.2.2 Data Cleaning Specialists\n\n{stringr} (cheatsheet): Text cleaning and manipulation\n{lubridate} (cheatsheet): Dates and times\n{forcats} (cheatsheet): Factor handling\n{tidyr} (cheatsheet): Data structure tools\n\nAll of these packages follow consistent principles and are designed for humans to use. The R for Data Science (2e) book has excellent chapters on each:\n\nData Import\nStrings\nFactors\nDates and Times\n\n\n\n\n7.3.3 The Compounding Value of Clean Data\nHere’s why mastering data cleaning is worth your time:\n\nUnique Insights: When everyone works with the same clean datasets, it’s hard to find unique patterns. The ability to clean messy data gives you access to information others might miss.\nReproducible Work: Good data cleaning isn’t just about getting the data right once - it’s about creating reproducible pipelines that can handle new data as it arrives.\nTime Investment: While cleaning data takes time upfront, having clean, reliable data saves countless hours of troubleshooting and redoing analyses later.\nCompetitive Advantage: In research, the quality of your inputs often matters more than the sophistication of your analysis. Being good at data cleaning lets you work with sources others might avoid.\n\n\n\n7.3.4 What We’ll Learn\nIn the following sections, you’ll learn to:\n\nImport data from various sources\nCreate reliable cleaning pipelines\nHandle common data issues like:\n\nInconsistent text formats\nMessy dates and times\nDifferent monetary formats\nVariant country names\n\n\nWhile data cleaning may never be the most exciting part of research, by the end of this section, you’ll have the tools to make it a manageable, reliable part of your workflow.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_pre_class.html#setup",
    "href": "week_4_pre_class.html#setup",
    "title": "7  Week 4: Import & Tidy Your Data (Pre-Class)",
    "section": "7.4 Setup",
    "text": "7.4 Setup\nLet’s get our workspace ready:\n\nCreate a new Quarto document for your notes:\n\n# File → New File → Quarto Document\n# Save as \"week_4_import_preclass.qmd\" in your week_4/R folder\n\nCreate folders for organizing data:\n\ndir.create(\"data-raw\", showWarnings = FALSE)  # For original data\ndir.create(\"data\", showWarnings = FALSE)      # For cleaned data\n\nDownload the AidData Critical Minerals Dataset and save it to your data-raw folder.\n\n\n\n\n\n\n\nWhy Two Data Folders?\n\n\n\n\ndata-raw/: Store original data exactly as received\n\nNever modify these files\nServes as your “source of truth”\nMakes your work reproducible\n\ndata/: Store cleaned, analysis-ready data\n\nModified through documented R code\nReady for analysis\nCan always recreate from raw data\n\n\n\n\n\nLoad required packages:\n\n\nlibrary(tidyverse)    # Core data science tools\nlibrary(readxl)       # For reading Excel files\nlibrary(readr)        # For reading CSV files\nlibrary(janitor)      # For cleaning column names\nlibrary(countrycode)  # For standardizing country names\nlibrary(here)        # For relative filepaths",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_pre_class.html#core-concepts",
    "href": "week_4_pre_class.html#core-concepts",
    "title": "7  Week 4: Import & Tidy Your Data (Pre-Class)",
    "section": "7.5 Core Concepts",
    "text": "7.5 Core Concepts\n\n7.5.1 Organizing Your Data Pipeline\nThink of data cleaning as a multi-step recipe. Just like cooking, you want to:\n\nGet your ingredients (import raw data, save in data-raw)\nPrep them properly (clean data)\nCreate something useful (analysis-ready data, save in data for further use)\n\nLet’s see how this works with real data.\n\n\n7.5.2 Reading Data from Spreadsheets\nThe two main functions for reading spreadsheet data are:\n\nreadxl::read_excel() for Excel files\nreadr::read_csv() for CSV files\n\nLet’s try reading our Critical Minerals data:\n\n# Read the Excel file\nminerals_raw &lt;- read_excel(\n  here(\n    \"data-raw\",\n    \"AidData_Chinese_Financing_for_Transition_Minerals_Dataset_Version_1.0.xlsx\"\n  ),\n  sheet = \"Financial_Contribution\",\n  na = c(\"\", \"NA\", \"N/A\", \"#N/A\", \"NULL\"),  # Handle missing values\n  guess_max = 20000  # Look at more rows when guessing types\n)\n\n# Quick look at what we imported\nglimpse(minerals_raw)\n\nRows: 137\nColumns: 128\n$ `AidData Record ID`                                &lt;dbl&gt; 95747, 95748, 39557…\n$ `AidData Parent ID`                                &lt;chr&gt; \"228\", \"228\", \"695\"…\n$ `Loan Event ID`                                    &lt;chr&gt; \"101\", \"201\", \"301\"…\n$ `Loan Event Description`                           &lt;chr&gt; \"2010 $200 million …\n$ `Financier Country`                                &lt;chr&gt; \"China (People's Re…\n$ Recipient                                          &lt;chr&gt; \"Kazakhstan\", \"Kaza…\n$ `Recipient ISO-3`                                  &lt;chr&gt; \"KAZ\", \"KAZ\", \"KAZ\"…\n$ `Recipient Region`                                 &lt;chr&gt; \"Asia\", \"Asia\", \"As…\n$ `Commitment Year`                                  &lt;dbl&gt; 2010, 2012, 2011, 2…\n$ `Implementation Start Year`                        &lt;dbl&gt; 2014, 2009, 2013, 2…\n$ `Completion Year`                                  &lt;dbl&gt; NA, NA, 2015, 2015,…\n$ `Mining Site`                                      &lt;chr&gt; \"Abyz Copper Mine a…\n$ `Mining Site ID`                                   &lt;dbl&gt; 1, 2, 3, 3, 3, 3, 4…\n$ `Investors Ownership ID`                           &lt;dbl&gt; 1, 2, 3, 3, 3, 3, 4…\n$ `Transition Minerals`                              &lt;chr&gt; \"Copper\", \"Copper\",…\n$ Title                                              &lt;chr&gt; \"CDB provides $200 …\n$ Description                                        &lt;chr&gt; \"In June 2009, Chin…\n$ `Staff Comments`                                   &lt;chr&gt; \"1. The loan’s prec…\n$ Status                                             &lt;chr&gt; \"Implementation\", \"…\n$ Intent                                             &lt;chr&gt; \"Commercial\", \"Mixe…\n$ `Flow Type`                                        &lt;chr&gt; \"Loan\", \"Loan\", \"Lo…\n$ `OECD ODA Concessionality Threshold`               &lt;dbl&gt; 0.25, 0.25, 0.25, 0…\n$ `Flow Class`                                       &lt;chr&gt; \"OOF-like\", \"OOF-li…\n$ `Sector Code`                                      &lt;dbl&gt; 320, 320, 320, 320,…\n$ `Sector Name`                                      &lt;chr&gt; \"INDUSTRY, MINING, …\n$ Infrastructure                                     &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\"…\n$ `Funding Agencies`                                 &lt;chr&gt; \"China Development …\n$ `Funding Agencies Type`                            &lt;chr&gt; \"State-owned Policy…\n$ Cofinanced                                         &lt;chr&gt; \"No\", \"No\", \"No\", \"…\n$ `Cofinancing Agencies`                             &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ `Cofinancing Agencies Type`                        &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ `Direct Receiving Agencies`                        &lt;chr&gt; \"KAZ Minerals Finan…\n$ `Direct Receiving Agencies Type`                   &lt;chr&gt; \"Other Joint Ventur…\n$ `Indirect Receiving Agencies`                      &lt;chr&gt; NA, NA, NA, NA, \"KA…\n$ `Indirect Receiving Agencies Type`                 &lt;chr&gt; NA, NA, NA, NA, \"Ot…\n$ `On-Lending`                                       &lt;chr&gt; NA, NA, NA, NA, \"Ye…\n$ `Implementing Agencies`                            &lt;chr&gt; NA, NA, \"ABB Group|…\n$ `Implementing Agencies Type`                       &lt;chr&gt; NA, NA, \"Other Priv…\n$ `Operator/Owner`                                   &lt;chr&gt; \"Kazakhmys Corporat…\n$ `Operator/Owner Type`                              &lt;chr&gt; \"Recipient Private …\n$ Investors                                          &lt;chr&gt; \"Kazakhmys PLC\", \"K…\n$ `Investors Type`                                   &lt;chr&gt; \"Other Private Sect…\n$ `Investors Ownership Percentages`                  &lt;chr&gt; \"100\", \"100\", \"100\"…\n$ `Controlling Shareholder`                          &lt;chr&gt; \"Kazakhmys PLC\", \"K…\n$ `Controlling Shareholder Type`                     &lt;chr&gt; \"Other Private Sect…\n$ `Guarantee Provided`                               &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\"…\n$ Guarantor                                          &lt;chr&gt; \"KAZ Minerals PLC (…\n$ `Guarantor Agency Type`                            &lt;chr&gt; \"Other Private Sect…\n$ `Insurance Provided`                               &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ `Insurance Provider`                               &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ `Insurance Provider Agency Type`                   &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ `Collateralized/Securitized`                       &lt;chr&gt; NA, \"Yes\", \"Yes\", \"…\n$ `Collateral Provider`                              &lt;chr&gt; NA, \"KAZ Minerals F…\n$ `Collateral Provider Agency Type`                  &lt;chr&gt; NA, \"Other Joint Ve…\n$ `Security Agent/Collateral Agent`                  &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ `Security Agent/Collateral Agent Type`             &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ Collateral                                         &lt;chr&gt; NA, \"Borrower to pr…\n$ `Amount (Original Currency)`                       &lt;dbl&gt; 200000000, 20000000…\n$ `Original Currency`                                &lt;chr&gt; \"USD\", \"USD\", \"CNY\"…\n$ `Amount Estimated`                                 &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ `Amount (Constant USD 2021)`                       &lt;dbl&gt; 278545387, 23482471…\n$ `Amount (Nominal USD)`                             &lt;dbl&gt; 200000000, 20000000…\n$ `Financial Distress`                               &lt;chr&gt; \"Yes\", \"Yes\", NA, N…\n$ `Commitment Date (MM/DD/YYYY)`                     &lt;dttm&gt; 2010-01-12, 2012-0…\n$ `Commitment Date Estimated`                        &lt;chr&gt; \"No\", \"No\", \"No\", \"…\n$ `Planned Implementation Start Date (MM/DD/YYYY)`   &lt;dttm&gt; NA, NA, NA, NA, NA…\n$ `Actual Implementation Start Date (MM/DD/YYYY)`    &lt;dttm&gt; 2014-01-01, 2009-0…\n$ `Actual Implementation Start Date Estimated`       &lt;chr&gt; \"No\", \"No\", NA, NA,…\n$ `Deviation from Planned Implementation Start Date` &lt;dbl&gt; NA, NA, NA, NA, NA,…\n$ `Planned Completion Date (MM/DD/YYYY)`             &lt;dttm&gt; NA, NA, NA, NA, NA…\n$ `Actual Completion Date (MM/DD/YYYY)`              &lt;dttm&gt; NA, NA, 2015-12-01…\n$ `Actual Completion Date Estimated`                 &lt;chr&gt; \"No\", \"No\", NA, NA,…\n$ `Deviation from Planned Completion Date`           &lt;dbl&gt; NA, NA, NA, NA, NA,…\n$ Maturity                                           &lt;dbl&gt; 13.50, 13.50, 15.00…\n$ `Interest Rate`                                    &lt;dbl&gt; 5.199, 5.536, 4.540…\n$ `Fixed/Variable Interest Rate`                     &lt;chr&gt; \"Variable\", \"Variab…\n$ `Variable Interest Reference Rate`                 &lt;chr&gt; \"LIBOR\", \"LIBOR\", \"…\n$ `Variable Interest Detail`                         &lt;chr&gt; NA, NA, NA, NA, \"6-…\n$ `Variable Interest Margin`                         &lt;dbl&gt; 4.8, 4.8, NA, 4.2, …\n$ `Grace Period`                                     &lt;dbl&gt; 3, 3, 3, 3, NA, NA,…\n$ `Management Fee`                                   &lt;dbl&gt; 1.5, 1.5, NA, NA, N…\n$ `Commitment Fee`                                   &lt;lgl&gt; NA, NA, NA, NA, NA,…\n$ `Insurance Fee (Percent)`                          &lt;lgl&gt; NA, NA, NA, NA, NA,…\n$ `Insurance Fee (Nominal USD)`                      &lt;lgl&gt; NA, NA, NA, NA, NA,…\n$ `Default Interest Rate`                            &lt;lgl&gt; NA, NA, NA, NA, NA,…\n$ `First Loan Repayment Date`                        &lt;dttm&gt; 2013-01-11, 2015-0…\n$ `Last Loan Repayment Date`                         &lt;dttm&gt; 2023-07-10, 2025-1…\n$ `Grant Element (OECD Cash-Flow)`                   &lt;dbl&gt; 24.4630, 22.6562, 2…\n$ `Grant Element (OECD Grant-Equiv)`                 &lt;dbl&gt; 4.4782, 2.3634, 29.…\n$ `Grant Element (IMF)`                              &lt;dbl&gt; 0.0000, 0.0000, 2.7…\n$ `Number of Lenders`                                &lt;chr&gt; \"Bilateral Loan\", \"…\n$ `Export Buyer's Credit`                            &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ `Supplier’s Credit/Export Seller’s Credit`         &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ `Interest-Free Loan`                               &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ Refinancing                                        &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ `Investment Project Loan`                          &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\"…\n$ `M&A`                                              &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ `Working Capital`                                  &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ EPCF                                               &lt;lgl&gt; NA, NA, NA, NA, NA,…\n$ Lease                                              &lt;lgl&gt; NA, NA, NA, NA, NA,…\n$ `FXSL/BOP`                                         &lt;lgl&gt; NA, NA, NA, NA, NA,…\n$ `CC IRS`                                           &lt;lgl&gt; NA, NA, NA, NA, NA,…\n$ RCF                                                &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ GCL                                                &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ PBC                                                &lt;lgl&gt; NA, NA, NA, NA, NA,…\n$ `PxF/Commodity Prepayment`                         &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ `Inter-Bank Loan`                                  &lt;chr&gt; NA, NA, NA, NA, \"Ye…\n$ `Overseas Project Contracting Loan`                &lt;lgl&gt; NA, NA, NA, NA, NA,…\n$ DPA                                                &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ `Project Finance`                                  &lt;chr&gt; NA, NA, \"Yes\", \"Yes…\n$ `Involving Multilateral`                           &lt;lgl&gt; NA, NA, NA, NA, NA,…\n$ `Involving Non-Chinese Financier`                  &lt;chr&gt; \"No\", \"No\", \"No\", \"…\n$ `Short-Term`                                       &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ Rescue                                             &lt;lgl&gt; NA, NA, NA, NA, NA,…\n$ `JV/SPV Host Government Ownership`                 &lt;chr&gt; \"No Host Government…\n$ `JV/SPV Chinese Government Ownership`              &lt;chr&gt; \"No Chinese Governm…\n$ `Level of Public Liability`                        &lt;chr&gt; \"Central government…\n$ `Total Source Count`                               &lt;dbl&gt; 9, 11, 17, 19, 10, …\n$ `Official Source Count`                            &lt;dbl&gt; 2, 2, 11, 12, 6, 12…\n$ `Source URLs`                                      &lt;chr&gt; \"https://www.proact…\n$ `Source Titles`                                    &lt;chr&gt; \"Kazakhmys signs ne…\n$ `Source Publishers`                                &lt;chr&gt; \"Proactive Investor…\n$ `Source Resource Types`                            &lt;chr&gt; \"Media Report|Imple…\n$ `Contact Name`                                     &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ `Contact Position`                                 &lt;chr&gt; NA, NA, NA, NA, NA,…\n$ `ODA Eligible Recipient`                           &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\"…\n$ `OECD ODA Income Group`                            &lt;chr&gt; \"Upper middle incom…\n$ `Location Narrative`                               &lt;chr&gt; \"The project develo…\n\n\n\n\n\n\n\n\nKey Import Arguments\n\n\n\n\nna =: What values should be treated as missing\nguess_max =: How many rows to check when determining column types\nsheet =: Which Excel sheet to read\nrange =: Specific cells to read\n\nThese help handle common import challenges like: - Different representations of missing data - Incorrect column type detection - Multiple sheets in one file\n\n\n\n\n\n\n\n\nRead the Documentation!\n\n\n\nWhile we’re covering key arguments, the readxl and readr packages have many more options. Taking time to read the documentation (read_excel(), read_csv()) will save you hours of troubleshooting later.\nYou don’t need to memorize all options - just know they exist and where to find them when needed.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_pre_class.html#a-systematic-approach-to-data-cleaning",
    "href": "week_4_pre_class.html#a-systematic-approach-to-data-cleaning",
    "title": "7  Week 4: Import & Tidy Your Data (Pre-Class)",
    "section": "7.6 A Systematic Approach to Data Cleaning",
    "text": "7.6 A Systematic Approach to Data Cleaning\n\n7.6.1 Step 1: Clean Column Names & Inspect Data\nFirst, we always want consistent, programming-friendly column names. glimpse() your new clean names, and look for data that might need to be cleaned. Note any variables where the data type displayed does not match what it logically should be (e.g. is a numeric variable show with data type &lt;chr&gt;?)\n\n# Clean the names\nminerals_clean &lt;- minerals_raw |&gt;\n  clean_names()\n\n# See the difference\nminerals_clean |&gt; glimpse()\n\nRows: 137\nColumns: 128\n$ aid_data_record_id                               &lt;dbl&gt; 95747, 95748, 39557, …\n$ aid_data_parent_id                               &lt;chr&gt; \"228\", \"228\", \"695\", …\n$ loan_event_id                                    &lt;chr&gt; \"101\", \"201\", \"301\", …\n$ loan_event_description                           &lt;chr&gt; \"2010 $200 million lo…\n$ financier_country                                &lt;chr&gt; \"China (People's Repu…\n$ recipient                                        &lt;chr&gt; \"Kazakhstan\", \"Kazakh…\n$ recipient_iso_3                                  &lt;chr&gt; \"KAZ\", \"KAZ\", \"KAZ\", …\n$ recipient_region                                 &lt;chr&gt; \"Asia\", \"Asia\", \"Asia…\n$ commitment_year                                  &lt;dbl&gt; 2010, 2012, 2011, 201…\n$ implementation_start_year                        &lt;dbl&gt; 2014, 2009, 2013, 201…\n$ completion_year                                  &lt;dbl&gt; NA, NA, 2015, 2015, 2…\n$ mining_site                                      &lt;chr&gt; \"Abyz Copper Mine and…\n$ mining_site_id                                   &lt;dbl&gt; 1, 2, 3, 3, 3, 3, 4, …\n$ investors_ownership_id                           &lt;dbl&gt; 1, 2, 3, 3, 3, 3, 4, …\n$ transition_minerals                              &lt;chr&gt; \"Copper\", \"Copper\", \"…\n$ title                                            &lt;chr&gt; \"CDB provides $200 mi…\n$ description                                      &lt;chr&gt; \"In June 2009, China …\n$ staff_comments                                   &lt;chr&gt; \"1. The loan’s precis…\n$ status                                           &lt;chr&gt; \"Implementation\", \"Im…\n$ intent                                           &lt;chr&gt; \"Commercial\", \"Mixed\"…\n$ flow_type                                        &lt;chr&gt; \"Loan\", \"Loan\", \"Loan…\n$ oecd_oda_concessionality_threshold               &lt;dbl&gt; 0.25, 0.25, 0.25, 0.2…\n$ flow_class                                       &lt;chr&gt; \"OOF-like\", \"OOF-like…\n$ sector_code                                      &lt;dbl&gt; 320, 320, 320, 320, 3…\n$ sector_name                                      &lt;chr&gt; \"INDUSTRY, MINING, CO…\n$ infrastructure                                   &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", …\n$ funding_agencies                                 &lt;chr&gt; \"China Development Ba…\n$ funding_agencies_type                            &lt;chr&gt; \"State-owned Policy B…\n$ cofinanced                                       &lt;chr&gt; \"No\", \"No\", \"No\", \"No…\n$ cofinancing_agencies                             &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ cofinancing_agencies_type                        &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ direct_receiving_agencies                        &lt;chr&gt; \"KAZ Minerals Finance…\n$ direct_receiving_agencies_type                   &lt;chr&gt; \"Other Joint Venture/…\n$ indirect_receiving_agencies                      &lt;chr&gt; NA, NA, NA, NA, \"KAZ …\n$ indirect_receiving_agencies_type                 &lt;chr&gt; NA, NA, NA, NA, \"Othe…\n$ on_lending                                       &lt;chr&gt; NA, NA, NA, NA, \"Yes\"…\n$ implementing_agencies                            &lt;chr&gt; NA, NA, \"ABB Group|Al…\n$ implementing_agencies_type                       &lt;chr&gt; NA, NA, \"Other Privat…\n$ operator_owner                                   &lt;chr&gt; \"Kazakhmys Corporatio…\n$ operator_owner_type                              &lt;chr&gt; \"Recipient Private Se…\n$ investors                                        &lt;chr&gt; \"Kazakhmys PLC\", \"Kaz…\n$ investors_type                                   &lt;chr&gt; \"Other Private Sector…\n$ investors_ownership_percentages                  &lt;chr&gt; \"100\", \"100\", \"100\", …\n$ controlling_shareholder                          &lt;chr&gt; \"Kazakhmys PLC\", \"Kaz…\n$ controlling_shareholder_type                     &lt;chr&gt; \"Other Private Sector…\n$ guarantee_provided                               &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", …\n$ guarantor                                        &lt;chr&gt; \"KAZ Minerals PLC (Fo…\n$ guarantor_agency_type                            &lt;chr&gt; \"Other Private Sector…\n$ insurance_provided                               &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ insurance_provider                               &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ insurance_provider_agency_type                   &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ collateralized_securitized                       &lt;chr&gt; NA, \"Yes\", \"Yes\", \"Ye…\n$ collateral_provider                              &lt;chr&gt; NA, \"KAZ Minerals Fin…\n$ collateral_provider_agency_type                  &lt;chr&gt; NA, \"Other Joint Vent…\n$ security_agent_collateral_agent                  &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ security_agent_collateral_agent_type             &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ collateral                                       &lt;chr&gt; NA, \"Borrower to prov…\n$ amount_original_currency                         &lt;dbl&gt; 200000000, 200000000,…\n$ original_currency                                &lt;chr&gt; \"USD\", \"USD\", \"CNY\", …\n$ amount_estimated                                 &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ amount_constant_usd_2021                         &lt;dbl&gt; 278545387, 234824712,…\n$ amount_nominal_usd                               &lt;dbl&gt; 200000000, 200000000,…\n$ financial_distress                               &lt;chr&gt; \"Yes\", \"Yes\", NA, NA,…\n$ commitment_date_mm_dd_yyyy                       &lt;dttm&gt; 2010-01-12, 2012-06-…\n$ commitment_date_estimated                        &lt;chr&gt; \"No\", \"No\", \"No\", \"No…\n$ planned_implementation_start_date_mm_dd_yyyy     &lt;dttm&gt; NA, NA, NA, NA, NA, …\n$ actual_implementation_start_date_mm_dd_yyyy      &lt;dttm&gt; 2014-01-01, 2009-01-…\n$ actual_implementation_start_date_estimated       &lt;chr&gt; \"No\", \"No\", NA, NA, N…\n$ deviation_from_planned_implementation_start_date &lt;dbl&gt; NA, NA, NA, NA, NA, N…\n$ planned_completion_date_mm_dd_yyyy               &lt;dttm&gt; NA, NA, NA, NA, NA, …\n$ actual_completion_date_mm_dd_yyyy                &lt;dttm&gt; NA, NA, 2015-12-01, …\n$ actual_completion_date_estimated                 &lt;chr&gt; \"No\", \"No\", NA, NA, N…\n$ deviation_from_planned_completion_date           &lt;dbl&gt; NA, NA, NA, NA, NA, N…\n$ maturity                                         &lt;dbl&gt; 13.50, 13.50, 15.00, …\n$ interest_rate                                    &lt;dbl&gt; 5.199, 5.536, 4.540, …\n$ fixed_variable_interest_rate                     &lt;chr&gt; \"Variable\", \"Variable…\n$ variable_interest_reference_rate                 &lt;chr&gt; \"LIBOR\", \"LIBOR\", \"LI…\n$ variable_interest_detail                         &lt;chr&gt; NA, NA, NA, NA, \"6-Mo…\n$ variable_interest_margin                         &lt;dbl&gt; 4.8, 4.8, NA, 4.2, 4.…\n$ grace_period                                     &lt;dbl&gt; 3, 3, 3, 3, NA, NA, N…\n$ management_fee                                   &lt;dbl&gt; 1.5, 1.5, NA, NA, NA,…\n$ commitment_fee                                   &lt;lgl&gt; NA, NA, NA, NA, NA, N…\n$ insurance_fee_percent                            &lt;lgl&gt; NA, NA, NA, NA, NA, N…\n$ insurance_fee_nominal_usd                        &lt;lgl&gt; NA, NA, NA, NA, NA, N…\n$ default_interest_rate                            &lt;lgl&gt; NA, NA, NA, NA, NA, N…\n$ first_loan_repayment_date                        &lt;dttm&gt; 2013-01-11, 2015-06-…\n$ last_loan_repayment_date                         &lt;dttm&gt; 2023-07-10, 2025-12-…\n$ grant_element_oecd_cash_flow                     &lt;dbl&gt; 24.4630, 22.6562, 29.…\n$ grant_element_oecd_grant_equiv                   &lt;dbl&gt; 4.4782, 2.3634, 29.44…\n$ grant_element_imf                                &lt;dbl&gt; 0.0000, 0.0000, 2.790…\n$ number_of_lenders                                &lt;chr&gt; \"Bilateral Loan\", \"Bi…\n$ export_buyers_credit                             &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ supplier_s_credit_export_seller_s_credit         &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ interest_free_loan                               &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ refinancing                                      &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ investment_project_loan                          &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", …\n$ m_a                                              &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ working_capital                                  &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ epcf                                             &lt;lgl&gt; NA, NA, NA, NA, NA, N…\n$ lease                                            &lt;lgl&gt; NA, NA, NA, NA, NA, N…\n$ fxsl_bop                                         &lt;lgl&gt; NA, NA, NA, NA, NA, N…\n$ cc_irs                                           &lt;lgl&gt; NA, NA, NA, NA, NA, N…\n$ rcf                                              &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ gcl                                              &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ pbc                                              &lt;lgl&gt; NA, NA, NA, NA, NA, N…\n$ px_f_commodity_prepayment                        &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ inter_bank_loan                                  &lt;chr&gt; NA, NA, NA, NA, \"Yes\"…\n$ overseas_project_contracting_loan                &lt;lgl&gt; NA, NA, NA, NA, NA, N…\n$ dpa                                              &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ project_finance                                  &lt;chr&gt; NA, NA, \"Yes\", \"Yes\",…\n$ involving_multilateral                           &lt;lgl&gt; NA, NA, NA, NA, NA, N…\n$ involving_non_chinese_financier                  &lt;chr&gt; \"No\", \"No\", \"No\", \"No…\n$ short_term                                       &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ rescue                                           &lt;lgl&gt; NA, NA, NA, NA, NA, N…\n$ jv_spv_host_government_ownership                 &lt;chr&gt; \"No Host Government O…\n$ jv_spv_chinese_government_ownership              &lt;chr&gt; \"No Chinese Governmen…\n$ level_of_public_liability                        &lt;chr&gt; \"Central government-g…\n$ total_source_count                               &lt;dbl&gt; 9, 11, 17, 19, 10, 13…\n$ official_source_count                            &lt;dbl&gt; 2, 2, 11, 12, 6, 12, …\n$ source_ur_ls                                     &lt;chr&gt; \"https://www.proactiv…\n$ source_titles                                    &lt;chr&gt; \"Kazakhmys signs new …\n$ source_publishers                                &lt;chr&gt; \"Proactive Investors|…\n$ source_resource_types                            &lt;chr&gt; \"Media Report|Impleme…\n$ contact_name                                     &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ contact_position                                 &lt;chr&gt; NA, NA, NA, NA, NA, N…\n$ oda_eligible_recipient                           &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", …\n$ oecd_oda_income_group                            &lt;chr&gt; \"Upper middle income\"…\n$ location_narrative                               &lt;chr&gt; \"The project develope…\n\n\n\n\n\n\n\n\nWhy Clean Column Names?\n\n\n\nRaw data often comes with inconsistent column names:\n\nSpaces (“Project Name”)\nSpecial characters (“Amount ($)”)\nInconsistent capitalization (“projectName”, “Project_name”)\nNumbers at start (“2021_amount”)\n\nclean_names():\n\nConverts to lowercase\nReplaces spaces/special chars with underscores\nMakes names programming-friendly\nCreates consistent style\n\nThis matters because:\n\nReduces coding errors\nMakes autocomplete work better\nPrevents quoting/escaping headaches\nCreates consistent style across projects\n\n\n\n\n\n7.6.2 Step 2: Fix Dates\nAlways inspect and clean date columns early:\n\n# First, find all date columns\nminerals_clean |&gt; \n  select(contains(\"date\")) |&gt; \n  glimpse()\n\nRows: 137\nColumns: 12\n$ commitment_date_mm_dd_yyyy                       &lt;dttm&gt; 2010-01-12, 2012-06-…\n$ commitment_date_estimated                        &lt;chr&gt; \"No\", \"No\", \"No\", \"No…\n$ planned_implementation_start_date_mm_dd_yyyy     &lt;dttm&gt; NA, NA, NA, NA, NA, …\n$ actual_implementation_start_date_mm_dd_yyyy      &lt;dttm&gt; 2014-01-01, 2009-01-…\n$ actual_implementation_start_date_estimated       &lt;chr&gt; \"No\", \"No\", NA, NA, N…\n$ deviation_from_planned_implementation_start_date &lt;dbl&gt; NA, NA, NA, NA, NA, N…\n$ planned_completion_date_mm_dd_yyyy               &lt;dttm&gt; NA, NA, NA, NA, NA, …\n$ actual_completion_date_mm_dd_yyyy                &lt;dttm&gt; NA, NA, 2015-12-01, …\n$ actual_completion_date_estimated                 &lt;chr&gt; \"No\", \"No\", NA, NA, N…\n$ deviation_from_planned_completion_date           &lt;dbl&gt; NA, NA, NA, NA, NA, N…\n$ first_loan_repayment_date                        &lt;dttm&gt; 2013-01-11, 2015-06-…\n$ last_loan_repayment_date                         &lt;dttm&gt; 2023-07-10, 2025-12-…\n\n# Convert all dates to proper format\nminerals_dates &lt;- minerals_clean |&gt;\n  mutate(\n    commitment_date_mm_dd_yyyy = ymd(commitment_date_mm_dd_yyyy),\n    planned_implementation_start_date_mm_dd_yyyy = ymd(planned_implementation_start_date_mm_dd_yyyy),\n    actual_implementation_start_date_mm_dd_yyyy = ymd(actual_implementation_start_date_mm_dd_yyyy),\n    planned_completion_date_mm_dd_yyyy = ymd(planned_completion_date_mm_dd_yyyy),\n    actual_completion_date_mm_dd_yyyy = ymd(actual_completion_date_mm_dd_yyyy),\n    first_loan_repayment_date = ymd(first_loan_repayment_date),\n    last_loan_repayment_date = ymd(last_loan_repayment_date)\n  )\n\nminerals_dates |&gt; \n  select(contains(\"date\")) |&gt; \n  glimpse()\n\nRows: 137\nColumns: 12\n$ commitment_date_mm_dd_yyyy                       &lt;date&gt; 2010-01-12, 2012-06-…\n$ commitment_date_estimated                        &lt;chr&gt; \"No\", \"No\", \"No\", \"No…\n$ planned_implementation_start_date_mm_dd_yyyy     &lt;date&gt; NA, NA, NA, NA, NA, …\n$ actual_implementation_start_date_mm_dd_yyyy      &lt;date&gt; 2014-01-01, 2009-01-…\n$ actual_implementation_start_date_estimated       &lt;chr&gt; \"No\", \"No\", NA, NA, N…\n$ deviation_from_planned_implementation_start_date &lt;dbl&gt; NA, NA, NA, NA, NA, N…\n$ planned_completion_date_mm_dd_yyyy               &lt;date&gt; NA, NA, NA, NA, NA, …\n$ actual_completion_date_mm_dd_yyyy                &lt;date&gt; NA, NA, 2015-12-01, …\n$ actual_completion_date_estimated                 &lt;chr&gt; \"No\", \"No\", NA, NA, N…\n$ deviation_from_planned_completion_date           &lt;dbl&gt; NA, NA, NA, NA, NA, N…\n$ first_loan_repayment_date                        &lt;date&gt; 2013-01-11, 2015-06-…\n$ last_loan_repayment_date                         &lt;date&gt; 2023-07-10, 2025-12-…\n\n\n\n\n\n\n\n\nWhy Clean Dates?\n\n\n\nRaw dates can appear in many formats:\n\n“2021-01-15”\n“1/15/21”\n“15 Jan 2021”\n“2021-Q1”\n\nProper date formatting enables:\n\nTime-series analysis\nDuration calculations\nCorrect sorting\nFiltering by time periods\n\nIf you are creating a data cleaning pipeline that will be used on newer versions of the same dataset, make sure to coerce dates into the correct format even if they are parsed correctly by read_excel() (or other data import methods). Next time they might not be, and a date variable that is read in as a character string might mess up your subsequent analysis pipelines.\n\n\n\n\n7.6.3 Step 3: Standardize Country Information\nCreate consistent country identifiers:\n\n\n\n\n\n\nWhy Standardize Country Names?\n\n\n\nCountries often appear differently across datasets:\n\n“Cote d’Ivoire” vs “Ivory Coast”\n“Democratic Republic of the Congo” vs “DR Congo”\n“People’s Republic of China” vs “China”\n\nStandardization enables:\n\nJoining across datasets\nConsistent visualization labels\nRegional aggregation\nIntegration with other global data\n\n\n\n\nminerals_countries &lt;- minerals_dates |&gt;\n  mutate(\n    # Add ISO3C codes\n    iso3c = countrycode(\n      sourcevar = recipient,\n      origin = \"country.name\",\n      destination = \"iso3c\",\n      origin_regex = TRUE,  # Helps match variations\n      warn = TRUE          # Shows what doesn't match\n    ),\n    # Add standardized names\n    country_name = countrycode(\n      sourcevar = iso3c,\n      origin = \"iso3c\",\n      destination = \"country.name\"\n    ),\n    # Add World Bank regions\n    wb_region = countrycode(\n      sourcevar = iso3c,\n      origin = \"iso3c\",\n      destination = \"region\"\n    )\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `iso3c = countrycode(...)`.\nCaused by warning:\n! Some values were not matched unambiguously: Africa, regional\n\nminerals_countries |&gt; \n  select(\n    country_name,\n    recipient,\n    wb_region,\n    recipient_region\n  ) |&gt; \n  unique()\n\n# A tibble: 20 × 4\n   country_name       recipient                       wb_region recipient_region\n   &lt;chr&gt;              &lt;chr&gt;                           &lt;chr&gt;     &lt;chr&gt;           \n 1 Kazakhstan         Kazakhstan                      Europe &… Asia            \n 2 Peru               Peru                            Latin Am… America         \n 3 Eritrea            Eritrea                         Sub-Saha… Africa          \n 4 Serbia             Serbia                          Europe &… Europe          \n 5 Kyrgyzstan         Kyrgyz Republic                 Europe &… Asia            \n 6 Russia             Russia                          Europe &… Europe          \n 7 Dominican Republic Dominican Republic              Latin Am… America         \n 8 Chile              Chile                           Latin Am… America         \n 9 Congo - Kinshasa   Democratic Republic of the Con… Sub-Saha… Africa          \n10 Myanmar (Burma)    Myanmar                         East Asi… Asia            \n11 Zambia             Zambia                          Sub-Saha… Africa          \n12 Ecuador            Ecuador                         Latin Am… America         \n13 South Africa       South Africa                    Sub-Saha… Africa          \n14 Laos               Lao People's Democratic Republ… East Asi… Asia            \n15 &lt;NA&gt;               Africa, regional                &lt;NA&gt;      Africa          \n16 Papua New Guinea   Papua New Guinea                East Asi… Oceania         \n17 Vietnam            Viet Nam                        East Asi… Asia            \n18 Uganda             Uganda                          Sub-Saha… Africa          \n19 Indonesia          Indonesia                       East Asi… Asia            \n20 Iran               Iran                            Middle E… Middle East     \n\n\n\n\n\n\n\n\nHandling Non-Country Entries\n\n\n\nSome datasets include regional entries (like “Africa, regional”) that won’t match country codes. Options for handling these:\n\nUse warn = TRUE to see what doesn’t match\nCreate custom matching rules for special cases (see ?countrycode)\nDocument any manual corrections needed\n\nHow you handle these will depend on the context of your dataset and analysis. It’s worth remembering that the definition of regions and other aggregates often varies slightly by data source.\n\n\n\n\n\n\n\n\nCountry Code Best Practices\n\n\n\n\nUse ISO3C for Programming\n\nThree-letter codes are unambiguous\nAvoid ISO2C (e.g., Namibia’s “NA” can cause issues)\nPerfect for plot labels where space is tight\n\nUse Standardized Names for Presentation\n\nMore readable than codes\nConsistent across datasets\nGood for reports and visualizations\n\nKeep Multiple Identifiers\n\nOriginal names (match documentation)\nISO3C codes (for programming)\nStandardized names (for presentation)\nRegional groupings (for analysis)\n\nCheck the countrycode::codelist\n# See all available code types\n?countrycode::codelist\n\n# Common useful conversions:\n# - \"continent\" Continent as defined in the World Bank Development Indicators\n# - \"currency\" ISO 4217 currency name\n# - \"region\" Regions as defined in the World Bank Development Indicators\n# - \"eu28\" for EU membership\n\n\n\n\n\n7.6.4 Step 4: Create Proper Categories\nConvert text categories to meaningful factors.\nYou don’t need to do this for all text variables, but consider doing it for ones you are going to use often, and where order matters for tables + charts.\n\nminerals_cats &lt;- minerals_countries |&gt;\n  mutate(\n    # Make status an ordered factor\n    status = factor(\n      status,\n      levels = c(\n        \"Pipeline: Commitment\",\n        \"Implementation\",\n        \"Completion\"\n      )\n    ),\n    # Make income groups ordered\n    oecd_oda_income_group = factor(\n      oecd_oda_income_group,\n      levels = c(\n        \"Low income\",\n        \"Lower middle income\",\n        \"Upper middle income\"\n      )\n    )\n  )\n\nminerals_cats |&gt; \n  count(\n    status\n  )\n\n# A tibble: 3 × 2\n  status                   n\n  &lt;fct&gt;                &lt;int&gt;\n1 Pipeline: Commitment    22\n2 Implementation          26\n3 Completion              89\n\n\n\n\n\n\n\n\nWhy Create Proper Factors?\n\n\n\nRaw categorical data often needs structure:\n\nNatural ordering (status phases)\nGrouping levels (income categories)\nConsistent labels\n\nProper factors enable:\n\nCorrect ordering in plots\nMeaningful summaries\nEfficient filtering\nClear presentation",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_pre_class.html#creating-a-reusable-pipeline",
    "href": "week_4_pre_class.html#creating-a-reusable-pipeline",
    "title": "7  Week 4: Import & Tidy Your Data (Pre-Class)",
    "section": "7.7 Creating a Reusable Pipeline",
    "text": "7.7 Creating a Reusable Pipeline\nNow let’s combine these steps into a reusable function:\n\nprocess_minerals_data &lt;- function(data) {\n  data |&gt;\n    # Step 1: Clean column names\n    clean_names() |&gt;\n    \n    # Step 2: Fix dates\n    mutate(\n      commitment_date_mm_dd_yyyy = ymd(commitment_date_mm_dd_yyyy),\n      planned_implementation_start_date_mm_dd_yyyy = ymd(planned_implementation_start_date_mm_dd_yyyy),\n      actual_implementation_start_date_mm_dd_yyyy = ymd(actual_implementation_start_date_mm_dd_yyyy),\n      planned_completion_date_mm_dd_yyyy = ymd(planned_completion_date_mm_dd_yyyy),\n      actual_completion_date_mm_dd_yyyy = ymd(actual_completion_date_mm_dd_yyyy),\n      first_loan_repayment_date = ymd(first_loan_repayment_date),\n      last_loan_repayment_date = ymd(last_loan_repayment_date)\n    ) |&gt;\n    \n    # Step 3: Standardize country information\n    mutate(\n      iso3c = countrycode(\n        sourcevar = recipient,\n        origin = \"country.name\",\n        destination = \"iso3c\",\n        origin_regex = TRUE,\n        warn = TRUE\n      ),\n      country_name = countrycode(\n        sourcevar = iso3c,\n        origin = \"iso3c\",\n        destination = \"country.name\"\n      ),\n      wb_region = countrycode(\n        sourcevar = iso3c,\n        origin = \"iso3c\",\n        destination = \"region\"\n      )\n    ) |&gt;\n    \n    # Step 4: Create proper factors\n    mutate(\n      status = factor(\n        status,\n        levels = c(\n          \"Pipeline: Commitment\",\n          \"Implementation\",\n          \"Completion\"\n        ),\n      ),\n      # Make income groups ordered\n      oecd_oda_income_group = factor(\n        oecd_oda_income_group,\n        levels = c(\n          \"Low income\",\n          \"Lower middle income\",\n          \"Upper middle income\"\n        )\n      ) \n    ) |&gt;\n    \n    # Step 5: Add derived variables\n    mutate(\n      amount_bn = amount_constant_usd_2021 / 1e9\n    )\n}\n\n# Use the pipeline\n# First import the data\nminerals_raw &lt;- read_excel(\n  here::here(\n    \"data-raw\", \n    \"AidData_Chinese_Financing_for_Transition_Minerals_Dataset_Version_1.0.xlsx\"\n  ),\n  sheet = \"Financial_Contribution\",\n  na = c(\"\", \"NA\", \"N/A\", \"#N/A\", \"NULL\"),\n  guess_max = 20000\n)\n\n# Then process it\nminerals_clean &lt;- minerals_raw |&gt; \n  process_minerals_data()\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `iso3c = countrycode(...)`.\nCaused by warning:\n! Some values were not matched unambiguously: Africa, regional\n\n# Save the results\nwrite_rds(\n  minerals_clean, \n  here::here(\"data\", \"minerals_clean.rds\")\n)\n\nwrite_csv(\n  minerals_clean, \n  here::here(\"data\", \"minerals_clean.csv\")\n)",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_pre_class.html#data-cleaning-checklist",
    "href": "week_4_pre_class.html#data-cleaning-checklist",
    "title": "7  Week 4: Import & Tidy Your Data (Pre-Class)",
    "section": "7.8 Data Cleaning Checklist",
    "text": "7.8 Data Cleaning Checklist\nBefore considering your data clean, verify:\nData Structure\n\nColumn names are clean and consistent\nEach variable is in its own column\nEach observation is in its own row\nNo duplicate observations\nNo hidden formatting/calculations (if from Excel)\n\nData Types\n\nDates are proper date objects\nNumbers are numeric (not text)\nCategories are proper factors\nText fields are character type\nNo mixed types in columns\n\nStandardization\n\nCountry names/codes are consistent\nCategories have standardized values\nUnits are consistent\nMissing values are properly coded\nSpecial characters handled appropriately\n\nDocumentation\n\nCleaning steps are documented\nUnusual values are noted\nMissing value handling is explained\nAssumptions are documented\nOutput files are properly labeled\n\nQuality Control\n\nRow counts match expectations\nColumn counts match expectations\nSummaries look reasonable\nMissing value patterns make sense\nExtreme values are investigated",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_pre_class.html#effective-ai-prompts-for-data-cleaning",
    "href": "week_4_pre_class.html#effective-ai-prompts-for-data-cleaning",
    "title": "7  Week 4: Import & Tidy Your Data (Pre-Class)",
    "section": "7.9 Effective AI Prompts for Data Cleaning",
    "text": "7.9 Effective AI Prompts for Data Cleaning\nHere are some powerful prompts that will help you get the most out of AI tools when cleaning data:\n\n7.9.1 Making Data Tidy\nI have a dataset that looks like this:\n[paste first few rows of your data using head() or glimpse()]\n\nI think it might not be in tidy format because:\n[describe what seems wrong, e.g., \"multiple variables in one column\" or \"values spread across columns\"]\n\nCan you help me:\n1. Identify which tidyverse principles it violates:\n   - Is each variable a column?\n   - Is each observation a row?\n   - Is each value a single cell?\n\n2. Suggest a tidyr pipeline to fix it?\n3. Explain why each step in the pipeline helps?\nExample:\nI have this dataset:\nYear  Q1_Sales  Q2_Sales  Q3_Sales  Q4_Sales\n2021    100       120       95        150\n2022    110       125       100       160\n\nThis seems untidy because sales values are spread across columns.\nHow can I reshape this to have columns: year, quarter, sales?\nTips for good tidy data prompts:\n\nShow sample data\nExplain what seems wrong\nDescribe desired output\nAsk for explanation of steps\n\n\n\n7.9.2 Understanding Data Structure\nI have an Excel file with this glimpse() output:\n[paste your glimpse() output]\n\nI want to:\n1. Clean the column names\n2. Convert dates to proper format\n3. Standardize country names\nCan you help me write a tidyverse pipeline to do this?\n\n\n7.9.3 Date Standardization\nI have dates in these formats:\n[paste unique(date_column)]\n\nI need to:\n1. Convert them to proper date objects\n2. Handle missing/invalid dates\n3. Create consistent format\n\nCan you help me write a robust date cleaning function?\n\n\n7.9.4 Debugging Data Issues\nI'm trying to clean this data but getting this error:\n[paste error message]\n\nHere's my code:\n[paste code]\n\nHere's a sample of my data:\n[paste glimpse(data)]\n\nCan you help me:\n1. Understand what's wrong\n2. Fix the immediate issue\n3. Prevent similar issues?\n\n\n7.9.5 Creating Cleaning Functions\nI need to clean multiple similar datasets with these characteristics:\n[paste glimpse(data)]\n\nCommon issues include:\n[list issues]\n\nCan you help me write a robust cleaning function that:\n1. Handles all these cases\n2. Includes error checking\n3. Documents the cleaning steps?\n\n\n\n\n\n\nGetting the Most from AI\n\n\n\n\nShow Your Data\n\nUse glimpse(), head(), or str()\nInclude sample values\nShow error messages\n\nBe Specific\n\nExplain your goal\nDescribe current issues\nList any constraints\n\nAsk for Explanation\n\nRequest comments in code\nAsk about trade-offs\nGet help with error handling",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_pre_class.html#practice-exercises",
    "href": "week_4_pre_class.html#practice-exercises",
    "title": "7  Week 4: Import & Tidy Your Data (Pre-Class)",
    "section": "7.10 Practice Exercises",
    "text": "7.10 Practice Exercises\n\n7.10.1 Exercise 1: Creating a Data Processing Pipeline\nLet’s practice by cleaning some financial data with common issues:\n\n# Create our messy data\nmessy_data &lt;- \"\nCountry,Project Value,Date,Status\nPeople's Republic of China,\\\"$12,000,000\\\",Sep 20 2021,ACTIVE\nDemocratic Republic of Congo,\\\"$8,500,000\\\",Sep 15 2021,Active\nVietnam,\\\"$15,250,000\\\",Sep 10 2021,COMPLETED\nChina,\\\"$9,750,000\\\",Sep 5 2021,active\nCote d'Ivoire,\\\"$11,250,000\\\",Sep 1 2021,Pipeline\n\"\n\n# Save to data-raw using here()\nwrite_file(\n  messy_data,\n  here::here(\"data-raw\", \"messy_finance.csv\")\n)\n\nYour tasks:\n\nCreate a function called process_finance_data() that:\n\nStandardizes country names (note: China appears twice with different names)\nCleans monetary values using parse_number()\nConverts dates to proper date format using lubridate\nCreates proper status factors. Use str_to_title() to get values to consistent case first.\n\nWrite a pipeline that:\n# Import data\nfinance_raw &lt;- read_csv(\n  here::here(\"data-raw\", \"messy_finance.csv\")\n)\n\n# Process it\nfinance_clean &lt;- finance_raw |&gt;\n  process_finance_data()\n\n# Save results\nwrite_rds(\n  finance_clean,\n  here::here(\"data\", \"finance_clean.rds\")\n)\n\n\n\n\n\n\n\nUseful Cleaning Functions\n\n\n\nFor Numbers:\n# parse_number() removes currency symbols and commas\nparse_number(\"$12,000,000\")  # Returns 12000000\nparse_number(\"$1,234.56\")    # Returns 1234.56\nFor Dates: Lubridate provides functions matching common date formats:\n\nmdy() (month-day-year): “Sep 20 2021” → 2021-09-20\nymd() (year-month-date): “2021-09-20” → 2021-09-20\ndmy() (day-month-year): “20-09-2021” → 2021-09-20\n\n\n# Examples\nlibrary(lubridate)\nmdy(\"Sep 20 2021\")    # Returns \"2021-09-20\"\n\n[1] \"2021-09-20\"\n\nymd(\"2021-09-20\")     # Returns \"2021-09-20\"\n\n[1] \"2021-09-20\"\n\ndmy(\"20-09-2021\")     # Returns \"2021-09-20\"\n\n[1] \"2021-09-20\"\n\n\nThe function name matches the order of the date components (m=month, d=day, y=year).\n\n\n\n\n\n\n\n\nMaking Text Case Consistent\n\n\n\nThe {stringr} package provides several functions for standardizing text case:\n# Convert to title case (First Letter Of Each Word)\nstr_to_title(\"RURAL ELECTRIFICATION project\")  # Returns \"Rural Electrification Project\"\n\n# Convert to upper case (ALL CAPS)\nstr_to_upper(\"Rural Electrification Project\")  # Returns \"RURAL ELECTRIFICATION PROJECT\"\n\n# Convert to lower case (all lowercase)\nstr_to_lower(\"Rural Electrification Project\")  # Returns \"rural electrification project\"\n\n# Real world example: standardizing status values\nstatus_values &lt;- c(\"IN PROGRESS\", \"Completed\", \"not started\", \"In Progress\")\n\nstatus_clean &lt;- status_values |&gt;\n  str_to_title()  # Returns: \"In Progress\", \"Completed\", \"Not Started\", \"In Progress\"\nWhen to use each:\n\nstr_to_title(): Names, project titles, status values\nstr_to_upper(): Country codes, ID values\nstr_to_lower(): Before matching or comparing strings\n\n\n\n\n\n7.10.2 Exercise 2: Working with Multiple Data Quality Issues\nLet’s practice handling several common data quality issues:\n\n# Create project data with various issues\nprojects &lt;- \"\nRegion,Project Title,Start Date,Budget (USD),Status\nEast Asia,Water Treatment Plant,Sep 15 2021,$12000000,In Progress\nEastern Asia,Solar Farm Phase 1,Sep 10 2021,$15250000,ACTIVE\nSub-Saharan Africa,Highway Extension,,\\\"$8,500,000\\\",planning\nSSA,Rural Electrification,Sep 1 2021,$11250000,ACTIVE\n\"\n\n# Save using here()\nwrite_file(\n  projects,\n  here::here(\"data-raw\", \"projects.csv\")\n)\n\nYour tasks:\n\nCreate a data processing function that:\n\nStandardizes region names (East Asia/Eastern Asia, Sub-Saharan Africa/SSA)\nHandles the missing date\nCleans monetary values\nStandardizes status values\nGroups similar projects by region\n\nAdd validation checks that:\n\nVerify all required fields are present\nCheck date ranges\nValidate budget ranges\nEnsure status values are standardized\n\n\n\n\n\n\n\n\nCommon Data Quality Issues\n\n\n\nWhen working with real data, watch for:\n\nInconsistent Names\n\nDifferent spellings\nAbbreviations\nRegional variations\n\nMissing Values\n\nEmpty cells\nPlaceholder values (“N/A”, “-”, etc.)\nImpossible values\n\nFormat Inconsistencies\n\nMixed date formats\nDifferent currency notations\nVaried text cases\n\n\nAlways document how you handle each type of issue!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_pre_class.html#resources-for-learning-more",
    "href": "week_4_pre_class.html#resources-for-learning-more",
    "title": "7  Week 4: Import & Tidy Your Data (Pre-Class)",
    "section": "7.11 Resources for Learning More",
    "text": "7.11 Resources for Learning More\n\n7.11.1 Essential References\n\nData Import & Cleaning\n\nR for Data Science - Data Import\nreadxl documentation\njanitor vignette\ncountrycode documentation\n\nWorking with Dates\n\nLubridate vignette\nDates and Times in R\n\nNumber Formatting\n\nreadr vignette on parsing numbers\nscales package for formatting",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_pre_class.html#next-steps",
    "href": "week_4_pre_class.html#next-steps",
    "title": "7  Week 4: Import & Tidy Your Data (Pre-Class)",
    "section": "7.12 Next Steps",
    "text": "7.12 Next Steps\nIn our class session, we’ll:\n\nWork with Complex Datasets\n\nHandle multiple related files\nLearn about different types of joins\nCreate robust cleaning pipelines\n\nBuild Validation Systems\n\nCreate data quality checks\nValidate transformations\nDocument cleaning decisions\n\nPractice with Real Data\n\nWork with your own datasets\nSolve common challenges\nCreate reusable solutions\n\nLearn Advanced Techniques\n\nHandle special cases\nCreate custom cleaning functions\nBuild automated workflows\n\n\nRemember: Good data cleaning is the foundation of reliable analysis. The time you invest in creating robust cleaning pipelines will save you hours of troubleshooting later!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (Pre-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_in_class.html",
    "href": "week_4_in_class.html",
    "title": "8  Week 4: Import & Tidy Your Data (In-Class)",
    "section": "",
    "text": "8.1 Today’s Agenda (90 minutes)",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_in_class.html#todays-agenda-90-minutes",
    "href": "week_4_in_class.html#todays-agenda-90-minutes",
    "title": "8  Week 4: Import & Tidy Your Data (In-Class)",
    "section": "",
    "text": "Understanding Data Integration (20 min)\n\nWhy combine multiple data sources?\nTypes of data relationships\nCommon integration challenges\nReal examples from loan performance analysis\n\nWorking with Multiple Data Sources (25 min)\n\nImporting from different sources (CSV, APIs, packages)\nStandardizing country names\nUnderstanding join types\nHandling missing values\n\nIntegrating Debt Data (40 min)\n\nCase study: GCDF and IDS data\nHands-on practice with joins\nCreating richer analysis\nSetting up for capstone project\n\nPreview: Capstone Project (5 min)\n\nNext week’s in-person session\nProject options\nResource sharing\nTeam formation",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_in_class.html#learning-objectives",
    "href": "week_4_in_class.html#learning-objectives",
    "title": "8  Week 4: Import & Tidy Your Data (In-Class)",
    "section": "8.2 Learning Objectives",
    "text": "8.2 Learning Objectives\nBy the end of this session, you will be able to:\n\nImport data from multiple sources (APIs, CSVs, R packages)\nStandardize key variables for joining datasets\nCombine datasets using different types of joins\nCreate integrated analysis incorporating multiple data sources\nBegin exploring capstone project possibilities\n\n\n\n\n\n\n\nWhy This Matters for TUFF Analysis\n\n\n\nThe ability to integrate multiple data sources is crucial for your work:\n\nCompare TUFF data with official statistics\nAdd macroeconomic context to lending data\nValidate data against multiple sources\nCreate richer analysis by combining perspectives\n\nHaving these skills will help you:\n\nWork more efficiently\nFind unique insights\nCreate compelling visualizations\nBuild reproducible workflows",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_in_class.html#todays-video-lecture",
    "href": "week_4_in_class.html#todays-video-lecture",
    "title": "8  Week 4: Import & Tidy Your Data (In-Class)",
    "section": "8.3 Today’s Video Lecture",
    "text": "8.3 Today’s Video Lecture\nWatch this video lecture to review the concepts from class 4:",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_in_class.html#setup",
    "href": "week_4_in_class.html#setup",
    "title": "8  Week 4: Import & Tidy Your Data (In-Class)",
    "section": "8.4 Setup",
    "text": "8.4 Setup\nLet’s get our workspace ready:\n# Create a new Quarto document\n# File → New File → Quarto Document\n# Save as \"week_4_integration_in_class.qmd\" in your week_4/R folder\nIntall new packages:\n\npak::pkg_install(\n  c(\n    \"wbids\",\n    \"WDI\", \n    \"Teal-Insights/imfweo\"\n  )\n)\n\nLoad required packages:\n\nlibrary(tidyverse)      # Core data science tools\nlibrary(chinadevfin3)   # GCDF 3.0 data\nlibrary(imfweo)         # IMF WEO data\nlibrary(wbids)          # WB IDS data\nlibrary(countrycode)    # Country name standardization\nlibrary(WDI)            # World Bank Development Indicators\nlibrary(janitor)        # Data cleaning tools",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_in_class.html#understanding-data-integration",
    "href": "week_4_in_class.html#understanding-data-integration",
    "title": "8  Week 4: Import & Tidy Your Data (In-Class)",
    "section": "8.5 Understanding Data Integration",
    "text": "8.5 Understanding Data Integration\n\n8.5.1 Why Combine Data Sources?\nIn real-world analysis, crucial insights often come from combining different perspectives on the same phenomenon. For example, in analyzing Chinese overseas lending:\n\nGCDF Data provides:\n\nProject-level details\nSectoral breakdown\nImplementation status\nFlow classifications\n\nIDS Data provides:\n\nOfficial debt statistics\nCreditor composition\nDebt service metrics\nRestructuring information\n\nIMF WEO Data provides:\n\nMacroeconomic context\nGDP and growth figures\nExternal sector metrics\nForward projections\n\n\n\n\n8.5.2 Key Integration Challenges\nWhen combining data, we often face:\n\nIdentifier Mismatches\n\nDifferent country names/codes\nVarious date formats\nInconsistent categorizations\n\nTemporal Alignment\n\nDifferent time periods\nVarying frequencies\nPoint vs. period data\n\nUnit Consistency\n\nNominal vs. real values\nCurrency conversions\nScale differences\n\nConceptual Mapping\n\nDifferent definitions\nVarying methodologies\nClassification systems\n\n\nLet’s see how to handle these challenges systematically.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_in_class.html#working-with-multiple-data-sources",
    "href": "week_4_in_class.html#working-with-multiple-data-sources",
    "title": "8  Week 4: Import & Tidy Your Data (In-Class)",
    "section": "8.6 Working with Multiple Data Sources",
    "text": "8.6 Working with Multiple Data Sources\n\n8.6.1 Getting IDS Debt Data\nFirst, let’s get the IDS debt distress data from GitHub:\n\n# URLs for IDS data\nids_data_url &lt;- \"https://raw.githubusercontent.com/Teal-Insights/ids_2024_explorations/main/data/ids_debt_distress_data.csv\"\nids_metadata_url &lt;- \"https://raw.githubusercontent.com/Teal-Insights/ids_2024_explorations/main/data/ids_debt_distress_metadata.csv\"\n\n# Import data\nids_data &lt;- read_csv(ids_data_url)\n\nRows: 1130763 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): geography_id, series_id, counterpart_id\ndbl (2): year, value\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nids_metadata &lt;- read_csv(ids_metadata_url)\n\nRows: 22 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (9): series_id, event_type, component, creditor, measurement, series_nam...\ndbl (1): source_id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Look at what we have\nglimpse(ids_data)\n\nRows: 1,130,763\nColumns: 5\n$ geography_id   &lt;chr&gt; \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\",…\n$ series_id      &lt;chr&gt; \"DT.DXR.DPPG.CD\", \"DT.NFL.DECT.CD\", \"DT.NFL.DECT.CD\", \"…\n$ counterpart_id &lt;chr&gt; \"915\", \"915\", \"915\", \"915\", \"915\", \"915\", \"915\", \"915\",…\n$ year           &lt;dbl&gt; 2014, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2…\n$ value          &lt;dbl&gt; 0, 66174000, 94274000, 50937000, 73861000, 64935000, 42…\n\nglimpse(ids_metadata)\n\nRows: 22\nColumns: 10\n$ series_id           &lt;chr&gt; \"DT.IXA.DPPG.CD.CG\", \"DT.IXA.OFFT.CD\", \"DT.IXA.PRV…\n$ event_type          &lt;chr&gt; \"arrears\", \"arrears\", \"arrears\", \"arrears\", \"arrea…\n$ component           &lt;chr&gt; \"interest\", \"interest\", \"interest\", \"principal\", \"…\n$ creditor            &lt;chr&gt; \"all\", \"official\", \"private\", \"official\", \"private…\n$ measurement         &lt;chr&gt; \"flow\", \"flow\", \"flow\", \"flow\", \"flow\", \"flow\", \"f…\n$ series_name         &lt;chr&gt; \"Net change in interest arrears (current US$)\", \"I…\n$ source_id           &lt;dbl&gt; 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81…\n$ source_name         &lt;chr&gt; \"International Debt Statistics: DSSI\", \"Internatio…\n$ source_note         &lt;chr&gt; \"Net change in interest arrears is the variation i…\n$ source_organization &lt;chr&gt; \"World Bank, International Debt Statistics.\", \"Wor…\n\n\n\n\n8.6.2 Getting IMF WEO Data\nNow let’s add some macroeconomic context:\n\n# List available WEO series\nweo_list_series()\n\n# A tibble: 44 × 3\n   series_code series_name                                      units           \n   &lt;chr&gt;       &lt;chr&gt;                                            &lt;chr&gt;           \n 1 BCA         Current account balance                          U.S. dollars    \n 2 BCA_NGDPD   Current account balance                          Percent of GDP  \n 3 GGR         General government revenue                       National curren…\n 4 GGR_NGDP    General government revenue                       Percent of GDP  \n 5 GGSB        General government structural balance            National curren…\n 6 GGSB_NPGDP  General government structural balance            Percent of pote…\n 7 GGX         General government total expenditure             National curren…\n 8 GGXCNL      General government net lending/borrowing         National curren…\n 9 GGXCNL_NGDP General government net lending/borrowing         Percent of GDP  \n10 GGXONLB     General government primary net lending/borrowing National curren…\n# ℹ 34 more rows\n\n# Get GDP data for all countries\ngdp_data &lt;- weo_get(\n  series = c(\n    \"NGDPD\",        # Nominal GDP in USD\n    \"NGDP_RPCH\"     # Real GDP growth\n  ),\n  # Get all countries - we'll filter later\n  countries = weo_list_countries()$country_code,\n  start_year = 2000\n)\n\nℹ Available series: NGDP_R, NGDP_RPCH, NGDP, NGDPD, PPPGDP, NGDP_D, NGDPRPC, NGDPRPPPPC, NGDPPC, NGDPDPC, PPPPC, PPPSH, PPPEX, NID_NGDP, NGSD_NGDP, PCPI, PCPIPCH, PCPIE, PCPIEPCH, TM_RPCH, TMG_RPCH, TX_RPCH, TXG_RPCH, LP, GGR, GGR_NGDP, GGX, GGX_NGDP, GGXCNL, GGXCNL_NGDP, GGXONLB, GGXONLB_NGDP, GGXWDG, GGXWDG_NGDP, NGDP_FY, BCA, BCA_NGDPD, LUR, GGXWDN, GGXWDN_NGDP, LE, GGSB, GGSB_NPGDP, NGAP_NPGDP\n\n\nℹ Requested series: NGDPD, NGDP_RPCH\n\n\nℹ Filtered series: NGDPD, NGDP_RPCH\n\nglimpse(gdp_data)\n\nRows: 11,567\nColumns: 7\n$ country_name &lt;chr&gt; \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Ar…\n$ country_code &lt;chr&gt; \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"…\n$ series_name  &lt;chr&gt; \"Gross domestic product, current prices\", \"Gross domestic…\n$ units        &lt;chr&gt; \"U.S. dollars\", \"U.S. dollars\", \"U.S. dollars\", \"U.S. dol…\n$ series_code  &lt;chr&gt; \"NGDPD\", \"NGDPD\", \"NGDPD\", \"NGDPD\", \"NGDPD\", \"NGDPD\", \"NG…\n$ year         &lt;int&gt; 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 200…\n$ value        &lt;dbl&gt; 1.873, 1.896, 1.962, 2.044, 2.255, 2.360, 2.470, 2.678, 2…\n\n\n\n\n8.6.3 Understanding Join Types\nBefore we combine our data, let’s understand the four main types of joins:\n\nInner Join: Keep only rows that match in both datasets\n\n\n# Example with small datasets\ncountry_debt &lt;- tibble(\n  country = c(\"Angola\", \"Ghana\", \"Kenya\"),\n  debt_stock = c(100, 200, 300)\n)\n\ncountry_debt\n\n# A tibble: 3 × 2\n  country debt_stock\n  &lt;chr&gt;        &lt;dbl&gt;\n1 Angola         100\n2 Ghana          200\n3 Kenya          300\n\ncountry_gdp &lt;- tibble(\n  country = c(\"Angola\", \"Ghana\", \"Zambia\"),\n  gdp = c(1000, 2000, 3000)\n)\n\ncountry_gdp\n\n# A tibble: 3 × 2\n  country   gdp\n  &lt;chr&gt;   &lt;dbl&gt;\n1 Angola   1000\n2 Ghana    2000\n3 Zambia   3000\n\n# Inner join - only Angola and Ghana appear\ncountry_debt |&gt;\n  inner_join(country_gdp, by = \"country\")\n\n# A tibble: 2 × 3\n  country debt_stock   gdp\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 Angola         100  1000\n2 Ghana          200  2000\n\n\n\nLeft Join: Keep all rows from left dataset, match where possible from right\n\n\n# Left join - Kenya appears with NA for gdp\ncountry_debt |&gt;\n  left_join(country_gdp, by = \"country\")\n\n# A tibble: 3 × 3\n  country debt_stock   gdp\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 Angola         100  1000\n2 Ghana          200  2000\n3 Kenya          300    NA\n\n\n\nRight Join: Keep all rows from right dataset, match where possible from left\n\n\n# Right join - Zambia appears with NA for debt_stock\ncountry_debt |&gt;\n  right_join(country_gdp, by = \"country\")\n\n# A tibble: 3 × 3\n  country debt_stock   gdp\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 Angola         100  1000\n2 Ghana          200  2000\n3 Zambia          NA  3000\n\n\n\nFull Join: Keep all rows from both datasets\n\n\n# Full join - all countries appear, with NAs where no match\ncountry_debt |&gt;\n  full_join(country_gdp, by = \"country\")\n\n# A tibble: 4 × 3\n  country debt_stock   gdp\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 Angola         100  1000\n2 Ghana          200  2000\n3 Kenya          300    NA\n4 Zambia          NA  3000\n\n\n\n\n\n\n\n\nChoosing Join Types\n\n\n\n\nUse inner_join() when you only want complete cases\nUse left_join() to keep all your primary data\nUse right_join() rarely (just use left_join with datasets reversed)\nUse full_join() to see what might be missing\n\n\n\n\n\n8.6.4 Practice Exercise: Basic Joins\nLet’s practice with some GCDF data:\n\n# Get total commitments by country\ncountry_totals &lt;- get_gcdf3_dataset() |&gt;\n  filter(recommended_for_aggregates == \"Yes\") |&gt;\n  group_by(country_name,iso3c) |&gt;\n  summarize(\n    total_commitments = sum(amount_constant_usd_2021, na.rm = TRUE)\n  ) |&gt; \n  ungroup()\n\n`summarise()` has grouped output by 'country_name'. You can override using the\n`.groups` argument.\n\ncountry_totals\n\n# A tibble: 153 × 3\n   country_name      iso3c total_commitments\n   &lt;chr&gt;             &lt;chr&gt;             &lt;dbl&gt;\n 1 Afghanistan       AFG          587689317.\n 2 Africa, regional  &lt;NA&gt;        5507076256.\n 3 Albania           ALB          128497599.\n 4 Algeria           DZA          310574109.\n 5 America, regional &lt;NA&gt;         410036891.\n 6 Angola            AGO        65104946269.\n 7 Antigua & Barbuda ATG          534626006.\n 8 Argentina         ARG       138750987557.\n 9 Armenia           ARM          105655950.\n10 Asia, regional    &lt;NA&gt;         518936052.\n# ℹ 143 more rows\n\n# Get GDP data for comparison\ngdp_totals &lt;- gdp_data |&gt;\n  filter(\n    series_code == \"NGDPD\",  # Nominal GDP\n    year == 2021             # Latest year\n  ) |&gt;\n  select(country_code, gdp = value)\n\ngdp_totals\n\n# A tibble: 194 × 2\n   country_code     gdp\n   &lt;chr&gt;          &lt;dbl&gt;\n 1 ABW             3.10\n 2 AFG            14.3 \n 3 AGO            84.4 \n 4 ALB            18.0 \n 5 AND             3.32\n 6 ARE           415.  \n 7 ARG           486.  \n 8 ARM            13.9 \n 9 ATG             1.60\n10 AUS          1658.  \n# ℹ 184 more rows\n\n\nYour turn: Try different joins\n\nInner join - which countries have both commitment and GDP data?\nLeft join - keep all countries with GCDF commitments\nFull join - see which countries are missing from each source\n\n\n\n\n\n\n\nJoining by a common key\n\n\n\nWhat variable in each dataset is the same? Look at the documentation (e.g. run ?left_join()) to figure out how to connect the two datasets.",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_in_class.html#integrating-debt-data",
    "href": "week_4_in_class.html#integrating-debt-data",
    "title": "8  Week 4: Import & Tidy Your Data (In-Class)",
    "section": "8.7 Integrating Debt Data",
    "text": "8.7 Integrating Debt Data\nNow let’s work with our real analysis datasets:\n\n8.7.1 Step 1: Standardize Country Information\nFirst, we need consistent country identifiers:\n\n# Standardize IDS data\nids_clean &lt;- ids_data |&gt;\n  mutate(\n    # Add ISO3C codes\n    iso3c = countrycode(\n      sourcevar = geography_id,\n      origin = \"iso3c\",\n      destination = \"iso3c\"\n    ),\n    # Add standardized names\n    country_name = countrycode(\n      sourcevar = iso3c,\n      origin = \"iso3c\",\n      destination = \"country.name\"\n    )\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `iso3c = countrycode(sourcevar = geography_id, origin = \"iso3c\",\n  destination = \"iso3c\")`.\nCaused by warning:\n! Some values were not matched unambiguously: EAP, ECA, IDA, IDX, LAC, LDC, LIC, LMC, LMY, MIC, MNA, SAS, SSA, UMC, XKX\n\nids_clean |&gt; glimpse()\n\nRows: 1,130,763\nColumns: 7\n$ geography_id   &lt;chr&gt; \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\",…\n$ series_id      &lt;chr&gt; \"DT.DXR.DPPG.CD\", \"DT.NFL.DECT.CD\", \"DT.NFL.DECT.CD\", \"…\n$ counterpart_id &lt;chr&gt; \"915\", \"915\", \"915\", \"915\", \"915\", \"915\", \"915\", \"915\",…\n$ year           &lt;dbl&gt; 2014, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2…\n$ value          &lt;dbl&gt; 0, 66174000, 94274000, 50937000, 73861000, 64935000, 42…\n$ iso3c          &lt;chr&gt; \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"AFG\",…\n$ country_name   &lt;chr&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanist…\n\n# Standardize WEO data\nweo_clean &lt;- gdp_data |&gt;\n  mutate(\n    # Add ISO3C codes - WEO uses ISO3C already\n    iso3c = country_code,\n    # Add standardized names\n    country_name = countrycode(\n      sourcevar = iso3c,\n      origin = \"iso3c\",\n      destination = \"country.name\"\n    )\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `country_name = countrycode(sourcevar = iso3c, origin = \"iso3c\",\n  destination = \"country.name\")`.\nCaused by warning:\n! Some values were not matched unambiguously: UVK, WBG\n\nweo_clean |&gt; glimpse()\n\nRows: 11,567\nColumns: 8\n$ country_name &lt;chr&gt; \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Aruba\", \"Ar…\n$ country_code &lt;chr&gt; \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"…\n$ series_name  &lt;chr&gt; \"Gross domestic product, current prices\", \"Gross domestic…\n$ units        &lt;chr&gt; \"U.S. dollars\", \"U.S. dollars\", \"U.S. dollars\", \"U.S. dol…\n$ series_code  &lt;chr&gt; \"NGDPD\", \"NGDPD\", \"NGDPD\", \"NGDPD\", \"NGDPD\", \"NGDPD\", \"NG…\n$ year         &lt;int&gt; 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 200…\n$ value        &lt;dbl&gt; 1.873, 1.896, 1.962, 2.044, 2.255, 2.360, 2.470, 2.678, 2…\n$ iso3c        &lt;chr&gt; \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"ABW\", \"…\n\n\n\n\n8.7.2 Step 2: Focus on Key Variables\nLet’s look at debt rescheduling:\n\n# Get rescheduling data from IDS\nrescheduling &lt;- ids_clean |&gt;\n  filter(\n    # Total amount rescheduled\n    series_id == \"DT.TXR.DPPG.CD\",\n    # Only Chinese debt\n    counterpart_id == \"730\",\n    # Focus on recent years\n    year &gt;= 2015\n  )\n\n# Get GCDF rescheduling cases and identify DSSI cases\ngcdf_rescheduling &lt;- get_gcdf3_dataset() |&gt;\n  filter(\n    flow_type == \"Debt rescheduling\",\n    recommended_for_aggregates == \"Yes\"\n  ) |&gt;\n  mutate(\n    is_dssi = str_detect(description, \"DSSI\")\n  )\n\n# Look at the mix of DSSI vs other reschedulings\ngcdf_rescheduling |&gt;\n  count(is_dssi)\n\n# A tibble: 2 × 2\n  is_dssi     n\n  &lt;lgl&gt;   &lt;int&gt;\n1 FALSE     127\n2 TRUE       76\n\n\n\n\n8.7.3 Step 3: Create Combined Analysis\nNow we can start comparing sources:\n\n# Get GCDF rescheduling counts by country-year\ngcdf_counts &lt;- gcdf_rescheduling |&gt;\n  group_by(country_name, commitment_year, is_dssi) |&gt;\n  summarize(\n    rescheduling_count = n(),\n    .groups = \"drop\"\n  ) |&gt;\n  # Make counts by type\n  pivot_wider(\n    names_from = is_dssi,\n    values_from = rescheduling_count,\n    values_fill = 0,\n    names_prefix = \"gcdf_count_\"\n  )\n\n# Combine with IDS amounts\nrescheduling_comparison &lt;- gcdf_counts |&gt;\n  distinct() |&gt;\n  left_join(\n    rescheduling |&gt;\n      distinct(\n        country_name,\n        year,\n        ids_amount = value\n      ),\n    by = c(\n      \"country_name\" = \"country_name\",\n      \"commitment_year\" = \"year\"\n    )\n  )\n\n# Check the results\nrescheduling_comparison |&gt;\n  filter(!is.na(ids_amount)) |&gt;\n  filter(commitment_year &gt;= 2015) |&gt;\n  arrange(desc(ids_amount))\n\n# A tibble: 45 × 5\n   country_name      commitment_year gcdf_count_FALSE gcdf_count_TRUE ids_amount\n   &lt;chr&gt;                       &lt;dbl&gt;            &lt;int&gt;           &lt;int&gt;      &lt;dbl&gt;\n 1 Angola                       2021                1               1 706480000 \n 2 Angola                       2020                2               1 417506000 \n 3 Zambia                       2021                0               1 396636083.\n 4 Congo - Brazzavi…            2018                1               0 348614000 \n 5 Kenya                        2021                0               4 260013515.\n 6 Pakistan                     2020                0              15 211145714.\n 7 Congo - Brazzavi…            2021                0               4 172200897.\n 8 Zambia                       2020                1               1 136449665.\n 9 Cameroon                     2021                0               1  93865480.\n10 Tanzania                     2021                0               1  91867983.\n# ℹ 35 more rows\n\n# First create summary data\nrescheduling_summary &lt;- gcdf_rescheduling |&gt;\n  # Get annual counts by DSSI vs non-DSSI\n  group_by(commitment_year, is_dssi) |&gt;\n  summarize(\n    count = n(),\n    .groups = \"drop\"\n  ) |&gt;\n  # Make DSSI labels more readable\n  mutate(\n    rescheduling_type = if_else(\n      is_dssi,\n      \"DSSI Rescheduling\",\n      \"Other Rescheduling\"\n    )\n  )\n\n# Create visualization\nggplot(\n  rescheduling_summary |&gt;\n    filter(commitment_year &gt;= 2015)\n) +\n  geom_col(\n    aes(\n      x = commitment_year,\n      y = count,\n      fill = rescheduling_type\n    ),\n    position = \"stack\"\n  ) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(\n    title = \"Debt Rescheduling Cases by Type\",\n    subtitle = \"DSSI vs Other Reschedulings (2015-2021)\",\n    x = \"Year\",\n    y = \"Number of Cases\",\n    fill = NULL\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n8.7.4 Practice Exercise: Exploring Rescheduling Patterns\nYour turn! Try these exercises:\n\nAnalyze DSSI participation:\n\n\nWhich countries had DSSI reschedulings?\nHow does this compare to eligible countries?\nWhat patterns do you see by region?\n\n\nCompare with IDS reporting:\n\n\nDo countries with more GCDF reschedulings show larger IDS amounts?\nAre there systematic differences by region or income group?\nWhat might explain any discrepancies?\n\n\nAdd economic context:\n\n\nUse WEO data to add GDP context\nCalculate rescheduling amounts as % of GDP\nLook for patterns in timing relative to growth rates\n\n\n\n\n\n\n\nAnalysis Tips\n\n\n\n\nStart by looking at simple counts and patterns\nAdd complexity gradually\nDocument unexpected findings\nConsider what patterns might mean for data collection",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_in_class.html#setting-up-the-capstone-project",
    "href": "week_4_in_class.html#setting-up-the-capstone-project",
    "title": "8  Week 4: Import & Tidy Your Data (In-Class)",
    "section": "8.8 Setting Up the Capstone Project",
    "text": "8.8 Setting Up the Capstone Project\n\n8.8.1 Project Structure\nThe capstone project will explore Chinese overseas lending data using multiple sources:\n\nCore Data Sources\n\nGCDF 3.0 Database\nWorld Bank IDS\nIMF WEO\nOther sources you identify\n\nKey Questions\n\nHow do GCDF and IDS data compare?\nWhat patterns emerge in debt distress?\nHow does economic context matter?\nWhat stories deserve deeper investigation?\n\nOutput Options\n\nBlog post\nPolicy brief\nInteractive dashboard\nAutomated report system\nYour creative ideas!\n\n\n\n\n8.8.2 Next Week’s Schedule\nMorning Session (9:30-11:00) - Storytelling with Data workshop - Project planning - Team formation\nMidday (11:30-3:00) - Optional work session - One-on-one consultations - Team collaboration time\nAfternoon Session (3:00-4:30) - Project development - Peer feedback - Planning next steps\n\n\n8.8.3 This Week’s Preparation\n\nExplore the Data\n\nTry different integration approaches\nLook for interesting patterns\nDocument questions that arise\n\nConsider Output Format\n\nWhat would be most useful?\nWho is your audience?\nWhat story do you want to tell?\n\nOptional: Other Projects\n\nIf you have other data to work with\nDifferent questions to explore\nAlternative output formats",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_in_class.html#resources-for-data-integration",
    "href": "week_4_in_class.html#resources-for-data-integration",
    "title": "8  Week 4: Import & Tidy Your Data (In-Class)",
    "section": "8.9 Resources for Data Integration",
    "text": "8.9 Resources for Data Integration\n\n8.9.1 Essential References\n\nR for Data Science Chapters\n\nData Import\nData Tidying\nJoins\n\nNotable Data Resources\n\nWDI vignette\nimfr examples\nOur World in Data GitHub\n\n\n\n\n8.9.2 Additional Learning\n\nData Integration Concepts\n\nRelational Data chapter\nDatabase Concepts in R\nBest Practices for Joins",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (In-Class)</span>"
    ]
  },
  {
    "objectID": "week_4_in_class.html#wrapping-up",
    "href": "week_4_in_class.html#wrapping-up",
    "title": "8  Week 4: Import & Tidy Your Data (In-Class)",
    "section": "8.10 Wrapping Up",
    "text": "8.10 Wrapping Up\n\n8.10.1 Key Takeaways\n\nData Integration Power\n\nCombining sources reveals new insights\nStandardization is crucial\nDocumentation matters\n\nJoin Mechanics\n\nDifferent joins for different needs\nAlways check results\nConsider what missing data means\n\nProject Preparation\n\nStart exploring now\nThink about storytelling\nConsider your audience\n\n\n\n\n8.10.2 Next Steps\n\nThis Week\n\nExplore the data\nTry different combinations\nDocument interesting findings\n\nNext Wednesday\n\nBring your discoveries\nCome with questions\nBe ready to collaborate\n\n\nRemember: The goal is to create something useful for your work while practicing your new R skills!",
    "crumbs": [
      "Part 1: Data Analysis Bootcamp",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Week 4: Import & Tidy Your Data (In-Class)</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "10  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Summary</span>"
    ]
  }
]